/*!
 * player v1.0.3 development
 * Updated : 2022-06-20
 */
/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
var adserve;
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/css-loader/dist/cjs.js!./src/css/styles.css":
/*!******************************************************************!*\
  !*** ./node_modules/css-loader/dist/cjs.js!./src/css/styles.css ***!
  \******************************************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_0__);\n// Imports\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_0___default()(function(i){return i[1]});\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \".adserve-tv-player,\\n.adserve-tv-player:before,\\n.adserve-tv-player:after,\\n.adserve-tv-player * {\\n    hyphens: manual;\\n    font-size: 16px; /*inherit*/\\n    color: inherit;\\n    background: 0 0;\\n    border: 0;\\n    border-radius: 0;\\n    border-spacing: 0;\\n    border-collapse: collapse;\\n    box-sizing: content-box;\\n    clear: none;\\n    float: none;\\n    font-variant: normal;\\n    font-weight: inherit;\\n    letter-spacing: normal;\\n    line-height: 1.5; /*normal*/\\n    margin: 0;\\n    max-height: none;\\n    max-width: none;\\n    min-height: 0;\\n    min-width: 0;\\n    outline: 0;\\n    padding: 0;\\n    position: static;\\n    text-align: left;\\n    text-decoration: none;\\n    text-indent: 0;\\n    text-transform: none;\\n    vertical-align: baseline;\\n    visibility: inherit;\\n    word-spacing: normal;\\n}\\n.adserve-tv-player {\\n    position: relative;\\n}\\n.adserve-tv-player.sticky {\\n    position: fixed;\\n    right: 20px;\\n    bottom: 20px;\\n    z-index: 9999;\\n    width: 280px;\\n}\\n.adserve-tv-player .video-container {\\n    padding-bottom: 56.25%;\\n}\\n.adserve-tv-player .video {\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    width: 100%;\\n    height: 100%;\\n}\\n.adserve-tv-player .resizer {\\n    width: 100%;\\n    height: 100%;\\n    position: absolute;\\n    border: none;\\n    background-color: transparent\\n}\\n.adserve-tv-player .ad-container {\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    width: 100%;\\n    height: 100%;\\n}\\n.adserve-tv-player .spinner {\\n    display: none;\\n    position: absolute;\\n    top: 50%;\\n    left: 50%;\\n    margin: -25px 0 0 -25px;\\n    opacity: 1;\\n    text-align: left;\\n    /*border: 6px solid rgba($primary-background-color, $primary-background-transparency);*/\\n    border: 4px solid rgba(255, 255, 255, 0.5);\\n    box-sizing: border-box;\\n    background-clip: padding-box;\\n    width: 50px;\\n    height: 50px;\\n    border-radius: 25px;\\n    visibility: hidden;\\n}\\n.adserve-tv-player.waiting .spinner {\\n    display: block;\\n    animation: spinner-show 0s linear 0.3s forwards;\\n}\\n.adserve-tv-player .spinner:before,\\n.adserve-tv-player .spinner:after {\\n    content: \\\"\\\";\\n    position: absolute;\\n    margin: -4px;\\n    box-sizing: inherit;\\n    width: inherit;\\n    height: inherit;\\n    border-radius: inherit;\\n    opacity: 1;\\n    border: inherit;\\n    border-color: transparent;\\n    border-top-color: white;\\n}\\n.adserve-tv-player.waiting .spinner:before,\\n.adserve-tv-player.waiting .spinner:after {\\n    -webkit-animation: spinner-spin 1.1s cubic-bezier(0.6, 0.2, 0, 0.8) infinite, spinner-fade 1.1s linear infinite;\\n    animation: spinner-spin 1.1s cubic-bezier(0.6, 0.2, 0, 0.8) infinite, spinner-fade 1.1s linear infinite;\\n}\\n.adserve-tv-player.waiting .spinner:before {\\n    border-top-color: rgb(255,255,255);\\n}\\n.adserve-tv-player.waiting .spinner:after {\\n    border-top-color: rgb(255,255,255);\\n    -webkit-animation-delay: 0.44s;\\n    animation-delay: 0.44s;\\n}\\n@keyframes spinner-show {\\n    to {\\n        visibility: visible;\\n    }\\n}\\n@-webkit-keyframes spinner-show {\\n    to {\\n        visibility: visible;\\n    }\\n}\\n@keyframes spinner-spin {\\n    100% {\\n        transform: rotate(360deg);\\n    }\\n}\\n@-webkit-keyframes spinner-spin {\\n    100% {\\n        -webkit-transform: rotate(360deg);\\n    }\\n}\\n@keyframes spinner-fade {\\n    0% {\\n        border-top-color: white;\\n    }\\n    20% {\\n        border-top-color: white;\\n    }\\n    35% {\\n        border-top-color: white;\\n    }\\n    60% {\\n        border-top-color: white;\\n    }\\n    100% {\\n        border-top-color: white;\\n    }\\n}\\n@-webkit-keyframes spinner-fade {\\n    0% {\\n        border-top-color: white;\\n    }\\n    20% {\\n        border-top-color: white;\\n    }\\n    35% {\\n        border-top-color: white;\\n    }\\n    60% {\\n        border-top-color: white;\\n    }\\n    100% {\\n        border-top-color: white;\\n    }\\n}\\n.adserve-tv-player .gradient {\\n    transition: opacity 250ms ease 0s, visibility 250ms ease 0s;\\n    opacity: 0.01;\\n    visibility: hidden;\\n}\\n.adserve-tv-player .gradiant.show {\\n    opacity: 1;\\n    visibility: visible;\\n}\\n.adserve-tv-player .overlay {\\n    height: 100%;\\n    width: 100%;\\n    position: absolute;\\n    z-index: 1;\\n    top: 0px;\\n    user-select: none;\\n    /*pointer-events: none;*/\\n}\\n.adserve-tv-player .header {\\n    transition: opacity 250ms ease 0s, visibility 250ms ease 0s;\\n    opacity: 0.01;\\n    visibility: hidden;\\n    box-sizing: border-box;\\n    position: absolute;\\n    top: 0px;\\n    left: 0px;\\n    line-height: 22px;\\n    padding: 25px 20px;\\n    font-size: 17px;\\n    width: 100%;\\n    display: flex;\\n    -webkit-box-align: center;\\n    align-items: center;\\n    z-index: 1;\\n}\\n/*.adserve-tv-player.hovered .header,*/\\n.adserve-tv-player.user-active .header,\\n.adserve-tv-player.slider-active .header,\\n.adserve-tv-player.paused .header {\\n    opacity: 1;\\n    visibility: visible;\\n}\\n.adserve-tv-player .title {\\n    box-sizing: border-box;\\n    overflow: hidden;\\n    text-overflow: ellipsis;\\n    white-space: nowrap;\\n    Xcursor: pointer;\\n    text-decoration: none;\\n    background-image: none;\\n    color: rgb(247, 247, 247);\\n    user-select: none;\\n    pointer-events: auto;\\n}\\n.adserve-tv-player .gradient {\\n    transition: opacity 250ms ease 0s, visibility 250ms ease 0s;\\n    opacity: 0.01;\\n    visibility: hidden;\\n}\\n/*.adserve-tv-player.hovered .gradient,*/\\n.adserve-tv-player.user-active .gradient,\\n.adserve-tv-player.slider-active .gradient,\\n.adserve-tv-player.paused .gradient {\\n    opacity: 1;\\n    visibility: visible;\\n}\\n.adserve-tv-player .gradient-top {\\n    left: 0px;\\n    pointer-events: none;\\n    position: absolute;\\n    width: 100%;\\n    z-index: 0;\\n    background: linear-gradient(rgba(0, 0, 0, 0.85), rgba(0, 0, 0, 0.45) 40%, rgba(0, 0, 0, 0));\\n    height: 6em;\\n    top: 0px;\\n}\\n.adserve-tv-player .gradient-bottom {\\n    left: 0px;\\n    pointer-events: none;\\n    position: absolute;\\n    width: 100%;\\n    z-index: 0;\\n    background: linear-gradient(0deg, rgba(0, 0, 0, 0.85), rgba(0, 0, 0, 0.45) 40%, rgba(0, 0, 0, 0));\\n    bottom: 0px;\\n    height: 10em;\\n}\\n.adserve-tv-player .control-bar {\\n    position: absolute;\\n    bottom: 0;\\n    top: auto;\\n    width: 100%;\\n    left: 0;\\n    right: 0;\\n    height: 65px;\\n}\\n.adserve-tv-player .controls {\\n    bottom: 0px;\\n    display: flex;\\n    flex-direction: row;\\n    -webkit-box-pack: start;\\n    justify-content: flex-start;\\n    position: absolute;\\n    width: 100%;\\n    color: rgb(247, 247, 247);\\n    padding: 0px 20px 20px;\\n    height: 45px;\\n    -webkit-box-align: center;\\n    align-items: center;\\n    z-index: 10;\\n    pointer-events: all;\\n    transition: opacity 250ms ease 0s, visibility 250ms ease 0s;\\n    opacity: 0.01;\\n    visibility: hidden;\\n    box-sizing: border-box;\\n}\\n/*.adserve-tv-player.hovered .controls,*/\\n.adserve-tv-player.user-active .controls,\\n.adserve-tv-player.slider-active .controls,\\n.adserve-tv-player.paused .controls {\\n    opacity: 1;\\n    visibility: visible;\\n}\\n.adserve-tv-player .timeline {\\n    position: absolute;\\n    height: 4px;\\n    left: 20px;\\n    right: 20px;\\n    bottom: 56px;\\n    cursor: pointer;\\n    background: rgb(100, 100, 100);\\n    background: rgba(255, 255, 255, 0.5);\\n    -webkit-box-shadow: 0 0 3px 0 rgb(0 0 0 / 10%);\\n    -moz-box-shadow: 0 0 3px 0 rgba(0, 0, 0, 0.1);\\n    box-shadow: 0 0 3px 0 rgb(0 0 0 / 10%);\\n\\n    transition: opacity 250ms ease 0s, visibility 250ms ease 0s;\\n    opacity: 0.01;\\n    visibility: hidden;\\n}\\n.adserve-tv-player.slider-active .timeline,\\n.adserve-tv-player .timeline:hover,\\n.adserve-tv-player .timeline.sliding {\\n    height: 8px;\\n    bottom: 54px;\\n}\\n/*.adserve-tv-player.hovered .timeline,*/\\n.adserve-tv-player.user-active .timeline,\\n.adserve-tv-player.slider-active .timeline,\\n.adserve-tv-player.paused .timeline {\\n    opacity: 1;\\n    visibility: visible;\\n}\\n.adserve-tv-player .timeline:before {\\n    content: \\\"\\\";\\n    width: 100%;\\n    position: absolute;\\n    left: 0;\\n    height: 100%\\n}\\n.adserve-tv-player .timeline-buffer {\\n    position: absolute;\\n    left: 0;\\n    height: 100%;\\n    background: #fff;\\n}\\n.adserve-tv-player .timeline-progress {\\n    position: absolute;\\n    left: 0;\\n    height: 100%;\\n    background: red;\\n}\\n.adserve-tv-player .timeline-progress:before {\\n    -webkit-transition-timing-function: cubic-bezier(0,0,0.2,1);\\n    transition-timing-function: cubic-bezier(0,0,0.2,1);\\n    -webkit-transition-duration: 167ms;\\n    transition-duration: 167ms;\\n    content: '';\\n    position: absolute;\\n    background-color: #fff;\\n    width: 10px;\\n    height: 10px;\\n    border-radius: 5px;\\n    -webkit-box-shadow: 0 1px 1px 1px rgb(0 0 0 / 40%);\\n    box-shadow: 0 1px 1px 1px rgb(0 0 0 / 40%);\\n    top: 50%;\\n    right: -5px;\\n    margin-top: -5px;\\n}\\n.adserve-tv-player .timeline:hover .timeline-progress:before {\\n    -webkit-transform: scale(1.5);\\n    transform: scale(1.5);\\n}\\n.adserve-tv-player .time-tooltip {\\n    -webkit-transition-timing-function: cubic-bezier(0,0,0.2,1);\\n    transition-timing-function: cubic-bezier(0,0,0.2,1);\\n    -webkit-transition-duration: 167ms;\\n    transition-duration: 167ms;\\n    background-color: rgba(0,0,0,0.75);\\n    -webkit-box-shadow: 0 0 0 1px rgb(255 255 255 / 10%);\\n    box-shadow: 0 0 0 1px rgb(255 255 255 / 10%);\\n    border-radius: 2px;\\n    white-space: nowrap;\\n    overflow: hidden;\\n    text-overflow: ellipsis;\\n    /*font-size: 1.2rem;\\n    line-height: 1.33333;\\n    font-weight: 600;*/\\n    color: #fff;\\n    text-shadow: 0 1px 0 rgb(0 0 0 / 80%);\\n    pointer-events: none;\\n    position: static;\\n    padding: 4px 8px;\\n    max-width: 240px;\\n    -webkit-transition-property: opacity;\\n    transition-property: opacity;\\n    display: none;\\n    position: absolute;\\n    bottom: 22px;\\n}\\n.adserve-tv-player .play {\\n    Xbackground-image: url(data:image/svg+xml;base64,DQo8c3ZnIHdpZHRoPSIzM3B4IiBoZWlnaHQ9IjM4cHgiIHZpZXdCb3g9IjMxIDI0IDMzIDM4IiB2ZXJzaW9uPSIxLjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiPg0KICAgIDwhLS0gR2VuZXJhdG9yOiBTa2V0Y2ggNDIgKDM2NzgxKSAtIGh0dHA6Ly93d3cuYm9oZW1pYW5jb2RpbmcuY29tL3NrZXRjaCAtLT4NCiAgICA8ZGVzYz5DcmVhdGVkIHdpdGggU2tldGNoLjwvZGVzYz4NCiAgICA8ZGVmcz48L2RlZnM+DQogICAgPHBhdGggZD0iTTQ2Ljc1MjQ1OTcsMjcuMjk5NDI0MSBDNDYuOTYzMzE0MiwyNi45Mzk3MDM4IDQ3LjMwNzMyNDEsMjYuOTQzMzY3IDQ3LjUxNjAzMTQsMjcuMjk5NDI0MSBMNjUuNDQxMzE5Nyw1Ny44ODAxODQ1IEM2NS42NTIxNzQyLDU4LjIzOTkwNDggNjUuNDg4NTU1OCw1OC41MzE1MTU4IDY1LjA3NjQ3MTUsNTguNTMxNTE1OCBMMjkuMTkyMDE5Niw1OC41MzE1MTU4IEMyOC43Nzk2NjUsNTguNTMxNTE1OCAyOC42MTg0NjQxLDU4LjIzNjI0MTYgMjguODI3MTcxNCw1Ny44ODAxODQ1IEw0Ni43NTI0NTk3LDI3LjI5OTQyNDEgWiIgaWQ9IlRyaWFuZ2xlIiBzdHJva2U9Im5vbmUiIGZpbGw9IiNGRkZGRkYiIGZpbGwtcnVsZT0iZXZlbm9kZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoNDcuMTM0NjkzLCA0Mi43ODEyNjEpIHJvdGF0ZSgtMjcwLjAwMDAwMCkgdHJhbnNsYXRlKC00Ny4xMzQ2OTMsIC00Mi43ODEyNjEpICI+PC9wYXRoPg0KPC9zdmc+);\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCA3NTIgMTAyNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNzUyIDEwMjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+DQoJLnN0MHtmaWxsOiNGRkZGRkY7fQ0KPC9zdHlsZT4NCjxwb2x5Z29uIGNsYXNzPSJzdDAiIHBvaW50cz0iNzUyLDUxMiAwLDAgMCwxMDI0ICIvPg0KPC9zdmc+DQo=);\\n    padding: 0px;\\n    background-color: transparent;\\n    border: none;\\n    background-repeat: no-repeat;\\n    background-position: center center;\\n    outline: none;\\n    width: 24px;\\n    height: 24px;\\n    background-size: 15px;\\n    cursor: pointer;\\n}\\n.adserve-tv-player .play.pause {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCA3ODQgMTAyNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNzg0IDEwMjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+DQoJLnN0MHtmaWxsOiNGRkZGRkY7fQ0KPC9zdHlsZT4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik01ODIuMiwwaDkuOGMzOSwwLDY4LjMsMjkuMyw2OC4zLDY4LjN2ODg3LjVjMCwzOS0yOS4zLDY4LjMtNjguMyw2OC4zaC05LjhjLTM5LDAtNjguMy0yOS4zLTY4LjMtNjguM1Y2OC4zDQoJQzUxMy45LDI5LjMsNTQzLjIsMCw1ODIuMiwwTDU4Mi4yLDB6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNMTkyLjEsMGg5LjhjMzksMCw2OC4zLDI5LjMsNjguMyw2OC4zdjg4Ny41YzAsMzktMjkuMyw2OC4zLTY4LjMsNjguM2gtOS44Yy0zOSwwLTY4LjMtMjkuMy02OC4zLTY4LjNWNjguMw0KCUMxMjMuOCwyOS4zLDE1My4xLDAsMTkyLjEsMEwxOTIuMSwweiIvPg0KPC9zdmc+DQo=);\\n    background-size: 14px;\\n}\\n.adserve-tv-player.ended .play {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCAxMDEwLjQgOTc2LjEiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDEwMTAuNCA5NzYuMTsiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4NCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9DQo8L3N0eWxlPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTE1Ny4yLDU0djI3Ny4zYzAsMzQuMS0yOS45LDY0LTY0LDY0aC00LjNjLTM0LjEsMC01OS43LTI1LjYtNTkuNy01OS43VjExMy43QzI5LjIsNzkuNiw1NC44LDU0LDg4LjksNTQNCglDODguOSw1NCwxNTcuMiw1NCwxNTcuMiw1NHoiLz4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik00MDguOSwzMTQuMkgxMTguOGMtMjkuOSwwLTU1LjUsMjUuNi01NS41LDU1LjVsMCwwYzAsMjkuOSwyNS42LDU1LjUsNTUuNSw1NS41aDIzMC40DQoJYzM0LjEsMCw1OS43LTI1LjYsNTkuNy01OS43VjMxNC4yTDQwOC45LDMxNC4yeiIvPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTEyNi4xLDI0OS45QzI1OC4zLDMyLjMsNTM5LjktMzYsNzU3LjUsOTYuM3MyOTAuMSw0MTMuOSwxNTcuOSw2MzEuNXMtNDEzLjksMjgxLjYtNjMxLjUsMTUzLjYNCgljLTIxLjMtMTcuMS0yOS45LTQ2LjktMTcuMS03Mi41YzEyLjgtMjUuNiw0Ni45LTI5LjksNjguMy0xNy4xYzE3MC43LDEwMi40LDM4OC4zLDQ2LjksNDkwLjctMTE5LjUNCglDOTI4LjIsNTAxLjYsODcyLjcsMjg0LDcwMi4xLDE4MS42cy0zODguMy00Ni45LTQ5MC43LDExOS41Yy0xMi44LDI1LjYtNDYuOSwyOS45LTY4LjMsMTcuMVMxMTMuMywyNzUuNSwxMjYuMSwyNDkuOUwxMjYuMSwyNDkuOXoiDQoJLz4NCjwvc3ZnPg0K);\\n    background-size: 20px;\\n}\\n.adserve-tv-player .next {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCA4ODAgMTAyNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgODgwIDEwMjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+DQoJLnN0MHtmaWxsOiNGRkZGRkY7fQ0KPC9zdHlsZT4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik04MDAuOCwwaDkuOGMzOSwwLDY4LjMsMjkuMyw2OC4zLDY4LjN2ODg3LjVjMCwzOS0yOS4zLDY4LjMtNjguMyw2OC4zaC05LjhjLTM5LDAtNjguMy0yOS4zLTY4LjMtNjguM1Y2OC4zDQoJQzczMi42LDI5LjMsNzYxLjgsMCw4MDAuOCwwTDgwMC44LDB6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNMS4xLDEwMjRjMCwwLDAtMzQxLjMsMC0xMDI0YzAsMCwyNDMuOCwxNjAuOSw3MzEuNCw0ODcuNmMwLDE5LjUsMCwyNC40LDAsNDguOA0KCUM3MzIuNiw1MjEuOCw0ODguOCw2ODIuNywxLjEsMTAyNHoiLz4NCjwvc3ZnPg0K);\\n    padding: 0px;\\n    background-color: transparent;\\n    border: none;\\n    background-repeat: no-repeat;\\n    background-position: center center;\\n    outline: none;\\n    width: 24px;\\n    height: 24px;\\n    background-size: 16px;\\n    cursor: pointer;\\n}\\n.adserve-tv-player .volume {\\n    Xbackground-image: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTE0NyIgaGVpZ2h0PSIxMDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGc+CiAgPHRpdGxlPkxheWVyIDE8L3RpdGxlPgogIDxnIGlkPSJzdmdfMSIgdHJhbnNmb3JtPSJtYXRyaXgoMSwwLDAsLTEsMCw5NjApICI+CiAgIDxwYXRoIGlkPSJzdmdfMiIgZD0ibTc5NSw3OThxLTksMCAtMTUsLTZ0LTYsLTE1bDAsLTQycTAsLTkgNiwtMTUuNXQxNSwtNi41cTUxLC0zIDk1LjUsLTI1dDc3LjUsLTU3LjV0NTIsLTgydDE5LC05OC41dC0xOSwtOTh0LTUyLC04MS41dC03Ny41LC01Ny41dC05NS41LC0yNnEtOSwwIC0xNSwtNnQtNiwtMTVsMCwtNDJxMCwtOSA2LC0xNXQxNSwtNnE2OSw0IDEyOC41LDMzdDEwMy41LDc2dDY5LjUsMTA4LjV0MjUuNSwxMjkuNXEwLDY5IC0yNS41LDEzMC41dC02OS41LDEwOHQtMTAzLjUsNzZ0LTEyOC41LDMzLjVsMCwwem01LC00NzlxNDYsOSA3Niw0NXQzMCw4NHQtMzAsODR0LTc2LDQ1cS0xMSwyIC0xOC41LC00dC03LjUsLTE3bDAsLTIxNnEwLC05IDcuNSwtMTZ0MTguNSwtNWwwLDB6bS0yNTEsNTI4bC0zMTcsLTE5OWwtMTcwLDBxLTI2LDAgLTQ0LjUsLTE4LjV0LTE4LjUsLTQ1LjVsMCwtMjg2cTAsLTI3IDE4LjUsLTQ1LjV0NDQuNSwtMTguNWwxOTUsMGwyODcsLTE4NXEyMywtMTYgNTUsLTUuNXQzMiw0MC41bDAsNzI4cTIsMzAgLTI5LDM5LjV0LTUzLC00LjVsMCwweiIgZmlsbD0iI2Y3ZjdmNyIvPgogIDwvZz4KIDwvZz4KPC9zdmc+Cg==);\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCAxMjE2IDEwMjQiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDEyMTYgMTAyNDsiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4NCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9DQo8L3N0eWxlPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAsNzExLjloMjYzLjNMNjc3LjgsMTAyNFYwTDI2My4zLDMxMi4xSDBWNzExLjl6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNODc3LjcsMzQxLjNsLTY4LjMsNjguM2M1My42LDU4LjUsNTMuNiwxNDYuMywwLDIwNC44bDY4LjMsNjguM0M5NzAuNCw1OTAsOTcwLjQsNDM0LDg3Ny43LDM0MS4zTDg3Ny43LDM0MS4zeg0KCSIvPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTEwODcuNCwyMDQuOGwtNzMuMSw3OGM2OC4zLDczLjEsMTAyLjQsMTY1LjgsMTAyLjQsMjYzLjNjMCwxMDIuNC0zNC4xLDE5NS0xMDIuNCwyNjMuM2w3My4xLDc4DQoJYzgyLjktOTIuNiwxMzEuNy0yMTQuNiwxMzEuNy0zNDEuM1MxMTcwLjMsMjk3LjQsMTA4Ny40LDIwNC44TDEwODcuNCwyMDQuOHoiLz4NCjwvc3ZnPg0K);\\n    padding: 0px;\\n    background-color: transparent;\\n    border: none;\\n    background-repeat: no-repeat;\\n    background-position: center center;\\n    outline: none;\\n    width: 24px;\\n    height: 24px;\\n    background-size: 24px;\\n    cursor: pointer;\\n    margin-left: 10px;\\n}\\n.adserve-tv-player .volume.mid {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCAxMjE2IDEwMjQiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDEyMTYgMTAyNDsiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4NCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9DQo8L3N0eWxlPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAsNzExLjloMjYzLjNMNjc3LjgsMTAyNFYwTDI2My4zLDMxMi4xSDBWNzExLjl6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNODc3LjcsMzQxLjNsLTY4LjMsNjguM2M1My42LDU4LjUsNTMuNiwxNDYuMywwLDIwNC44bDY4LjMsNjguM0M5NzAuNCw1OTAsOTcwLjQsNDM0LDg3Ny43LDM0MS4zTDg3Ny43LDM0MS4zeg0KCSIvPg0KPC9zdmc+DQo=);\\n}\\n.adserve-tv-player .volume.muted {\\n    Xbackground-image: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTE0NCIgaGVpZ2h0PSIxMDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGc+CiAgPHRpdGxlPkxheWVyIDE8L3RpdGxlPgogIDxnIGlkPSJzdmdfMSIgdHJhbnNmb3JtPSJtYXRyaXgoMSwwLDAsLTEsMCw5NjApICI+CiAgIDxwYXRoIGlkPSJzdmdfMiIgZD0ibTEwMTUsNDQxbDg5LDg5cTEyLDEzIDEyLDMwdC0xMiwyOXQtMjkuNSwxMnQtMjkuNSwtMTJsLTg5LC04OWwtODksODlxLTEzLDEyIC0zMCwxMnQtMjksLTEydC0xMiwtMjl0MTIsLTMwbDg5LC04OWwtODksLTg5cS0xMiwtMTMgLTEyLC0zMHQxMiwtMjlxNywtNyAxNC41LC05LjV0MTUuNSwtMi41cTksMCAxNi41LDMuNXQxNC41LDguNWw4OSw4OWw4OSwtODlxOCwtNyAxNSwtOS41dDE2LC0yLjV0MTYuNSwzLjV0MTQuNSw4LjVxMTIsMTIgMTIsMjl0LTEyLDMwbC05NCw4OWwwLDB6bS00NjgsNDA0bC0zMTQsLTE5N2wtMTcyLDBxLTI2LDAgLTQ0LjUsLTE4LjV0LTE4LjUsLTQ1LjVsMCwtMjg2cTAsLTI3IDE4LjUsLTQ1LjV0NDQuNSwtMTguNWwxOTUsMGwyODcsLTE4NXEyMiwtMTYgNTQsLTUuNXQzMiw0MC41bDAsNzI2cTIsMzAgLTI3LjUsNDAuNXQtNTQuNSwtNS41bDAsMHoiIGZpbGw9IiNmN2Y3ZjciLz4KICA8L2c+CiA8L2c+Cjwvc3ZnPgo=);\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCAxMjE2IDEwMjQiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDEyMTYgMTAyNDsiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4NCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9DQo8L3N0eWxlPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAsNzExLjloMjYzLjNMNjc3LjgsMTAyNFYwTDI2My4zLDMxMi4xSDBWNzExLjl6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNMTE4Ny4xLDY4NC4ybC0zOC4xLDM1LjdjLTkuMyw4LjctMjMuOCw4LjItMzIuNS0xLjFMNzczLjEsMzUyLjJjLTguNy05LjMtOC4yLTIzLjgsMS4xLTMyLjVsMzguMS0zNS43DQoJYzkuMy04LjcsMjMuOC04LjIsMzIuNSwxLjFsMzQzLjUsMzY2LjZDMTE5Ni44LDY2MSwxMTk2LjMsNjc1LjYsMTE4Ny4xLDY4NC4yeiIvPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTc3NC4xLDY4NC4ybDM4LjEsMzUuN2M5LjMsOC43LDIzLjgsOC4yLDMyLjUtMS4xbDM0My41LTM2Ni42YzguNy05LjMsOC4yLTIzLjgtMS4xLTMyLjVsLTM4LjEtMzUuNw0KCWMtOS4zLTguNy0yMy44LTguMi0zMi41LDEuMUw3NzMuMSw2NTEuOEM3NjQuNCw2NjEsNzY0LjksNjc1LjYsNzc0LjEsNjg0LjJ6Ii8+DQo8L3N2Zz4NCg==);\\n}\\n.adserve-tv-player .timer {\\n    margin-left: 10px;\\n}\\n.adserve-tv-player .fullscreen {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCA5OTIgMTAyNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgOTkyIDEwMjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+DQoJLnN0MHtmaWxsOiNGRkZGRkY7fQ0KPC9zdHlsZT4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik05MDEuMSw0MTguNWgtMTcuOGMtMjIuMywwLTQ0LjUtMTcuOC00NC41LTQ0LjVWMTY5LjJINjM0Yy0yMi4zLDAtNDQuNS0xNy44LTQ0LjUtNDQuNVY4OQ0KCWMwLTIyLjMsMTcuOC00NC41LDQ0LjUtNDQuNWgzMjkuNVYzNzRjMCwyMi4zLTE3LjgsNDQuNS00NC41LDQ0LjVIOTAxLjFMOTAxLjEsNDE4LjV6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNNTg5LjUsOTE3LjF2LTE3LjhjMC0yMi4zLDE3LjgtNDQuNSw0NC41LTQ0LjVoMjA0LjhWNjUwYzAtMjIuMywxNy44LTQ0LjUsNDQuNS00NC41SDkxOQ0KCWMyMi4zLDAsNDQuNSwxNy44LDQ0LjUsNDQuNXYzMjkuNUg2MzRjLTIyLjMsMC00NC41LTE3LjgtNDQuNS00NC41VjkxNy4xTDU4OS41LDkxNy4xeiIvPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTkwLjksNjA1LjVoMTcuOGMyMi4zLDAsNDQuNSwxNy44LDQ0LjUsNDQuNXYyMDQuOEgzNThjMjIuMywwLDQ0LjUsMTcuOCw0NC41LDQ0LjVWOTM1DQoJYzAsMjIuMy0xNy44LDQ0LjUtNDQuNSw0NC41SDI4LjVWNjUwYzAtMjIuMywxNy44LTQ0LjUsNDQuNS00NC41SDkwLjlMOTAuOSw2MDUuNXoiLz4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik00MDIuNSwxMDYuOXYxNy44YzAsMjIuMy0xNy44LDQ0LjUtNDQuNSw0NC41SDE1My4yVjM3NGMwLDIyLjMtMTcuOCw0NC41LTQ0LjUsNDQuNUg3Mw0KCWMtMjIuMywwLTQ0LjUtMTcuOC00NC41LTQ0LjVWNDQuNUgzNThjMjIuMywwLDQ0LjUsMTcuOCw0NC41LDQ0LjVWMTA2LjlMNDAyLjUsMTA2Ljl6Ii8+DQo8L3N2Zz4NCg==);\\n    padding: 0px;\\n    background-color: transparent;\\n    border: none;\\n    background-repeat: no-repeat;\\n    background-position: center center;\\n    outline: none;\\n    width: 24px;\\n    height: 24px;\\n    background-size: 18px;\\n    cursor: pointer;\\n    margin-left: auto;\\n}\\n.adserve-tv-player .fullscreen.off {\\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiDQoJIHZpZXdCb3g9IjAgMCAxMDI0IDEwMjQiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDEwMjQgMTAyNDsiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4NCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9DQo8L3N0eWxlPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTY4Mi43LDBoMjAuNUM3MzAuNSwwLDc1MSwyMC41LDc1MSw0Ny44djIyNS4zaDIyNS4zYzI3LjMsMCw0Ny44LDIwLjUsNDcuOCw0Ny44djQxDQoJYzAsMjcuMy0yMC41LDQ3LjgtNDcuOCw0Ny44SDYxNC40VjQ3LjhjMC0yNy4zLDIwLjUtNDcuOCw0Ny44LTQ3LjhINjgyLjdMNjgyLjcsMHoiLz4NCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0xMDI0LDY4Mi43djIwLjVjMCwyNy4zLTIwLjUsNDcuOC00Ny44LDQ3LjhINzUwLjl2MjI1LjNjMCwyNy4zLTIwLjUsNDcuOC00Ny44LDQ3LjhoLTQxDQoJYy0yNy4zLDAtNDcuOC0yMC41LTQ3LjgtNDcuOFY2MTQuNGgzNjEuOGMyNy4zLDAsNDcuOCwyMC41LDQ3LjgsNDcuOEwxMDI0LDY4Mi43TDEwMjQsNjgyLjd6Ii8+DQo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNMCwzNDEuM3YtMjAuNUMwLDI5My41LDIwLjUsMjczLDQ3LjgsMjczaDIyNS4zVjQ3LjhjMC0yNy4zLDIwLjUtNDcuOCw0Ny44LTQ3LjhoNDENCgljMjcuMywwLDQ3LjgsMjAuNSw0Ny44LDQ3Ljh2MzYxLjhINDcuOEMyMC41LDQwOS42LDAsMzg5LjEsMCwzNjEuOFYzNDEuM0wwLDM0MS4zeiIvPg0KPHBhdGggY2xhc3M9InN0MCIgZD0iTTM0MS4zLDEwMjRoLTIwLjVjLTI3LjMsMC00Ny44LTIwLjUtNDcuOC00Ny44Vjc1MC45SDQ3LjhDMjAuNSw3NTAuOSwwLDczMC41LDAsNzAzLjF2LTQxDQoJYzAtMjcuMywyMC41LTQ3LjgsNDcuOC00Ny44aDM2MS44djM2MS44YzAsMjcuMy0yMC41LDQ3LjgtNDcuOCw0Ny44TDM0MS4zLDEwMjRMMzQxLjMsMTAyNHoiLz4NCjwvc3ZnPg0K);\\n}\\n\\n.adserve-tv-player.ads .overlay,\\n.adserve-tv-player.ads .gradient,\\n.adserve-tv-player.ads .header,\\n.adserve-tv-player.ads .timeline,\\n.adserve-tv-player.ads .controls {\\n    opacity: 0;\\n    visibility: hidden;\\n}\\n\", \"\"]);\n// Exports\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://adserve/./src/css/styles.css?./node_modules/css-loader/dist/cjs.js");

/***/ }),

/***/ "./node_modules/@videojs/vhs-utils/es/decode-b64-to-uint8-array.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@videojs/vhs-utils/es/decode-b64-to-uint8-array.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ decodeB64ToUint8Array)\n/* harmony export */ });\n/* harmony import */ var global_window__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! global/window */ \"./node_modules/global/window.js\");\n/* harmony import */ var global_window__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(global_window__WEBPACK_IMPORTED_MODULE_0__);\n\n\nvar atob = function atob(s) {\n  return (global_window__WEBPACK_IMPORTED_MODULE_0___default().atob) ? global_window__WEBPACK_IMPORTED_MODULE_0___default().atob(s) : Buffer.from(s, 'base64').toString('binary');\n};\n\nfunction decodeB64ToUint8Array(b64Text) {\n  var decodedString = atob(b64Text);\n  var array = new Uint8Array(decodedString.length);\n\n  for (var i = 0; i < decodedString.length; i++) {\n    array[i] = decodedString.charCodeAt(i);\n  }\n\n  return array;\n}\n\n//# sourceURL=webpack://adserve/./node_modules/@videojs/vhs-utils/es/decode-b64-to-uint8-array.js?");

/***/ }),

/***/ "./node_modules/@videojs/vhs-utils/es/stream.js":
/*!******************************************************!*\
  !*** ./node_modules/@videojs/vhs-utils/es/stream.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Stream)\n/* harmony export */ });\n/**\n * @file stream.js\n */\n\n/**\n * A lightweight readable stream implemention that handles event dispatching.\n *\n * @class Stream\n */\nvar Stream = /*#__PURE__*/function () {\n  function Stream() {\n    this.listeners = {};\n  }\n  /**\n   * Add a listener for a specified event type.\n   *\n   * @param {string} type the event name\n   * @param {Function} listener the callback to be invoked when an event of\n   * the specified type occurs\n   */\n\n\n  var _proto = Stream.prototype;\n\n  _proto.on = function on(type, listener) {\n    if (!this.listeners[type]) {\n      this.listeners[type] = [];\n    }\n\n    this.listeners[type].push(listener);\n  }\n  /**\n   * Remove a listener for a specified event type.\n   *\n   * @param {string} type the event name\n   * @param {Function} listener  a function previously registered for this\n   * type of event through `on`\n   * @return {boolean} if we could turn it off or not\n   */\n  ;\n\n  _proto.off = function off(type, listener) {\n    if (!this.listeners[type]) {\n      return false;\n    }\n\n    var index = this.listeners[type].indexOf(listener); // TODO: which is better?\n    // In Video.js we slice listener functions\n    // on trigger so that it does not mess up the order\n    // while we loop through.\n    //\n    // Here we slice on off so that the loop in trigger\n    // can continue using it's old reference to loop without\n    // messing up the order.\n\n    this.listeners[type] = this.listeners[type].slice(0);\n    this.listeners[type].splice(index, 1);\n    return index > -1;\n  }\n  /**\n   * Trigger an event of the specified type on this stream. Any additional\n   * arguments to this function are passed as parameters to event listeners.\n   *\n   * @param {string} type the event name\n   */\n  ;\n\n  _proto.trigger = function trigger(type) {\n    var callbacks = this.listeners[type];\n\n    if (!callbacks) {\n      return;\n    } // Slicing the arguments on every invocation of this method\n    // can add a significant amount of overhead. Avoid the\n    // intermediate object creation for the common case of a\n    // single callback argument\n\n\n    if (arguments.length === 2) {\n      var length = callbacks.length;\n\n      for (var i = 0; i < length; ++i) {\n        callbacks[i].call(this, arguments[1]);\n      }\n    } else {\n      var args = Array.prototype.slice.call(arguments, 1);\n      var _length = callbacks.length;\n\n      for (var _i = 0; _i < _length; ++_i) {\n        callbacks[_i].apply(this, args);\n      }\n    }\n  }\n  /**\n   * Destroys the stream and cleans up.\n   */\n  ;\n\n  _proto.dispose = function dispose() {\n    this.listeners = {};\n  }\n  /**\n   * Forwards all `data` events on this stream to the destination stream. The\n   * destination stream should provide a method `push` to receive the data\n   * events as they arrive.\n   *\n   * @param {Stream} destination the stream that will receive all `data` events\n   * @see http://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\n   */\n  ;\n\n  _proto.pipe = function pipe(destination) {\n    this.on('data', function (data) {\n      destination.push(data);\n    });\n  };\n\n  return Stream;\n}();\n\n\n\n//# sourceURL=webpack://adserve/./node_modules/@videojs/vhs-utils/es/stream.js?");

/***/ }),

/***/ "./node_modules/ads-manager/dist/ads-manager.es.js":
/*!*********************************************************!*\
  !*** ./node_modules/ads-manager/dist/ads-manager.es.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AdsManager\": () => (/* binding */ n)\n/* harmony export */ });\nvar e={686:function(e,t){!function(e){function t(e){return(t=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e})(e)}function i(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}function r(e,t){for(var i=0;i<t.length;i++){var r=t[i];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}function n(e,t,i){return t&&r(e.prototype,t),i&&r(e,i),e}function a(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function s(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,r)}return i}function o(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?s(Object(i),!0).forEach((function(t){a(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):s(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function l(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),t&&u(e,t)}function d(e){return(d=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)})(e)}function u(e,t){return(u=Object.setPrototypeOf||function(e,t){return e.__proto__=t,e})(e,t)}function c(e,t){return!t||\"object\"!=typeof t&&\"function\"!=typeof t?function(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}(e):t}function h(e){var t=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Date.prototype.toString.call(Reflect.construct(Date,[],(function(){}))),!0}catch(e){return!1}}();return function(){var i,r=d(e);if(t){var n=d(this).constructor;i=Reflect.construct(r,arguments,n)}else i=r.apply(this,arguments);return c(this,i)}}function p(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return{id:e.id||null,adId:e.adId||null,sequence:e.sequence||null,apiFramework:e.apiFramework||null,universalAdId:{value:null,idRegistry:\"unknown\"},creativeExtensions:[]}}var v=[\"ADCATEGORIES\",\"ADCOUNT\",\"ADPLAYHEAD\",\"ADSERVINGID\",\"ADTYPE\",\"APIFRAMEWORKS\",\"APPBUNDLE\",\"ASSETURI\",\"BLOCKEDADCATEGORIES\",\"BREAKMAXADLENGTH\",\"BREAKMAXADS\",\"BREAKMAXDURATION\",\"BREAKMINADLENGTH\",\"BREAKMINDURATION\",\"BREAKPOSITION\",\"CLICKPOS\",\"CLICKTYPE\",\"CLIENTUA\",\"CONTENTID\",\"CONTENTPLAYHEAD\",\"CONTENTURI\",\"DEVICEIP\",\"DEVICEUA\",\"DOMAIN\",\"EXTENSIONS\",\"GDPRCONSENT\",\"IFA\",\"IFATYPE\",\"INVENTORYSTATE\",\"LATLONG\",\"LIMITADTRACKING\",\"MEDIAMIME\",\"MEDIAPLAYHEAD\",\"OMIDPARTNER\",\"PAGEURL\",\"PLACEMENTTYPE\",\"PLAYERCAPABILITIES\",\"PLAYERSIZE\",\"PLAYERSTATE\",\"PODSEQUENCE\",\"REGULATIONS\",\"SERVERSIDE\",\"SERVERUA\",\"TRANSACTIONID\",\"UNIVERSALADID\",\"VASTVERSIONS\",\"VERIFICATIONVENDORS\"];function m(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=[],n=g(e);for(var a in!t.ERRORCODE||i.isCustomCode||/^[0-9]{3}$/.test(t.ERRORCODE)||(t.ERRORCODE=900),t.CACHEBUSTING=k(Math.round(1e8*Math.random()).toString()),t.TIMESTAMP=(new Date).toISOString(),t.RANDOM=t.random=t.CACHEBUSTING,t)t[a]=y(t[a]);for(var s in n){var o=n[s];\"string\"==typeof o&&r.push(A(o,t))}return r}function A(e,t){var i=(e=f(e,t)).match(/[^[\\]]+(?=])/g);if(!i)return e;var r=i.filter((function(e){return v.indexOf(e)>-1}));return 0===r.length?e:f(e,r=r.reduce((function(e,t){return e[t]=-1,e}),{}))}function f(e,t){var i=e;for(var r in t){var n=t[r];i=i.replace(new RegExp(\"(?:\\\\[|%%)(\".concat(r,\")(?:\\\\]|%%)\"),\"g\"),n)}return i}function g(e){return Array.isArray(e)?e.map((function(e){return e&&e.hasOwnProperty(\"url\")?e.url:e})):e}function T(e,t){for(var i=0;i<t.length;i++)if(E(t[i],e))return!0;return!1}function E(e,t){if(e&&t){var i=Object.getOwnPropertyNames(e),r=Object.getOwnPropertyNames(t);return i.length===r.length&&e.id===t.id&&e.url===t.url}return!1}function y(e){return encodeURIComponent(e).replace(/[!'()*]/g,(function(e){return\"%\".concat(e.charCodeAt(0).toString(16))}))}function k(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:8,i=String(e);return i.length<t?_(0,t-i.length,!1).map((function(){return\"0\"})).join(\"\")+i:i}function _(e,t,i){for(var r=[],n=e<t,a=i?n?t+1:t-1:t,s=e;n?s<a:s>a;n?s++:s--)r.push(s);return r}var R={track:function(e,t,i){m(e,t,i).forEach((function(e){\"undefined\"!=typeof window&&null!==window&&((new Image).src=e)}))},resolveURLTemplates:m,extractURLsFromTemplates:g,containsTemplateObject:T,isTemplateObjectEqual:E,encodeURIComponentRFC3986:y,replaceUrlMacros:A,leftpad:k,range:_,isNumeric:function(e){return!isNaN(parseFloat(e))&&isFinite(e)},flatten:function e(t){return t.reduce((function(t,i){return t.concat(Array.isArray(i)?e(i):i)}),[])},joinArrayOfUniqueTemplateObjs:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],i=Array.isArray(e)?e:[],r=Array.isArray(t)?t:[];return i.concat(r).reduce((function(e,t){return T(t,e)||e.push(t),e}),[])}};function C(e){return-1!==[\"true\",\"TRUE\",\"True\",\"1\"].indexOf(e)}var S={childByName:function(e,t){var i=e.childNodes;for(var r in i){var n=i[r];if(n.nodeName===t)return n}},childrenByName:function(e,t){var i=[],r=e.childNodes;for(var n in r){var a=r[n];a.nodeName===t&&i.push(a)}return i},resolveVastAdTagURI:function(e,t){if(!t)return e;if(0===e.indexOf(\"//\")){var i=location.protocol;return\"\".concat(i).concat(e)}if(-1===e.indexOf(\"://\")){var r=t.slice(0,t.lastIndexOf(\"/\"));return\"\".concat(r,\"/\").concat(e)}return e},parseBoolean:C,parseNodeText:function(e){return e&&(e.textContent||e.text||\"\").trim()},copyNodeAttribute:function(e,t,i){var r=t.getAttribute(e);r&&i.setAttribute(e,r)},parseAttributes:function(e){for(var t=e.attributes,i={},r=0;r<t.length;r++)i[t[r].nodeName]=t[r].nodeValue;return i},parseDuration:function(e){if(null==e)return-1;if(R.isNumeric(e))return parseInt(e);var t=e.split(\":\");if(3!==t.length)return-1;var i=t[2].split(\".\"),r=parseInt(i[0]);2===i.length&&(r+=parseFloat(\"0.\".concat(i[1])));var n=parseInt(60*t[1]),a=parseInt(60*t[0]*60);return isNaN(a)||isNaN(n)||isNaN(r)||n>3600||r>60?-1:a+n+r},splitVAST:function(e){var t=[],i=null;return e.forEach((function(r,n){if(r.sequence&&(r.sequence=parseInt(r.sequence,10)),r.sequence>1){var a=e[n-1];if(a&&a.sequence===r.sequence-1)return void(i&&i.push(r));delete r.sequence}i=[r],t.push(i)})),t},assignAttributes:function(e,t){if(e)for(var i in e){var r=e[i];if(r.nodeName&&r.nodeValue&&t.hasOwnProperty(r.nodeName)){var n=r.nodeValue;\"boolean\"==typeof t[r.nodeName]&&(n=C(n)),t[r.nodeName]=n}}},mergeWrapperAdData:function(e,t){e.errorURLTemplates=t.errorURLTemplates.concat(e.errorURLTemplates),e.impressionURLTemplates=t.impressionURLTemplates.concat(e.impressionURLTemplates),e.extensions=t.extensions.concat(e.extensions),e.followAdditionalWrappers=t.followAdditionalWrappers,e.allowMultipleAds=t.allowMultipleAds,e.fallbackOnNoAd=t.fallbackOnNoAd;var i=(t.creatives||[]).filter((function(e){return e&&\"companion\"===e.type})),r=i.reduce((function(e,t){return(t.variations||[]).forEach((function(t){(t.companionClickTrackingURLTemplates||[]).forEach((function(t){R.containsTemplateObject(t,e)||e.push(t)}))})),e}),[]);e.creatives=i.concat(e.creatives);var n=t.videoClickTrackingURLTemplates&&t.videoClickTrackingURLTemplates.length,a=t.videoCustomClickURLTemplates&&t.videoCustomClickURLTemplates.length;e.creatives.forEach((function(e){if(t.trackingEvents&&t.trackingEvents[e.type])for(var i in t.trackingEvents[e.type]){var s=t.trackingEvents[e.type][i];Array.isArray(e.trackingEvents[i])||(e.trackingEvents[i]=[]),e.trackingEvents[i]=e.trackingEvents[i].concat(s)}\"linear\"===e.type&&(n&&(e.videoClickTrackingURLTemplates=e.videoClickTrackingURLTemplates.concat(t.videoClickTrackingURLTemplates)),a&&(e.videoCustomClickURLTemplates=e.videoCustomClickURLTemplates.concat(t.videoCustomClickURLTemplates)),!t.videoClickThroughURLTemplate||null!==e.videoClickThroughURLTemplate&&void 0!==e.videoClickThroughURLTemplate||(e.videoClickThroughURLTemplate=t.videoClickThroughURLTemplate)),\"companion\"===e.type&&r.length&&(e.variations||[]).forEach((function(e){e.companionClickTrackingURLTemplates=R.joinArrayOfUniqueTemplateObjs(e.companionClickTrackingURLTemplates,r)}))})),t.adVerifications&&(e.adVerifications=e.adVerifications.concat(t.adVerifications)),t.blockedAdCategories&&(e.blockedAdCategories=e.blockedAdCategories.concat(t.blockedAdCategories))}};function b(e,t){var i=function(){var e=p(arguments.length>0&&void 0!==arguments[0]?arguments[0]:{});return{id:e.id,adId:e.adId,sequence:e.sequence,apiFramework:e.apiFramework,type:\"companion\",required:null,variations:[]}}(t);return i.required=e.getAttribute(\"required\")||null,i.variations=S.childrenByName(e,\"Companion\").map((function(e){var t=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return{id:e.id||null,adType:\"companionAd\",width:e.width||0,height:e.height||0,assetWidth:e.assetWidth||null,assetHeight:e.assetHeight||null,expandedWidth:e.expandedWidth||null,expandedHeight:e.expandedHeight||null,apiFramework:e.apiFramework||null,adSlotID:e.adSlotID||null,pxratio:e.pxratio||\"1\",renderingMode:e.renderingMode||\"default\",staticResources:[],htmlResources:[],iframeResources:[],adParameters:null,xmlEncoded:null,altText:null,companionClickThroughURLTemplate:null,companionClickTrackingURLTemplates:[],trackingEvents:{}}}(S.parseAttributes(e));t.htmlResources=S.childrenByName(e,\"HTMLResource\").reduce((function(e,t){var i=S.parseNodeText(t);return i?e.concat(i):e}),[]),t.iframeResources=S.childrenByName(e,\"IFrameResource\").reduce((function(e,t){var i=S.parseNodeText(t);return i?e.concat(i):e}),[]),t.staticResources=S.childrenByName(e,\"StaticResource\").reduce((function(e,t){var i=S.parseNodeText(t);return i?e.concat({url:i,creativeType:t.getAttribute(\"creativeType\")||null}):e}),[]),t.altText=S.parseNodeText(S.childByName(e,\"AltText\"))||null;var i=S.childByName(e,\"TrackingEvents\");i&&S.childrenByName(i,\"Tracking\").forEach((function(e){var i=e.getAttribute(\"event\"),r=S.parseNodeText(e);i&&r&&(Array.isArray(t.trackingEvents[i])||(t.trackingEvents[i]=[]),t.trackingEvents[i].push(r))})),t.companionClickTrackingURLTemplates=S.childrenByName(e,\"CompanionClickTracking\").map((function(e){return{id:e.getAttribute(\"id\")||null,url:S.parseNodeText(e)}})),t.companionClickThroughURLTemplate=S.parseNodeText(S.childByName(e,\"CompanionClickThrough\"))||null;var r=S.childByName(e,\"AdParameters\");return r&&(t.adParameters=S.parseNodeText(r),t.xmlEncoded=r.getAttribute(\"xmlEncoded\")||null),t})),i}function V(e){return\"linear\"===e.type}function N(e,t){var i,r=function(){var e=p(arguments.length>0&&void 0!==arguments[0]?arguments[0]:{});return{id:e.id,adId:e.adId,sequence:e.sequence,apiFramework:e.apiFramework,type:\"linear\",duration:0,skipDelay:null,mediaFiles:[],mezzanine:null,interactiveCreativeFile:null,closedCaptionFiles:[],videoClickThroughURLTemplate:null,videoClickTrackingURLTemplates:[],videoCustomClickURLTemplates:[],adParameters:null,icons:[],trackingEvents:{}}}(t);r.duration=S.parseDuration(S.parseNodeText(S.childByName(e,\"Duration\")));var n=e.getAttribute(\"skipoffset\");if(null==n)r.skipDelay=null;else if(\"%\"===n.charAt(n.length-1)&&-1!==r.duration){var a=parseInt(n,10);r.skipDelay=r.duration*(a/100)}else r.skipDelay=S.parseDuration(n);var s=S.childByName(e,\"VideoClicks\");if(s){var o=S.childByName(s,\"ClickThrough\");r.videoClickThroughURLTemplate=o?{id:o.getAttribute(\"id\")||null,url:S.parseNodeText(o)}:null,S.childrenByName(s,\"ClickTracking\").forEach((function(e){r.videoClickTrackingURLTemplates.push({id:e.getAttribute(\"id\")||null,url:S.parseNodeText(e)})})),S.childrenByName(s,\"CustomClick\").forEach((function(e){r.videoCustomClickURLTemplates.push({id:e.getAttribute(\"id\")||null,url:S.parseNodeText(e)})}))}var l=S.childByName(e,\"AdParameters\");l&&(r.adParameters=S.parseNodeText(l)),S.childrenByName(e,\"TrackingEvents\").forEach((function(e){S.childrenByName(e,\"Tracking\").forEach((function(e){var t=e.getAttribute(\"event\"),n=S.parseNodeText(e);if(t&&n){if(\"progress\"===t){if(!(i=e.getAttribute(\"offset\")))return;t=\"%\"===i.charAt(i.length-1)?\"progress-\".concat(i):\"progress-\".concat(Math.round(S.parseDuration(i)))}Array.isArray(r.trackingEvents[t])||(r.trackingEvents[t]=[]),r.trackingEvents[t].push(n)}}))})),S.childrenByName(e,\"MediaFiles\").forEach((function(e){S.childrenByName(e,\"MediaFile\").forEach((function(e){r.mediaFiles.push(function(e){var t={id:null,fileURL:null,fileSize:0,deliveryType:\"progressive\",mimeType:null,mediaType:null,codec:null,bitrate:0,minBitrate:0,maxBitrate:0,width:0,height:0,apiFramework:null,scalable:null,maintainAspectRatio:null};t.id=e.getAttribute(\"id\"),t.fileURL=S.parseNodeText(e),t.deliveryType=e.getAttribute(\"delivery\"),t.codec=e.getAttribute(\"codec\"),t.mimeType=e.getAttribute(\"type\"),t.mediaType=e.getAttribute(\"mediaType\")||\"2D\",t.apiFramework=e.getAttribute(\"apiFramework\"),t.fileSize=parseInt(e.getAttribute(\"fileSize\")||0),t.bitrate=parseInt(e.getAttribute(\"bitrate\")||0),t.minBitrate=parseInt(e.getAttribute(\"minBitrate\")||0),t.maxBitrate=parseInt(e.getAttribute(\"maxBitrate\")||0),t.width=parseInt(e.getAttribute(\"width\")||0),t.height=parseInt(e.getAttribute(\"height\")||0);var i=e.getAttribute(\"scalable\");i&&\"string\"==typeof i&&(t.scalable=S.parseBoolean(i));var r=e.getAttribute(\"maintainAspectRatio\");return r&&\"string\"==typeof r&&(t.maintainAspectRatio=S.parseBoolean(r)),t}(e))}));var t=S.childByName(e,\"InteractiveCreativeFile\");t&&(r.interactiveCreativeFile=function(e){var t=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return{type:e.type||null,apiFramework:e.apiFramework||null,variableDuration:S.parseBoolean(e.variableDuration),fileURL:null}}(S.parseAttributes(e));return t.fileURL=S.parseNodeText(e),t}(t));var i=S.childByName(e,\"ClosedCaptionFiles\");i&&S.childrenByName(i,\"ClosedCaptionFile\").forEach((function(e){var t=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return{type:e.type||null,language:e.language||null,fileURL:null}}(S.parseAttributes(e));t.fileURL=S.parseNodeText(e),r.closedCaptionFiles.push(t)}));var n,a,s,o=S.childByName(e,\"Mezzanine\"),l=(n=o,a={},s=!1,[\"delivery\",\"type\",\"width\",\"height\"].forEach((function(e){n&&n.getAttribute(e)?a[e]=n.getAttribute(e):s=!0})),s?null:a);if(l){var d={id:null,fileURL:null,delivery:null,codec:null,type:null,width:0,height:0,fileSize:0,mediaType:\"2D\"};d.id=o.getAttribute(\"id\"),d.fileURL=S.parseNodeText(o),d.delivery=l.delivery,d.codec=o.getAttribute(\"codec\"),d.type=l.type,d.width=parseInt(l.width,10),d.height=parseInt(l.height,10),d.fileSize=parseInt(o.getAttribute(\"fileSize\"),10),d.mediaType=o.getAttribute(\"mediaType\")||\"2D\",r.mezzanine=d}}));var d=S.childByName(e,\"Icons\");return d&&S.childrenByName(d,\"Icon\").forEach((function(e){r.icons.push(function(e){var t={program:null,height:0,width:0,xPosition:0,yPosition:0,apiFramework:null,offset:null,duration:0,type:null,staticResource:null,htmlResource:null,iframeResource:null,pxratio:\"1\",iconClickThroughURLTemplate:null,iconClickTrackingURLTemplates:[],iconViewTrackingURLTemplate:null};t.program=e.getAttribute(\"program\"),t.height=parseInt(e.getAttribute(\"height\")||0),t.width=parseInt(e.getAttribute(\"width\")||0),t.xPosition=function(e){return-1!==[\"left\",\"right\"].indexOf(e)?e:parseInt(e||0)}(e.getAttribute(\"xPosition\")),t.yPosition=function(e){return-1!==[\"top\",\"bottom\"].indexOf(e)?e:parseInt(e||0)}(e.getAttribute(\"yPosition\")),t.apiFramework=e.getAttribute(\"apiFramework\"),t.pxratio=e.getAttribute(\"pxratio\")||\"1\",t.offset=S.parseDuration(e.getAttribute(\"offset\")),t.duration=S.parseDuration(e.getAttribute(\"duration\")),S.childrenByName(e,\"HTMLResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||\"text/html\",t.htmlResource=S.parseNodeText(e)})),S.childrenByName(e,\"IFrameResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||0,t.iframeResource=S.parseNodeText(e)})),S.childrenByName(e,\"StaticResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||0,t.staticResource=S.parseNodeText(e)}));var i=S.childByName(e,\"IconClicks\");return i&&(t.iconClickThroughURLTemplate=S.parseNodeText(S.childByName(i,\"IconClickThrough\")),S.childrenByName(i,\"IconClickTracking\").forEach((function(e){t.iconClickTrackingURLTemplates.push({id:e.getAttribute(\"id\")||null,url:S.parseNodeText(e)})}))),t.iconViewTrackingURLTemplate=S.parseNodeText(S.childByName(e,\"IconViewTracking\")),t}(e))})),r}function I(e,t){var i=function(){var e=p(arguments.length>0&&void 0!==arguments[0]?arguments[0]:{});return{id:e.id,adId:e.adId,sequence:e.sequence,apiFramework:e.apiFramework,type:\"nonlinear\",variations:[],trackingEvents:{}}}(t);return S.childrenByName(e,\"TrackingEvents\").forEach((function(e){var t,r;S.childrenByName(e,\"Tracking\").forEach((function(e){t=e.getAttribute(\"event\"),r=S.parseNodeText(e),t&&r&&(Array.isArray(i.trackingEvents[t])||(i.trackingEvents[t]=[]),i.trackingEvents[t].push(r))}))})),S.childrenByName(e,\"NonLinear\").forEach((function(e){var t={id:null,width:0,height:0,expandedWidth:0,expandedHeight:0,scalable:!0,maintainAspectRatio:!0,minSuggestedDuration:0,apiFramework:\"static\",adType:\"nonLinearAd\",type:null,staticResource:null,htmlResource:null,iframeResource:null,nonlinearClickThroughURLTemplate:null,nonlinearClickTrackingURLTemplates:[],adParameters:null};t.id=e.getAttribute(\"id\")||null,t.width=e.getAttribute(\"width\"),t.height=e.getAttribute(\"height\"),t.expandedWidth=e.getAttribute(\"expandedWidth\"),t.expandedHeight=e.getAttribute(\"expandedHeight\"),t.scalable=S.parseBoolean(e.getAttribute(\"scalable\")),t.maintainAspectRatio=S.parseBoolean(e.getAttribute(\"maintainAspectRatio\")),t.minSuggestedDuration=S.parseDuration(e.getAttribute(\"minSuggestedDuration\")),t.apiFramework=e.getAttribute(\"apiFramework\"),S.childrenByName(e,\"HTMLResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||\"text/html\",t.htmlResource=S.parseNodeText(e)})),S.childrenByName(e,\"IFrameResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||0,t.iframeResource=S.parseNodeText(e)})),S.childrenByName(e,\"StaticResource\").forEach((function(e){t.type=e.getAttribute(\"creativeType\")||0,t.staticResource=S.parseNodeText(e)}));var r=S.childByName(e,\"AdParameters\");r&&(t.adParameters=S.parseNodeText(r)),t.nonlinearClickThroughURLTemplate=S.parseNodeText(S.childByName(e,\"NonLinearClickThrough\")),S.childrenByName(e,\"NonLinearClickTracking\").forEach((function(e){t.nonlinearClickTrackingURLTemplates.push({id:e.getAttribute(\"id\")||null,url:S.parseNodeText(e)})})),i.variations.push(t)})),i}function L(e){var t=[];return e.forEach((function(e){var i=w(e);i&&t.push(i)})),t}function w(e){if(\"#comment\"===e.nodeName)return null;var t,i={name:null,value:null,attributes:{},children:[]},r=e.attributes,n=e.childNodes;if(i.name=e.nodeName,e.attributes)for(var a in r)if(r.hasOwnProperty(a)){var s=r[a];s.nodeName&&s.nodeValue&&(i.attributes[s.nodeName]=s.nodeValue)}for(var o in n)if(n.hasOwnProperty(o)){var l=w(n[o]);l&&i.children.push(l)}if(0===i.children.length||1===i.children.length&&[\"#cdata-section\",\"#text\"].indexOf(i.children[0].name)>=0){var d=S.parseNodeText(e);\"\"!==d&&(i.value=d),i.children=[]}return null===(t=i).value&&0===Object.keys(t.attributes).length&&0===t.children.length?null:i}function D(e){var t=[];return e.forEach((function(e){var i,r,n={id:e.getAttribute(\"id\")||null,adId:O(e),sequence:e.getAttribute(\"sequence\")||null,apiFramework:e.getAttribute(\"apiFramework\")||null},a=S.childByName(e,\"UniversalAdId\");a&&(i={idRegistry:a.getAttribute(\"idRegistry\")||\"unknown\",value:S.parseNodeText(a)});var s=S.childByName(e,\"CreativeExtensions\");for(var o in s&&(r=L(S.childrenByName(s,\"CreativeExtension\"))),e.childNodes){var l=e.childNodes[o],d=void 0;switch(l.nodeName){case\"Linear\":d=N(l,n);break;case\"NonLinearAds\":d=I(l,n);break;case\"CompanionAds\":d=b(l,n)}d&&(i&&(d.universalAdId=i),r&&(d.creativeExtensions=r),t.push(d))}})),t}function O(e){return e.getAttribute(\"AdID\")||e.getAttribute(\"adID\")||e.getAttribute(\"adId\")||null}var U={Wrapper:{subElements:[\"VASTAdTagURI\",\"Impression\"]},BlockedAdCategories:{attributes:[\"authority\"]},InLine:{subElements:[\"AdSystem\",\"AdTitle\",\"Impression\",\"AdServingId\",\"Creatives\"]},Category:{attributes:[\"authority\"]},Pricing:{attributes:[\"model\",\"currency\"]},Verification:{oneOfinLineResources:[\"JavaScriptResource\",\"ExecutableResource\"],attributes:[\"vendor\"]},UniversalAdId:{attributes:[\"idRegistry\"]},JavaScriptResource:{attributes:[\"apiFramework\",\"browserOptional\"]},ExecutableResource:{attributes:[\"apiFramework\",\"type\"]},Tracking:{attributes:[\"event\"]},Creatives:{subElements:[\"Creative\"]},Creative:{subElements:[\"UniversalAdId\"]},Linear:{subElements:[\"MediaFiles\",\"Duration\"]},MediaFiles:{subElements:[\"MediaFile\"]},MediaFile:{attributes:[\"delivery\",\"type\",\"width\",\"height\"]},Mezzanine:{attributes:[\"delivery\",\"type\",\"width\",\"height\"]},NonLinear:{oneOfinLineResources:[\"StaticResource\",\"IFrameResource\",\"HTMLResource\"],attributes:[\"width\",\"height\"]},Companion:{oneOfinLineResources:[\"StaticResource\",\"IFrameResource\",\"HTMLResource\"],attributes:[\"width\",\"height\"]},StaticResource:{attributes:[\"creativeType\"]},Icons:{subElements:[\"Icon\"]},Icon:{oneOfinLineResources:[\"StaticResource\",\"IFrameResource\",\"HTMLResource\"]}};function P(e,t){if(U[e.nodeName]&&U[e.nodeName].attributes){var i=U[e.nodeName].attributes.filter((function(t){return!e.getAttribute(t)}));i.length>0&&F({name:e.nodeName,parentName:e.parentNode.nodeName,attributes:i},t)}}function x(e,t,i){var r=U[e.nodeName],n=!i&&\"Wrapper\"!==e.nodeName;if(r&&!n){if(r.subElements){var a=r.subElements.filter((function(t){return!S.childByName(e,t)}));a.length>0&&F({name:e.nodeName,parentName:e.parentNode.nodeName,subElements:a},t)}i&&r.oneOfinLineResources&&(r.oneOfinLineResources.some((function(t){return S.childByName(e,t)}))||F({name:e.nodeName,parentName:e.parentNode.nodeName,oneOfResources:r.oneOfinLineResources},t))}}function M(e){return e.children&&0!==e.children.length}function F(e,t){var i=e.name,r=e.parentName,n=e.attributes,a=e.subElements,s=e.oneOfResources,o=\"Element '\".concat(i,\"'\");t(\"VAST-warning\",{message:o+=n?\" missing required attribute(s) '\".concat(n.join(\", \"),\"' \"):a?\" missing required sub element(s) '\".concat(a.join(\", \"),\"' \"):s?\" must provide one of the following '\".concat(s.join(\", \"),\"' \"):\" is empty\",parentElement:r,specVersion:4.1})}var B={verifyRequiredValues:function e(t,i,r){if(t&&t.nodeName)if(\"InLine\"===t.nodeName&&(r=!0),P(t,i),M(t)){x(t,i,r);for(var n=0;n<t.children.length;n++)e(t.children[n],i,r)}else 0===S.parseNodeText(t).length&&F({name:t.nodeName,parentName:t.parentNode.nodeName},i)},hasSubElements:M,emitMissingValueWarning:F,verifyRequiredAttributes:P,verifyRequiredSubElements:x};function W(e,t){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=i.allowMultipleAds,n=i.followAdditionalWrappers,a=e.childNodes;for(var s in a){var o=a[s];if(-1!==[\"Wrapper\",\"InLine\"].indexOf(o.nodeName)&&(\"Wrapper\"!==o.nodeName||!1!==n)){if(S.copyNodeAttribute(\"id\",e,o),S.copyNodeAttribute(\"sequence\",e,o),S.copyNodeAttribute(\"adType\",e,o),\"Wrapper\"===o.nodeName)return{ad:H(o,t),type:\"WRAPPER\"};if(\"InLine\"===o.nodeName)return{ad:q(o,t,{allowMultipleAds:r}),type:\"INLINE\"}}}}function q(e,t){return!1===(arguments.length>2&&void 0!==arguments[2]?arguments[2]:{}).allowMultipleAds&&e.getAttribute(\"sequence\")?null:j(e,t)}function j(e,t){var i=[];t&&B.verifyRequiredValues(e,t);var r=e.childNodes,n=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return{id:e.id||null,sequence:e.sequence||null,adType:e.adType||null,adServingId:null,categories:[],expires:null,viewableImpression:{},system:null,title:null,description:null,advertiser:null,pricing:null,survey:null,errorURLTemplates:[],impressionURLTemplates:[],creatives:[],extensions:[],adVerifications:[],blockedAdCategories:[],followAdditionalWrappers:!0,allowMultipleAds:!1,fallbackOnNoAd:null}}(S.parseAttributes(e));for(var a in r){var s=r[a];switch(s.nodeName){case\"Error\":n.errorURLTemplates.push(S.parseNodeText(s));break;case\"Impression\":n.impressionURLTemplates.push({id:s.getAttribute(\"id\")||null,url:S.parseNodeText(s)});break;case\"Creatives\":n.creatives=D(S.childrenByName(s,\"Creative\"));break;case\"Extensions\":var o=S.childrenByName(s,\"Extension\");n.extensions=L(o),n.adVerifications.length||(i=z(o));break;case\"AdVerifications\":n.adVerifications=Q(S.childrenByName(s,\"Verification\"));break;case\"AdSystem\":n.system={value:S.parseNodeText(s),version:s.getAttribute(\"version\")||null};break;case\"AdTitle\":n.title=S.parseNodeText(s);break;case\"AdServingId\":n.adServingId=S.parseNodeText(s);break;case\"Category\":n.categories.push({authority:s.getAttribute(\"authority\")||null,value:S.parseNodeText(s)});break;case\"Expires\":n.expires=parseInt(S.parseNodeText(s),10);break;case\"ViewableImpression\":n.viewableImpression=Y(s);break;case\"Description\":n.description=S.parseNodeText(s);break;case\"Advertiser\":n.advertiser={id:s.getAttribute(\"id\")||null,value:S.parseNodeText(s)};break;case\"Pricing\":n.pricing={value:S.parseNodeText(s),model:s.getAttribute(\"model\")||null,currency:s.getAttribute(\"currency\")||null};break;case\"Survey\":n.survey=S.parseNodeText(s);break;case\"BlockedAdCategories\":n.blockedAdCategories.push({authority:s.getAttribute(\"authority\")||null,value:S.parseNodeText(s)})}}return i.length&&(n.adVerifications=n.adVerifications.concat(i)),n}function H(e,t){var i=j(e,t),r=e.getAttribute(\"followAdditionalWrappers\"),n=e.getAttribute(\"allowMultipleAds\"),a=e.getAttribute(\"fallbackOnNoAd\");i.followAdditionalWrappers=!r||S.parseBoolean(r),i.allowMultipleAds=!!n&&S.parseBoolean(n),i.fallbackOnNoAd=a?S.parseBoolean(a):null;var s=S.childByName(e,\"VASTAdTagURI\");if(s?i.nextWrapperURL=S.parseNodeText(s):(s=S.childByName(e,\"VASTAdTagURL\"))&&(i.nextWrapperURL=S.parseNodeText(S.childByName(s,\"URL\"))),i.creatives.forEach((function(e){if(-1!==[\"linear\",\"nonlinear\"].indexOf(e.type)){if(e.trackingEvents){i.trackingEvents||(i.trackingEvents={}),i.trackingEvents[e.type]||(i.trackingEvents[e.type]={});var t=function(t){var r=e.trackingEvents[t];Array.isArray(i.trackingEvents[e.type][t])||(i.trackingEvents[e.type][t]=[]),r.forEach((function(r){i.trackingEvents[e.type][t].push(r)}))};for(var r in e.trackingEvents)t(r)}e.videoClickTrackingURLTemplates&&(Array.isArray(i.videoClickTrackingURLTemplates)||(i.videoClickTrackingURLTemplates=[]),e.videoClickTrackingURLTemplates.forEach((function(e){i.videoClickTrackingURLTemplates.push(e)}))),e.videoClickThroughURLTemplate&&(i.videoClickThroughURLTemplate=e.videoClickThroughURLTemplate),e.videoCustomClickURLTemplates&&(Array.isArray(i.videoCustomClickURLTemplates)||(i.videoCustomClickURLTemplates=[]),e.videoCustomClickURLTemplates.forEach((function(e){i.videoCustomClickURLTemplates.push(e)})))}})),i.nextWrapperURL)return i}function Q(e){var t=[];return e.forEach((function(e){var i={resource:null,vendor:null,browserOptional:!1,apiFramework:null,type:null,parameters:null,trackingEvents:{}},r=e.childNodes;for(var n in S.assignAttributes(e.attributes,i),r){var a=r[n];switch(a.nodeName){case\"JavaScriptResource\":case\"ExecutableResource\":i.resource=S.parseNodeText(a),S.assignAttributes(a.attributes,i);break;case\"VerificationParameters\":i.parameters=S.parseNodeText(a)}}var s=S.childByName(e,\"TrackingEvents\");s&&S.childrenByName(s,\"Tracking\").forEach((function(e){var t=e.getAttribute(\"event\"),r=S.parseNodeText(e);t&&r&&(Array.isArray(i.trackingEvents[t])||(i.trackingEvents[t]=[]),i.trackingEvents[t].push(r))})),t.push(i)})),t}function z(e){var t=null,i=[];return e.some((function(e){return t=S.childByName(e,\"AdVerifications\")})),t&&(i=Q(S.childrenByName(t,\"Verification\"))),i}function Y(e){var t={};t.id=e.getAttribute(\"id\")||null;var i=e.childNodes;for(var r in i){var n=i[r],a=n.nodeName,s=S.parseNodeText(n);if((\"Viewable\"===a||\"NotViewable\"===a||\"ViewUndetermined\"===a)&&s){var o=a.toLowerCase();Array.isArray(t[o])||(t[o]=[]),t[o].push(s)}}return t}var G=function(){function e(){i(this,e),this._handlers=[]}return n(e,[{key:\"on\",value:function(e,i){if(\"function\"!=typeof i)throw new TypeError(\"The handler argument must be of type Function. Received type \".concat(t(i)));if(!e)throw new TypeError(\"The event argument must be of type String. Received type \".concat(t(e)));return this._handlers.push({event:e,handler:i}),this}},{key:\"once\",value:function(e,t){return this.on(e,function(e,t,i){var r={fired:!1,wrapFn:void 0};function n(){r.fired||(e.off(t,r.wrapFn),r.fired=!0,i.bind(e).apply(void 0,arguments))}return r.wrapFn=n,n}(this,e,t))}},{key:\"off\",value:function(e,t){return this._handlers=this._handlers.filter((function(i){return i.event!==e||i.handler!==t})),this}},{key:\"emit\",value:function(e){for(var t=arguments.length,i=new Array(t>1?t-1:0),r=1;r<t;r++)i[r-1]=arguments[r];var n=!1;return this._handlers.forEach((function(t){\"*\"===t.event&&(n=!0,t.handler.apply(t,[e].concat(i))),t.event===e&&(n=!0,t.handler.apply(t,i))})),n}},{key:\"removeAllListeners\",value:function(e){return e?(this._handlers=this._handlers.filter((function(t){return t.event!==e})),this):(this._handlers=[],this)}},{key:\"listenerCount\",value:function(e){return this._handlers.filter((function(t){return t.event===e})).length}},{key:\"listeners\",value:function(e){return this._handlers.reduce((function(t,i){return i.event===e&&t.push(i.handler),t}),[])}},{key:\"eventNames\",value:function(){return this._handlers.map((function(e){return e.event}))}}]),e}(),K={get:function(e,t,i){i(new Error(\"Please bundle the library for node to use the node urlHandler\"))}},X=12e4;function J(){try{var e=new window.XMLHttpRequest;return\"withCredentials\"in e?e:null}catch(e){return null}}function Z(e,t,i){var r=i?408:e.status,n=i?\"XHRURLHandler: Request timed out after \".concat(e.timeout,\" ms (\").concat(r,\")\"):\"XHRURLHandler: \".concat(e.statusText,\" (\").concat(r,\")\");t(new Error(n),null,{statusCode:r})}var $={get:function(e,t,i){if(\"https:\"===window.location.protocol&&0===e.indexOf(\"http://\"))return i(new Error(\"XHRURLHandler: Cannot go from HTTPS to HTTP.\"));try{var r=J();r.open(\"GET\",e),r.timeout=t.timeout||X,r.withCredentials=t.withCredentials||!1,r.overrideMimeType&&r.overrideMimeType(\"text/xml\"),r.onload=function(){return function(e,t){200===e.status?t(null,e.responseXML,{byteLength:e.response.length,statusCode:e.status}):Z(e,t,!1)}(r,i)},r.onerror=function(){return Z(r,i,!1)},r.onabort=function(){return Z(r,i,!1)},r.ontimeout=function(){return Z(r,i,!0)},r.send()}catch(e){i(new Error(\"XHRURLHandler: Unexpected error\"))}},supported:function(){return!!J()}},ee={get:function(e,t,i){return i||(\"function\"==typeof t&&(i=t),t={}),\"undefined\"==typeof window||null===window?K.get(e,t,i):$.supported()?$.get(e,t,i):i(new Error(\"Current context is not supported by any of the default URLHandlers. Please provide a custom URLHandler\"))}},te=0,ie=0,re=function(e,t){!e||!t||e<=0||t<=0||(ie=(ie*te+8*e/t)/++te)},ne={ERRORCODE:900,extensions:[]},ae=function(e){l(r,e);var t=h(r);function r(){var e;return i(this,r),(e=t.call(this)).remainingAds=[],e.parentURLs=[],e.errorURLTemplates=[],e.rootErrorURLTemplates=[],e.maxWrapperDepth=null,e.URLTemplateFilters=[],e.fetchingOptions={},e.parsingOptions={},e}return n(r,[{key:\"addURLTemplateFilter\",value:function(e){\"function\"==typeof e&&this.URLTemplateFilters.push(e)}},{key:\"removeURLTemplateFilter\",value:function(){this.URLTemplateFilters.pop()}},{key:\"countURLTemplateFilters\",value:function(){return this.URLTemplateFilters.length}},{key:\"clearURLTemplateFilters\",value:function(){this.URLTemplateFilters=[]}},{key:\"trackVastError\",value:function(e,t){for(var i=arguments.length,r=new Array(i>2?i-2:0),n=2;n<i;n++)r[n-2]=arguments[n];this.emit(\"VAST-error\",Object.assign.apply(Object,[{},ne,t].concat(r))),R.track(e,t)}},{key:\"getErrorURLTemplates\",value:function(){return this.rootErrorURLTemplates.concat(this.errorURLTemplates)}},{key:\"getEstimatedBitrate\",value:function(){return ie}},{key:\"fetchVAST\",value:function(e){var t=this,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,r=arguments.length>2&&void 0!==arguments[2]?arguments[2]:null;return new Promise((function(n,a){t.URLTemplateFilters.forEach((function(t){e=t(e)})),t.parentURLs.push(e);var s=Date.now();t.emit(\"VAST-resolving\",{url:e,previousUrl:r,wrapperDepth:i,maxWrapperDepth:t.maxWrapperDepth,timeout:t.fetchingOptions.timeout}),t.urlHandler.get(e,t.fetchingOptions,(function(o,l){var d=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},u=Math.round(Date.now()-s),c=Object.assign({url:e,previousUrl:r,wrapperDepth:i,error:o,duration:u},d);t.emit(\"VAST-resolved\",c),re(d.byteLength,u),o?a(o):n(l)}))}))}},{key:\"initParsingStatus\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.errorURLTemplates=[],this.fetchingOptions={timeout:e.timeout||X,withCredentials:e.withCredentials},this.maxWrapperDepth=e.wrapperLimit||10,this.parentURLs=[],this.parsingOptions={allowMultipleAds:e.allowMultipleAds},this.remainingAds=[],this.rootErrorURLTemplates=[],this.rootURL=\"\",this.urlHandler=e.urlHandler||e.urlhandler||ee,this.vastVersion=null,re(e.byteLength,e.requestDuration)}},{key:\"getRemainingAds\",value:function(e){var t=this;if(0===this.remainingAds.length)return Promise.reject(new Error(\"No more ads are available for the given VAST\"));var i=e?R.flatten(this.remainingAds):this.remainingAds.shift();return this.errorURLTemplates=[],this.parentURLs=[],this.resolveAds(i,{wrapperDepth:0,url:this.rootURL}).then((function(e){return t.buildVASTResponse(e)}))}},{key:\"getAndParseVAST\",value:function(e){var t=this,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return this.initParsingStatus(i),this.URLTemplateFilters.forEach((function(t){e=t(e)})),this.rootURL=e,this.fetchVAST(e).then((function(r){return i.previousUrl=e,i.isRootVAST=!0,i.url=e,t.parse(r,i).then((function(e){return t.buildVASTResponse(e)}))}))}},{key:\"parseVAST\",value:function(e){var t=this,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return this.initParsingStatus(i),i.isRootVAST=!0,this.parse(e,i).then((function(e){return t.buildVASTResponse(e)}))}},{key:\"buildVASTResponse\",value:function(e){var t,i={ads:(t={ads:e,errorURLTemplates:this.getErrorURLTemplates(),version:this.vastVersion}).ads||[],errorURLTemplates:t.errorURLTemplates||[],version:t.version||null};return this.completeWrapperResolving(i),i}},{key:\"parseVastXml\",value:function(e,t){var i=t.isRootVAST,r=void 0!==i&&i,n=t.url,a=void 0===n?null:n,s=t.wrapperDepth,o=void 0===s?0:s,l=t.allowMultipleAds,d=t.followAdditionalWrappers;if(!e||!e.documentElement||\"VAST\"!==e.documentElement.nodeName)throw this.emit(\"VAST-ad-parsed\",{type:\"ERROR\",url:a,wrapperDepth:o}),new Error(\"Invalid VAST XMLDocument\");var u=[],c=e.documentElement.childNodes,h=e.documentElement.getAttribute(\"version\");for(var p in r&&h&&(this.vastVersion=h),c){var v=c[p];if(\"Error\"===v.nodeName){var m=S.parseNodeText(v);r?this.rootErrorURLTemplates.push(m):this.errorURLTemplates.push(m)}else if(\"Ad\"===v.nodeName){if(this.vastVersion&&parseFloat(this.vastVersion)<3)l=!0;else if(!1===l&&u.length>1)break;var A=W(v,this.emit.bind(this),{allowMultipleAds:l,followAdditionalWrappers:d});A.ad?(u.push(A.ad),this.emit(\"VAST-ad-parsed\",{type:A.type,url:a,wrapperDepth:o,adIndex:u.length-1,vastVersion:h})):this.trackVastError(this.getErrorURLTemplates(),{ERRORCODE:101})}}return u}},{key:\"parse\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},i=t.url,r=void 0===i?null:i,n=t.resolveAll,a=void 0===n||n,s=t.wrapperSequence,o=void 0===s?null:s,l=t.previousUrl,d=void 0===l?null:l,u=t.wrapperDepth,c=void 0===u?0:u,h=t.isRootVAST,p=void 0!==h&&h,v=t.followAdditionalWrappers,m=t.allowMultipleAds,A=[];this.vastVersion&&parseFloat(this.vastVersion)<3&&p&&(m=!0);try{A=this.parseVastXml(e,{isRootVAST:p,url:r,wrapperDepth:c,allowMultipleAds:m,followAdditionalWrappers:v})}catch(e){return Promise.reject(e)}return 1===A.length&&null!=o&&(A[0].sequence=o),!1===a&&(this.remainingAds=S.splitVAST(A),A=this.remainingAds.shift()),this.resolveAds(A,{wrapperDepth:c,previousUrl:d,url:r})}},{key:\"resolveAds\",value:function(){var e=this,t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],i=arguments.length>1?arguments[1]:void 0,r=i.wrapperDepth,n=i.previousUrl,a=i.url,s=[];return n=a,t.forEach((function(t){var i=e.resolveWrappers(t,r,n);s.push(i)})),Promise.all(s).then((function(t){var i=R.flatten(t);if(!i&&e.remainingAds.length>0){var s=e.remainingAds.shift();return e.resolveAds(s,{wrapperDepth:r,previousUrl:n,url:a})}return i}))}},{key:\"resolveWrappers\",value:function(e,t,i){var r=this;return new Promise((function(n){var a;if(t++,!e.nextWrapperURL)return delete e.nextWrapperURL,n(e);if(t>=r.maxWrapperDepth||-1!==r.parentURLs.indexOf(e.nextWrapperURL))return e.errorCode=302,delete e.nextWrapperURL,n(e);e.nextWrapperURL=S.resolveVastAdTagURI(e.nextWrapperURL,i),r.URLTemplateFilters.forEach((function(t){e.nextWrapperURL=t(e.nextWrapperURL)}));var s=null!==(a=r.parsingOptions.allowMultipleAds)&&void 0!==a?a:e.allowMultipleAds,o=e.sequence;r.fetchVAST(e.nextWrapperURL,t,i).then((function(a){return r.parse(a,{url:e.nextWrapperURL,previousUrl:i,wrapperSequence:o,wrapperDepth:t,followAdditionalWrappers:e.followAdditionalWrappers,allowMultipleAds:s}).then((function(t){if(delete e.nextWrapperURL,0===t.length)return e.creatives=[],n(e);t.forEach((function(t){t&&S.mergeWrapperAdData(t,e)})),n(t)}))})).catch((function(t){e.errorCode=301,e.errorMessage=t.message,n(e)}))}))}},{key:\"completeWrapperResolving\",value:function(e){if(0===e.ads.length)this.trackVastError(e.errorURLTemplates,{ERRORCODE:303});else for(var t=e.ads.length-1;t>=0;t--){var i=e.ads[t];(i.errorCode||0===i.creatives.length)&&(this.trackVastError(i.errorURLTemplates.concat(e.errorURLTemplates),{ERRORCODE:i.errorCode||303},{ERRORMESSAGE:i.errorMessage||\"\"},{extensions:i.extensions},{system:i.system}),e.ads.splice(t,1))}}}]),r}(G),se=null,oe={data:{},length:0,getItem:function(e){return this.data[e]},setItem:function(e,t){this.data[e]=t,this.length=Object.keys(this.data).length},removeItem:function(e){delete this.data[e],this.length=Object.keys(this.data).length},clear:function(){this.data={},this.length=0}},le=function(){function e(){i(this,e),this.storage=this.initStorage()}return n(e,[{key:\"initStorage\",value:function(){if(se)return se;try{se=\"undefined\"!=typeof window&&null!==window?window.localStorage||window.sessionStorage:null}catch(e){se=null}return se&&!this.isStorageDisabled(se)||(se=oe).clear(),se}},{key:\"isStorageDisabled\",value:function(e){var t=\"__VASTStorage__\";try{if(e.setItem(t,t),e.getItem(t)!==t)return e.removeItem(t),!0}catch(e){return!0}return e.removeItem(t),!1}},{key:\"getItem\",value:function(e){return this.storage.getItem(e)}},{key:\"setItem\",value:function(e,t){return this.storage.setItem(e,t)}},{key:\"removeItem\",value:function(e){return this.storage.removeItem(e)}},{key:\"clear\",value:function(){return this.storage.clear()}}]),e}(),de=function(){function e(t,r,n){i(this,e),this.cappingFreeLunch=t||0,this.cappingMinimumTimeInterval=r||0,this.defaultOptions={withCredentials:!1,timeout:0},this.vastParser=new ae,this.storage=n||new le,void 0===this.lastSuccessfulAd&&(this.lastSuccessfulAd=0),void 0===this.totalCalls&&(this.totalCalls=0),void 0===this.totalCallsTimeout&&(this.totalCallsTimeout=0)}return n(e,[{key:\"getParser\",value:function(){return this.vastParser}},{key:\"hasRemainingAds\",value:function(){return this.vastParser.remainingAds.length>0}},{key:\"getNextAds\",value:function(e){return this.vastParser.getRemainingAds(e)}},{key:\"get\",value:function(e){var t=this,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},r=Date.now();return(i=Object.assign({},this.defaultOptions,i)).hasOwnProperty(\"resolveAll\")||(i.resolveAll=!1),this.totalCallsTimeout<r?(this.totalCalls=1,this.totalCallsTimeout=r+36e5):this.totalCalls++,new Promise((function(n,a){if(t.cappingFreeLunch>=t.totalCalls)return a(new Error(\"VAST call canceled – FreeLunch capping not reached yet \".concat(t.totalCalls,\"/\").concat(t.cappingFreeLunch)));var s=r-t.lastSuccessfulAd;if(s<0)t.lastSuccessfulAd=0;else if(s<t.cappingMinimumTimeInterval)return a(new Error(\"VAST call canceled – (\".concat(t.cappingMinimumTimeInterval,\")ms minimum interval reached\")));t.vastParser.getAndParseVAST(e,i).then((function(e){return n(e)})).catch((function(e){return a(e)}))}))}},{key:\"lastSuccessfulAd\",get:function(){return this.storage.getItem(\"vast-client-last-successful-ad\")},set:function(e){this.storage.setItem(\"vast-client-last-successful-ad\",e)}},{key:\"totalCalls\",get:function(){return this.storage.getItem(\"vast-client-total-calls\")},set:function(e){this.storage.setItem(\"vast-client-total-calls\",e)}},{key:\"totalCallsTimeout\",get:function(){return this.storage.getItem(\"vast-client-total-calls-timeout\")},set:function(e){this.storage.setItem(\"vast-client-total-calls-timeout\",e)}}]),e}(),ue=function(e){l(r,e);var t=h(r);function r(e,n,a){var s,o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:null;for(var l in i(this,r),(s=t.call(this)).ad=n,s.creative=a,s.variation=o,s.muted=!1,s.impressed=!1,s.skippable=!1,s.trackingEvents={},s.lastPercentage=0,s._alreadyTriggeredQuartiles={},s.emitAlwaysEvents=[\"creativeView\",\"start\",\"firstQuartile\",\"midpoint\",\"thirdQuartile\",\"complete\",\"resume\",\"pause\",\"rewind\",\"skip\",\"closeLinear\",\"close\"],s.creative.trackingEvents){var d=s.creative.trackingEvents[l];s.trackingEvents[l]=d.slice(0)}return V(s.creative)?s._initLinearTracking():s._initVariationTracking(),e&&s.on(\"start\",(function(){e.lastSuccessfulAd=Date.now()})),s}return n(r,[{key:\"_initLinearTracking\",value:function(){this.linear=!0,this.skipDelay=this.creative.skipDelay,this.setDuration(this.creative.duration),this.clickThroughURLTemplate=this.creative.videoClickThroughURLTemplate,this.clickTrackingURLTemplates=this.creative.videoClickTrackingURLTemplates}},{key:\"_initVariationTracking\",value:function(){if(this.linear=!1,this.skipDelay=-1,this.variation){for(var e in this.variation.trackingEvents){var t=this.variation.trackingEvents[e];this.trackingEvents[e]?this.trackingEvents[e]=this.trackingEvents[e].concat(t.slice(0)):this.trackingEvents[e]=t.slice(0)}\"nonLinearAd\"===this.variation.adType?(this.clickThroughURLTemplate=this.variation.nonlinearClickThroughURLTemplate,this.clickTrackingURLTemplates=this.variation.nonlinearClickTrackingURLTemplates,this.setDuration(this.variation.minSuggestedDuration)):function(e){return\"companionAd\"===e.adType}(this.variation)&&(this.clickThroughURLTemplate=this.variation.companionClickThroughURLTemplate,this.clickTrackingURLTemplates=this.variation.companionClickTrackingURLTemplates)}}},{key:\"setDuration\",value:function(e){this.assetDuration=e,this.quartiles={firstQuartile:Math.round(25*this.assetDuration)/100,midpoint:Math.round(50*this.assetDuration)/100,thirdQuartile:Math.round(75*this.assetDuration)/100}}},{key:\"setProgress\",value:function(e){var t=this,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},r=this.skipDelay||-1;if(-1===r||this.skippable||(r>e?this.emit(\"skip-countdown\",r-e):(this.skippable=!0,this.emit(\"skip-countdown\",0))),this.assetDuration>0){var n=Math.round(e/this.assetDuration*100),a=[];if(e>0){a.push(\"start\");for(var s=this.lastPercentage;s<n;s++)a.push(\"progress-\".concat(s+1,\"%\"));for(var o in a.push(\"progress-\".concat(Math.round(e))),this.quartiles)this.isQuartileReached(o,this.quartiles[o],e)&&(a.push(o),this._alreadyTriggeredQuartiles[o]=!0);this.lastPercentage=n}a.forEach((function(e){t.track(e,{macros:i,once:!0})})),e<this.progress&&this.track(\"rewind\",{macros:i})}this.progress=e}},{key:\"isQuartileReached\",value:function(e,t,i){var r=!1;return t<=i&&!this._alreadyTriggeredQuartiles[e]&&(r=!0),r}},{key:\"setMuted\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};this.muted!==e&&this.track(e?\"mute\":\"unmute\",{macros:t}),this.muted=e}},{key:\"setPaused\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};this.paused!==e&&this.track(e?\"pause\":\"resume\",{macros:t}),this.paused=e}},{key:\"setFullscreen\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};this.fullscreen!==e&&this.track(e?\"fullscreen\":\"exitFullscreen\",{macros:t}),this.fullscreen=e}},{key:\"setExpand\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};this.expanded!==e&&(this.track(e?\"expand\":\"collapse\",{macros:t}),this.track(e?\"playerExpand\":\"playerCollapse\",{macros:t})),this.expanded=e}},{key:\"setSkipDelay\",value:function(e){\"number\"==typeof e&&(this.skipDelay=e)}},{key:\"trackImpression\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.impressed||(this.impressed=!0,this.trackURLs(this.ad.impressionURLTemplates,e),this.track(\"creativeView\",{macros:e}))}},{key:\"error\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},t=arguments.length>1&&void 0!==arguments[1]&&arguments[1];this.trackURLs(this.ad.errorURLTemplates,e,{isCustomCode:t})}},{key:\"errorWithCode\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]&&arguments[1];this.error({ERRORCODE:e},t)}},{key:\"complete\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"complete\",{macros:e})}},{key:\"notUsed\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"notUsed\",{macros:e}),this.trackingEvents=[]}},{key:\"otherAdInteraction\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"otherAdInteraction\",{macros:e})}},{key:\"acceptInvitation\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"acceptInvitation\",{macros:e})}},{key:\"adExpand\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"adExpand\",{macros:e})}},{key:\"adCollapse\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"adCollapse\",{macros:e})}},{key:\"minimize\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"minimize\",{macros:e})}},{key:\"verificationNotExecuted\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(!this.ad||!this.ad.adVerifications||!this.ad.adVerifications.length)throw new Error(\"No adVerifications provided\");if(!e)throw new Error(\"No vendor provided, unable to find associated verificationNotExecuted\");var i=this.ad.adVerifications.find((function(t){return t.vendor===e}));if(!i)throw new Error(\"No associated verification element found for vendor: \".concat(e));var r=i.trackingEvents;if(r&&r.verificationNotExecuted){var n=r.verificationNotExecuted;this.trackURLs(n,t),this.emit(\"verificationNotExecuted\",{trackingURLTemplates:n})}}},{key:\"overlayViewDuration\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};t.ADPLAYHEAD=e,this.track(\"overlayViewDuration\",{macros:t})}},{key:\"close\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(this.linear?\"closeLinear\":\"close\",{macros:e})}},{key:\"skip\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"skip\",{macros:e})}},{key:\"load\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.track(\"loaded\",{macros:e})}},{key:\"click\",value:function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:null,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};this.clickTrackingURLTemplates&&this.clickTrackingURLTemplates.length&&this.trackURLs(this.clickTrackingURLTemplates,t);var i=this.clickThroughURLTemplate||e,r=o({},t);if(i){this.progress&&(r.ADPLAYHEAD=this.progressFormatted());var n=R.resolveURLTemplates([i],r)[0];this.emit(\"clickthrough\",n)}}},{key:\"track\",value:function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},i=t.macros,r=void 0===i?{}:i,n=t.once,a=void 0!==n&&n;\"closeLinear\"===e&&!this.trackingEvents[e]&&this.trackingEvents.close&&(e=\"close\");var s=this.trackingEvents[e],o=this.emitAlwaysEvents.indexOf(e)>-1;s?(this.emit(e,{trackingURLTemplates:s}),this.trackURLs(s,r)):o&&this.emit(e,null),a&&(delete this.trackingEvents[e],o&&this.emitAlwaysEvents.splice(this.emitAlwaysEvents.indexOf(e),1))}},{key:\"trackURLs\",value:function(e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},i=o({},arguments.length>1&&void 0!==arguments[1]?arguments[1]:{});this.linear&&(this.creative&&this.creative.mediaFiles&&this.creative.mediaFiles[0]&&this.creative.mediaFiles[0].fileURL&&(i.ASSETURI=this.creative.mediaFiles[0].fileURL),this.progress&&(i.ADPLAYHEAD=this.progressFormatted())),this.creative&&this.creative.universalAdId&&this.creative.universalAdId.idRegistry&&this.creative.universalAdId.value&&(i.UNIVERSALADID=\"\".concat(this.creative.universalAdId.idRegistry,\" \").concat(this.creative.universalAdId.value)),this.ad&&(this.ad.sequence&&(i.PODSEQUENCE=this.ad.sequence),this.ad.adType&&(i.ADTYPE=this.ad.adType),this.ad.adServingId&&(i.ADSERVINGID=this.ad.adServingId),this.ad.categories&&this.ad.categories.length&&(i.ADCATEGORIES=this.ad.categories.map((function(e){return e.value})).join(\",\")),this.ad.blockedAdCategories&&this.ad.blockedAdCategories.length&&(i.BLOCKEDADCATEGORIES=this.ad.blockedAdCategories)),R.track(e,i,t)}},{key:\"convertToTimecode\",value:function(e){var t=1e3*e,i=Math.floor(t/36e5),r=Math.floor(t/6e4%60),n=Math.floor(t/1e3%60),a=Math.floor(t%1e3);return\"\".concat(R.leftpad(i,2),\":\").concat(R.leftpad(r,2),\":\").concat(R.leftpad(n,2),\".\").concat(R.leftpad(a,3))}},{key:\"progressFormatted\",value:function(){return this.convertToTimecode(this.progress)}}]),r}(G);e.VASTClient=de,e.VASTParser=ae,e.VASTTracker=ue,Object.defineProperty(e,\"__esModule\",{value:!0})}(t)}},t={};function i(r){var n=t[r];if(void 0!==n)return n.exports;var a=t[r]={exports:{}};return e[r].call(a.exports,a,a.exports,i),a.exports}i.d=(e,t)=>{for(var r in t)i.o(t,r)&&!i.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t);var r={};(()=>{i.d(r,{h:()=>a});var e=i(686);const t=function(e,t,i){this.errorCode=e,this.message=t,this.innerError=i};t.prototype.getErrorCode=function(){return this.errorCode},t.prototype.getMessage=function(){return this.message},t.prototype.getInnerError=function(){return this.innerError instanceof Object?this.innerError:null},t.prototype.formatMessage=function(...e){return this.message=function(e,...t){try{t.forEach((function(t,i){e=e.replace(new RegExp(\"\\\\{\"+i+\"}\",\"g\"),t)}))}catch(e){}return e}(this.message,e),this},t.prototype.toString=function(){return\"AdError \"+this.getErrorCode()+\": \"+this.getMessage()+(null!=this.getInnerError()?\" Caused by: \"+this.getInnerError():\"\")};const n=t,a=function(e){if(!(e instanceof Element||e instanceof HTMLDocument))throw new Error(\"ad container is not defined\");this._adContainer=e,this._slot=null,this._videoSlot=null,this.createSlot(),this.EVENTS={AdsManagerLoaded:\"AdsManagerLoaded\",AdStarted:\"AdStarted\",AdStopped:\"AdStopped\",AdSkipped:\"AdSkipped\",AdLoaded:\"AdLoaded\",AdLinearChange:\"AdLinearChange\",AdSizeChange:\"AdSizeChange\",AdExpandedChange:\"AdExpandedChange\",AdSkippableStateChange:\"AdSkippableStateChange\",AdDurationChange:\"AdDurationChange\",AdRemainingTimeChange:\"AdRemainingTimeChange\",AdVolumeChange:\"AdVolumeChange\",AdImpression:\"AdImpression\",AdClickThru:\"AdClickThru\",AdInteraction:\"AdInteraction\",AdVideoStart:\"AdVideoStart\",AdVideoFirstQuartile:\"AdVideoFirstQuartile\",AdVideoMidpoint:\"AdVideoMidpoint\",AdVideoThirdQuartile:\"AdVideoThirdQuartile\",AdVideoComplete:\"AdVideoComplete\",AdUserAcceptInvitation:\"AdUserAcceptInvitation\",AdUserMinimize:\"AdUserMinimize\",AdUserClose:\"AdUserClose\",AdPaused:\"AdPaused\",AdPlaying:\"AdPlaying\",AdError:\"AdError\",AdLog:\"AdLog\",AllAdsCompleted:\"AllAdsCompleted\"},this._eventCallbacks={},this._creativeEventCallbacks={},this._attributes={width:300,height:154,viewMode:\"normal\",desiredBitrate:268,duration:10,remainingTime:10,currentTime:0,volume:0,version:\"1.1.3\"},this._quartileEvents=[{event:\"AdImpression\",value:0},{event:\"AdVideoStart\",value:0},{event:\"AdVideoFirstQuartile\",value:25},{event:\"AdVideoMidpoint\",value:50},{event:\"AdVideoThirdQuartile\",value:75},{event:\"AdVideoComplete\",value:100}],this._nextQuartileIndex=0,this._defaultEventCallbacks={AdImpression:this.onAdImpression.bind(this),AdVideoStart:this.onAdVideoStart.bind(this),AdVideoFirstQuartile:this.onAdVideoFirstQuartile.bind(this),AdVideoMidpoint:this.onAdVideoMidpoint.bind(this),AdVideoThirdQuartile:this.onAdVideoThirdQuartile.bind(this),AdVideoComplete:this.onAdVideoComplete.bind(this)},this._options={autoplay:!0,muted:!0,vastLoadTimeout:23e3,loadVideoTimeout:8e3,withCredentials:!1,wrapperLimit:10,resolveAll:!0},this.ERROR_CODES={ADS_REQUEST_NETWORK_ERROR:1012,FAILED_TO_REQUEST_ADS:1005,UNKNOWN_AD_RESPONSE:1010,VAST_ASSET_NOT_FOUND:1007,VAST_EMPTY_RESPONSE:1009,VAST_LINEAR_ASSET_MISMATCH:403,VAST_LOAD_TIMEOUT:301,VAST_MEDIA_LOAD_TIMEOUT:402,VIDEO_PLAY_ERROR:400,VPAID_ERROR:901},this.ERROR_MESSAGES={ADS_REQUEST_ERROR:\"Unable to request ads from server. Cause: {0}.\",ADS_REQUEST_NETWORK_ERROR:\"Unable to request ads from server due to network error.\",FAILED_TO_REQUEST_ADS:\"The was a problem requesting ads from the server.\",NO_ADS_FOUND:\"The response does not contain any valid ads.\",UNKNOWN_AD_RESPONSE:\"The ad response was not understood and cannot be parsed.\",VAST_ASSET_NOT_FOUND:\"No assets were found in the VAST ad response.\",VAST_EMPTY_RESPONSE:\"The VAST response document is empty.\",VAST_LINEAR_ASSET_MISMATCH:\"Linear assets were found in the VAST ad response, but none of them matched the player's capabilities.\",VAST_LOAD_TIMEOUT:\"Ad request reached a timeout.\",VAST_MEDIA_LOAD_TIMEOUT:\"VAST media file loading reached a timeout of {0} seconds.\",VIDEO_PLAY_ERROR:\"There was an error playing the video ad.\",VPAID_CREATIVE_ERROR:\"An unexpected error occurred within the VPAID creative. Refer to the inner error for more info.\"},this.ERRORS={VAST_EMPTY_RESPONSE:new n(this.ERROR_CODES.VAST_EMPTY_RESPONSE,this.ERROR_MESSAGES.VAST_EMPTY_RESPONSE),VAST_ASSET_NOT_FOUND:new n(this.ERROR_CODES.VAST_ASSET_NOT_FOUND,this.ERROR_MESSAGES.VAST_ASSET_NOT_FOUND),VAST_LINEAR_ASSET_MISMATCH:new n(this.ERROR_CODES.VAST_LINEAR_ASSET_MISMATCH,this.ERROR_MESSAGES.VAST_LINEAR_ASSET_MISMATCH),VAST_LOAD_TIMEOUT:new n(this.ERROR_CODES.VAST_LOAD_TIMEOUT,this.ERROR_MESSAGES.VAST_LOAD_TIMEOUT),VAST_MEDIA_LOAD_TIMEOUT:new n(this.ERROR_CODES.VAST_MEDIA_LOAD_TIMEOUT,this.ERROR_MESSAGES.VAST_MEDIA_LOAD_TIMEOUT),VIDEO_PLAY_ERROR:new n(this.ERROR_CODES.VIDEO_PLAY_ERROR,this.ERROR_MESSAGES.VIDEO_PLAY_ERROR)},this._vastClient=null,this._vastParser=null,this._vastTracker=null,this._ad=null,this._adPod=null,this._creative=null,this._mediaFiles=null,this._mediaFileIndex=0,this._mediaFile=null,this._isVPAID=!1,this._vpaidCreative=null,this._vastMediaLoadTimeoutId=null,this._vpaidProgressCounter=null,this.SUPPORTED_CREATIVE_VPAID_VERSION_MIN=2,this._hasLoaded=!1,this._hasError=!1,this._hasImpression=!1,this._hasStarted=!1};a.prototype.createSlot=function(){this._slot=document.createElement(\"div\"),this._slot.style.position=\"absolute\",this._slot.style.display=\"none\",this._adContainer.appendChild(this._slot),this.createVideoSlot()},a.prototype.removeSlot=function(){this._slot.parentNode.removeChild(this._slot),this.createSlot()},a.prototype.showSlot=function(){\"\"===this._videoSlot.src&&this.hideVideoSlot(),this._slot.style.display=\"block\"},a.prototype.resizeSlot=function(e,t){this._slot.style.width=e+\"px\",this._slot.style.height=t+\"px\"},a.prototype.createVideoSlot=function(){this._videoSlot=document.createElement(\"video\"),this._videoSlot.setAttribute(\"webkit-playsinline\",!0),this._videoSlot.setAttribute(\"playsinline\",!0),this._videoSlot.style.width=\"100%\",this._videoSlot.style.height=\"100%\",this._videoSlot.style.backgroundColor=\"rgb(0, 0, 0)\",this._slot.appendChild(this._videoSlot)},a.prototype.hideVideoSlot=function(){this._videoSlot.style.display=\"none\"},a.prototype.stopVASTMediaLoadTimeout=function(){this._vastMediaLoadTimeoutId&&(clearTimeout(this._vastMediaLoadTimeoutId),this._vastMediaLoadTimeoutId=null)},a.prototype.startVASTMediaLoadTimeout=function(){this.stopVASTMediaLoadTimeout(),this._vastMediaLoadTimeoutId=setTimeout((()=>{this.onAdError(this.ERRORS.VAST_MEDIA_LOAD_TIMEOUT.formatMessage(this._options.loadVideoTimeout))}),this._options.loadVideoTimeout)},a.prototype.updateVPAIDProgress=function(){this._attributes.remainingTime=this._isCreativeFunctionInvokable(\"getAdRemainingTime\")?this._vpaidCreative.getAdRemainingTime():-1,isNaN(this._attributes.remainingTime)||1===this._attributes.remainingTime||(this._attributes.currentTime=this._attributes.duration-this._attributes.remainingTime,this._vastTracker.setProgress(this._attributes.currentTime))},a.prototype.startVPAIDProgress=function(){this.stopVPAIDProgress(),this._vpaidProgressCounter=setInterval((()=>{this._isVPAID&&this._vpaidCreative&&this._vastTracker?this.updateVPAIDProgress():this.stopVPAIDProgress()}),1e3)},a.prototype.stopVPAIDProgress=function(){this._vpaidProgressCounter&&(clearInterval(this._vpaidProgressCounter),this._vpaidProgressCounter=null)},a.prototype.addEventListener=function(e,t,i){const r=t.bind(i);this._eventCallbacks[e]=r},a.prototype.removeEventListener=function(e){this._eventCallbacks[e]=null},a.prototype.onAdsManagerLoaded=function(){this.EVENTS.AdsManagerLoaded in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdsManagerLoaded]&&this._eventCallbacks[this.EVENTS.AdsManagerLoaded]()},a.prototype.onAdLoaded=function(){this.stopVASTMediaLoadTimeout(),this.EVENTS.AdLoaded in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdLoaded]&&this._eventCallbacks[this.EVENTS.AdLoaded](this._creative)},a.prototype.onAdDurationChange=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&(this._attributes.duration=this._isCreativeFunctionInvokable(\"getAdDuration\")?this._vpaidCreative.getAdDuration():-1,-1!==this._attributes.duration&&this._vastTracker.setDuration(this._attributes.duration)),this.EVENTS.AdDurationChange in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdDurationChange]&&this._eventCallbacks[this.EVENTS.AdDurationChange]()},a.prototype.onAdSizeChange=function(){this.EVENTS.AdSizeChange in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdSizeChange]&&this._eventCallbacks[this.EVENTS.AdSizeChange]()},a.prototype.onAdStarted=function(){this.showSlot(),this.EVENTS.AdStarted in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdStarted]&&this._eventCallbacks[this.EVENTS.AdStarted]()},a.prototype.onAdVideoStart=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this.updateVPAIDProgress(),this.EVENTS.AdVideoStart in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVideoStart]&&this._eventCallbacks[this.EVENTS.AdVideoStart]()},a.prototype.onAdStopped=function(){this.EVENTS.AdStopped in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdStopped]&&this._eventCallbacks[this.EVENTS.AdStopped](),this.destroyAd()},a.prototype.onAdSkipped=function(){this.EVENTS.AdSkipped in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdSkipped]&&this._eventCallbacks[this.EVENTS.AdSkipped](),this.destroyAd()},a.prototype.onAdVolumeChange=function(){this.EVENTS.AdVolumeChange in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVolumeChange]&&this._eventCallbacks[this.EVENTS.AdVolumeChange]()},a.prototype.onAdImpression=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&(this._hasImpression||(this._attributes.duration=this._isCreativeFunctionInvokable(\"getAdDuration\")?this._vpaidCreative.getAdDuration():-1,-1!==this._attributes.duration&&this._vastTracker.setDuration(this._attributes.duration),this._vastTracker.trackImpression(),this.startVPAIDProgress(),this._hasImpression=!0)),this.EVENTS.AdImpression in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdImpression]&&this._eventCallbacks[this.EVENTS.AdImpression]()},a.prototype.onAdClickThru=function(e,t,i){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this._vastTracker.click(),this.EVENTS.AdClickThru in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdClickThru]&&this._eventCallbacks[this.EVENTS.AdClickThru](e,t,i)},a.prototype.onAdVideoFirstQuartile=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this.updateVPAIDProgress(),this.EVENTS.AdVideoFirstQuartile in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVideoFirstQuartile]&&this._eventCallbacks[this.EVENTS.AdVideoFirstQuartile]()},a.prototype.onAdVideoMidpoint=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this.updateVPAIDProgress(),this.EVENTS.AdVideoMidpoint in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVideoMidpoint]&&this._eventCallbacks[this.EVENTS.AdVideoMidpoint]()},a.prototype.onAdVideoThirdQuartile=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this.updateVPAIDProgress(),this.EVENTS.AdVideoThirdQuartile in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVideoThirdQuartile]&&this._eventCallbacks[this.EVENTS.AdVideoThirdQuartile]()},a.prototype.onAdPaused=function(){this._vastTracker&&this._vastTracker.setPaused(!0),this.EVENTS.AdPaused in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdPaused]&&this._eventCallbacks[this.EVENTS.AdPaused]()},a.prototype.onAdPlaying=function(){this._vastTracker&&this._vastTracker.setPaused(!1),this.EVENTS.AdPlaying in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdPlaying]&&this._eventCallbacks[this.EVENTS.AdPlaying]()},a.prototype.onAdVideoComplete=function(){this._isVPAID&&this._vpaidCreative&&this._vastTracker&&this._vastTracker.complete(),this.EVENTS.AdVideoComplete in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdVideoComplete]&&this._eventCallbacks[this.EVENTS.AdVideoComplete]()},a.prototype.onAllAdsCompleted=function(){this.EVENTS.AllAdsCompleted in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AllAdsCompleted]&&this._eventCallbacks[this.EVENTS.AllAdsCompleted]()},a.prototype.onAdError=function(e){this._hasError=!0,this.stopVASTMediaLoadTimeout(),this.stopVPAIDProgress(),this.EVENTS.AdError in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdError]&&this._eventCallbacks[this.EVENTS.AdError](e)},a.prototype.onAdLog=function(e){this.EVENTS.AdLog in this._eventCallbacks&&\"function\"==typeof this._eventCallbacks[this.EVENTS.AdLog]&&this._eventCallbacks[this.EVENTS.AdLog](e)},a.prototype.processVASTResponse=function(t){const i=t.ads;0!=i.length?(i.length>1?(this._adPod=i.sort((function(e,t){let i=e.sequence,r=t.sequence;return i===r?0:null===i?1:null===r||i<r?-1:i>r?1:0})),this._ad=i[0]):this._ad=i[0],this._ad&&(this._creative=i[0].creatives.filter((e=>\"linear\"===e.type))[0],this._creative&&(0!=this._creative.mediaFiles.length?(this._mediaFiles=this._creative.mediaFiles.filter((e=>this.canPlayVideoType(e.mimeType)||\"application/javascript\"===e.mimeType?e:void 0)),this._mediaFiles.sort((function(e,t){let i=e.height,r=t.height;return i<r?-1:i>r?1:0})),this._mediaFiles&&0!=this._mediaFiles.length?(this._vastTracker=new e.VASTTracker(null,this._ad,this._creative),this._vastTracker.load(),this.onAdsManagerLoaded()):this.onAdError(this.ERRORS.VAST_LINEAR_ASSET_MISMATCH)):this.onAdError(this.ERRORS.VAST_ASSET_NOT_FOUND)))):this.onAdError(this.ERRORS.VAST_EMPTY_RESPONSE)},a.prototype.requestAds=function(t,i={}){Object.assign(this._options,i);const r={timeout:this._options.vastLoadTimeout,withCredentials:this._options.withCredentials,wrapperLimit:this._options.wrapperLimit,resolveAll:this._options.resolveAll};if(this.destroy(),t&&\"string\"==typeof t){let i=!1;try{new URL(t),i=!0}catch(e){}if(i)this._vastClient=new e.VASTClient,this._vastClient.get(t,r).then((e=>{this.processVASTResponse(e)})).catch((e=>{this.onAdError(e.message)}));else{const i=(new window.DOMParser).parseFromString(t,\"text/xml\");this._vastParser=new e.VASTParser,this._vastParser.parseVAST(i,r).then((e=>{this.processVASTResponse(e)})).catch((e=>{this.onAdError(e.message)}))}}else this.onAdError(\"VAST URL/XML is empty\")},a.prototype.canPlayVideoType=function(e){return!(\"video/3gpp\"!==e||!this.supportsThreeGPVideo())||(!(\"video/webm\"!==e||!this.supportsWebmVideo())||(!(\"video/ogg\"!==e||!this.supportsOggTheoraVideo())||!(\"video/mp4\"!==e||!this.supportsH264BaselineVideo())))},a.prototype.supportsVideo=function(){return!!document.createElement(\"video\").canPlayType},a.prototype.supportsH264BaselineVideo=function(){return!!this.supportsVideo()&&document.createElement(\"video\").canPlayType('video/mp4; codecs=\"avc1.42E01E, mp4a.40.2\"')},a.prototype.supportsOggTheoraVideo=function(){return!!this.supportsVideo()&&document.createElement(\"video\").canPlayType('video/ogg; codecs=\"theora, vorbis\"')},a.prototype.supportsWebmVideo=function(){return!!this.supportsVideo()&&document.createElement(\"video\").canPlayType('video/webm; codecs=\"vp8, vorbis\"')},a.prototype.supportsThreeGPVideo=function(){return!!this.supportsVideo()&&document.createElement(\"video\").canPlayType('video/3gpp; codecs=\"mp4v.20.8, samr\"')},a.prototype.handshakeVersion=function(e){return this._vpaidCreative.handshakeVersion(e)},a.prototype._isCreativeFunctionInvokable=function(e){return!!this._vpaidCreative&&((e=this._vpaidCreative[e])&&\"function\"==typeof e)},a.prototype.checkVPAIDInterface=function(e){for(var t={passed:!0,missingInterfaces:\"\"},i=e.length-1;0<=i;i--)this._isCreativeFunctionInvokable(e[i])||(t.passed=!1,t.missingInterfaces+=e[i]+\" \");return t},a.prototype.setCallbacksForCreative=function(e,t){for(var i in e)e.hasOwnProperty(i)&&this._vpaidCreative.subscribe(e[i],i,t)},a.prototype.removeCallbacksForCreative=function(e){for(var t in e)e.hasOwnProperty(t)&&this._vpaidCreative.unsubscribe(t)},a.prototype.creativeAssetLoaded=function(){var e,t=this;if((e=t.checkVPAIDInterface(\"handshakeVersion initAd startAd stopAd subscribe unsubscribe getAdLinear\".split(\" \"))).passed||t.onAdError(\"Missing interfaces in the VPAID creative: \"+e.missingInterfaces),e.passed&&function(){var e=t.handshakeVersion(t.SUPPORTED_CREATIVE_VPAID_VERSION_MIN.toFixed(1));return e?!(parseFloat(e)<t.SUPPORTED_CREATIVE_VPAID_VERSION_MIN)||(t.onAdError(\"Only support creatives with VPAID version >= \"+t.SUPPORTED_CREATIVE_VPAID_VERSION_MIN.toFixed(1)),!1):(t.onAdError(\"Cannot get VPAID version from the creative\"),!1)}()){this._creativeEventCallbacks={AdStarted:this.onAdStarted,AdStopped:this.onAdStopped,AdSkipped:this.onAdSkipped,AdLoaded:this.onAdLoaded,AdSizeChange:this.onAdSizeChange,AdDurationChange:this.onAdDurationChange,AdVolumeChange:this.onAdVolumeChange,AdImpression:this.onAdImpression,AdClickThru:this.onAdClickThru,AdVideoStart:this.onAdVideoStart,AdVideoFirstQuartile:this.onAdVideoFirstQuartile,AdVideoMidpoint:this.onAdVideoMidpoint,AdVideoThirdQuartile:this.onAdVideoThirdQuartile,AdVideoComplete:this.onAdVideoComplete,AdPaused:this.onAdPaused,AdPlaying:this.onAdPlaying,AdError:this.onAdError,AdLog:this.onAdLog},this.setCallbacksForCreative(this._creativeEventCallbacks,this);const e=this._attributes.width,t=this._attributes.height,i={AdParameters:this._creative.adParameters},r={slot:this._slot,videoSlot:this._videoSlot,videoSlotCanAutoPlay:!0};this.startVASTMediaLoadTimeout(),this._vpaidCreative.initAd(e,t,this._attributes.viewMode,this._attributes.desiredBitrate,i,r)}},a.prototype.loadCreativeAsset=function(e){const t=document.getElementById(\"vpaidIframe\"),i=document.createElement(\"iframe\");i.id=\"vpaidIframe\",null==t?this._adContainer.appendChild(i):this._adContainer.replaceChild(i,t),i.width=0,i.height=0,i.style.display=\"none\",i.setAttribute(\"allowfullscreen\",\"\"),i.setAttribute(\"sandbox\",\"allow-scripts allow-same-origin\"),i.setAttribute(\"allow\",\"autoplay;\"),i.tabIndex=-1,i.contentWindow.document.open(),i.contentWindow.document.write('<script type=\"text/javascript\" src=\"'+e+'\"> <\\/script>'),i.contentWindow.document.close(),this._loadIntervalTimer=setInterval((()=>{let e=document.getElementById(\"vpaidIframe\").contentWindow.getVPAIDAd;e&&\"function\"==typeof e&&(clearInterval(this._loadIntervalTimer),e=e(),void 0===e||null==e||(this._vpaidCreative=e,this.creativeAssetLoaded()))}),200)},a.prototype.removeCreativeAsset=function(){const e=document.getElementById(\"vpaidIframe\");e&&e.parentNode.removeChild(e)},a.prototype.destroyAd=function(){this.destroy(),this.onAllAdsCompleted()},a.prototype.isCreativeExists=function(){return this._creative&&0!=this._creative.mediaFiles.length},a.prototype.init=function(e,t,i){this.isCreativeExists()?(this._mediaFileIndex=this._mediaFiles.findIndex((function(e){return e.height>=t})),-1!=this._mediaFileIndex?this._mediaFile=this._mediaFiles[this._mediaFileIndex]:this._mediaFile=this._mediaFiles[this._mediaFiles.length-1],this._mediaFile&&(\"application/javascript\"===this._mediaFile.mimeType&&(this._isVPAID=!0),this._attributes.width=e,this._attributes.height=t,this._attributes.viewMode=i,this.resizeSlot(this._attributes.width,this._attributes.height),this._videoSlot.addEventListener(\"error\",(()=>{this.onAdError(this.ERRORS.VIDEO_PLAY_ERROR)}),!1),this._isVPAID?this.loadCreativeAsset(this._mediaFile.fileURL):(this._slot.addEventListener(\"click\",(()=>{!this._isVPAID&&this._vastTracker&&this._vastTracker.click()})),this._videoSlot.addEventListener(\"canplay\",(()=>{})),this._videoSlot.addEventListener(\"volumechange\",(e=>{this._vastTracker&&this._vastTracker.setMuted(e.target.muted)})),this._videoSlot.addEventListener(\"timeupdate\",(e=>{if(this.isCreativeExists()){if(this._nextQuartileIndex>=this._quartileEvents.length)return;const t=100*e.target.currentTime/e.target.duration;if(t>=this._quartileEvents[this._nextQuartileIndex].value){const e=this._quartileEvents[this._nextQuartileIndex].event;this._defaultEventCallbacks[e](),this._nextQuartileIndex+=1}t>=0&&(this._hasImpression||(this._vastTracker&&this._vastTracker.trackImpression(),this._hasImpression=!0)),this._vastTracker&&this._vastTracker.setProgress(e.target.currentTime),e.target.duration>0&&(this._attributes.remainingTime=e.target.duration-e.target.currentTime)}}),!0),this._videoSlot.addEventListener(\"loadedmetadata\",(e=>{this._attributes.duration=e.target.duration,this._vastTracker&&this._vastTracker.setDuration(e.target.duration),this.onAdDurationChange()})),this._videoSlot.addEventListener(\"ended\",(()=>{this._vastTracker&&this._vastTracker.complete(),this.onAdStopped()})),this._videoSlot.setAttribute(\"src\",this._mediaFile.fileURL),this.onAdLoaded()),this._vastTracker&&this._vastTracker.on(\"clickthrough\",(e=>{this._isVPAID||this.onAdClickThru(e);const t=window.open(e,\"_blank\");void 0!==t?t.focus():window.location.href=e})))):this.onAdError(\"\")},a.prototype.start=function(){this.isCreativeExists()&&(this._videoSlot.muted=this._options.muted,this._isVPAID?this._isCreativeFunctionInvokable(\"startAd\")&&this._vpaidCreative.startAd():(this._videoSlot.load(),this._videoSlot.play(),this.onAdStarted()))},a.prototype.getDuration=function(){return this.isCreativeExists()&&this._attributes.duration},a.prototype.pause=function(){this.isCreativeExists()&&(this._isVPAID?this._isCreativeFunctionInvokable(\"pauseAd\")&&this._vpaidCreative.pauseAd():(this._videoSlot.pause(),this.onAdPaused()))},a.prototype.resume=function(){this.isCreativeExists()&&(this._isVPAID?this._isCreativeFunctionInvokable(\"resumeAd\")&&this._vpaidCreative.resumeAd():(this._videoSlot.play(),this.onAdPlaying()))},a.prototype.stop=function(){this.isCreativeExists()&&(this._isVPAID?this._isCreativeFunctionInvokable(\"stopAd\")&&this._vpaidCreative.stopAd():this.onAdStopped())},a.prototype.skip=function(){this.isCreativeExists()&&(this._isVPAID?this._isCreativeFunctionInvokable(\"skipAd\")&&this._vpaidCreative.skipAd():this.onAdSkipped())},a.prototype.resize=function(e,t,i){this.isCreativeExists()&&(this._attributes.width=e,this._attributes.height=t,this._attributes.viewMode=i,this.resizeSlot(this._attributes.width,this._attributes.height),this._isVPAID?this._isCreativeFunctionInvokable(\"resizeAd\")&&this._vpaidCreative.resizeAd(e,t,i):this.onAdSizeChange())},a.prototype.getVolume=function(){if(this.isCreativeExists())return this._isVPAID?this._isCreativeFunctionInvokable(\"getAdVolume\")?this._vpaidCreative.getAdVolume():-1:this._videoSlot.volume},a.prototype.setVolume=function(e){if(this.isCreativeExists())if(this._isVPAID)this._isCreativeFunctionInvokable(\"setAdVolume\")&&this._vpaidCreative.setAdVolume(e);else{e!==this._videoSlot.volume&&(this._attributes.volume=e,this._videoSlot.volume=e,this.onAdVolumeChange())}},a.prototype.getRemainingTime=function(){if(this.isCreativeExists())return this._isVPAID?this._isCreativeFunctionInvokable(\"getAdRemainingTime\")?this._vpaidCreative.getAdRemainingTime():-1:this._attributes.remainingTime},a.prototype.collapse=function(){this.isCreativeExists()&&this._isVPAID&&this._isCreativeFunctionInvokable(\"collapseAd\")&&this._vpaidCreative.collapseAd()},a.prototype.expand=function(){this.isCreativeExists()&&this._isVPAID&&this._isCreativeFunctionInvokable(\"expandAd\")&&this._vpaidCreative.expandAd()},a.prototype.destroy=function(){this.isCreativeExists(),this.stopVASTMediaLoadTimeout(),this.stopVPAIDProgress(),this._isVPAID&&(this.removeCallbacksForCreative(this._creativeEventCallbacks),this.removeCreativeAsset()),this._nextQuartileIndex=0,this._isVPAID=!1,this._hasLoaded=!1,this._hasError=!1,this._hasImpression=!1,this._hasStarted=!1,this._ad=null,this._creative=null,this._mediaFile=null,this._vpaidCreative=null,this._vastTracker=null,this.removeSlot()},a.prototype.getVersion=function(){return this._attributes.version}})();var n=r.h;\n\n//# sourceURL=webpack://adserve/./node_modules/ads-manager/dist/ads-manager.es.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/api.js":
/*!*****************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/api.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n  MIT License http://www.opensource.org/licenses/mit-license.php\n  Author Tobias Koppers @sokra\n*/\n// css base code, injected by the css-loader\n// eslint-disable-next-line func-names\nmodule.exports = function (cssWithMappingToString) {\n  var list = []; // return the list of modules as css string\n\n  list.toString = function toString() {\n    return this.map(function (item) {\n      var content = cssWithMappingToString(item);\n\n      if (item[2]) {\n        return \"@media \".concat(item[2], \" {\").concat(content, \"}\");\n      }\n\n      return content;\n    }).join(\"\");\n  }; // import a list of modules into the list\n  // eslint-disable-next-line func-names\n\n\n  list.i = function (modules, mediaQuery, dedupe) {\n    if (typeof modules === \"string\") {\n      // eslint-disable-next-line no-param-reassign\n      modules = [[null, modules, \"\"]];\n    }\n\n    var alreadyImportedModules = {};\n\n    if (dedupe) {\n      for (var i = 0; i < this.length; i++) {\n        // eslint-disable-next-line prefer-destructuring\n        var id = this[i][0];\n\n        if (id != null) {\n          alreadyImportedModules[id] = true;\n        }\n      }\n    }\n\n    for (var _i = 0; _i < modules.length; _i++) {\n      var item = [].concat(modules[_i]);\n\n      if (dedupe && alreadyImportedModules[item[0]]) {\n        // eslint-disable-next-line no-continue\n        continue;\n      }\n\n      if (mediaQuery) {\n        if (!item[2]) {\n          item[2] = mediaQuery;\n        } else {\n          item[2] = \"\".concat(mediaQuery, \" and \").concat(item[2]);\n        }\n      }\n\n      list.push(item);\n    }\n  };\n\n  return list;\n};\n\n//# sourceURL=webpack://adserve/./node_modules/css-loader/dist/runtime/api.js?");

/***/ }),

/***/ "./node_modules/global/window.js":
/*!***************************************!*\
  !*** ./node_modules/global/window.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var win;\n\nif (typeof window !== \"undefined\") {\n    win = window;\n} else if (typeof __webpack_require__.g !== \"undefined\") {\n    win = __webpack_require__.g;\n} else if (typeof self !== \"undefined\"){\n    win = self;\n} else {\n    win = {};\n}\n\nmodule.exports = win;\n\n\n//# sourceURL=webpack://adserve/./node_modules/global/window.js?");

/***/ }),

/***/ "./node_modules/m3u8-parser/dist/m3u8-parser.es.js":
/*!*********************************************************!*\
  !*** ./node_modules/m3u8-parser/dist/m3u8-parser.es.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LineStream\": () => (/* binding */ LineStream),\n/* harmony export */   \"ParseStream\": () => (/* binding */ ParseStream),\n/* harmony export */   \"Parser\": () => (/* binding */ Parser)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_inheritsLoose__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/inheritsLoose */ \"./node_modules/@babel/runtime/helpers/esm/inheritsLoose.js\");\n/* harmony import */ var _videojs_vhs_utils_es_stream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @videojs/vhs-utils/es/stream.js */ \"./node_modules/@videojs/vhs-utils/es/stream.js\");\n/* harmony import */ var _babel_runtime_helpers_extends__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @babel/runtime/helpers/extends */ \"./node_modules/@babel/runtime/helpers/esm/extends.js\");\n/* harmony import */ var _babel_runtime_helpers_assertThisInitialized__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @babel/runtime/helpers/assertThisInitialized */ \"./node_modules/@babel/runtime/helpers/esm/assertThisInitialized.js\");\n/* harmony import */ var _videojs_vhs_utils_es_decode_b64_to_uint8_array_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @videojs/vhs-utils/es/decode-b64-to-uint8-array.js */ \"./node_modules/@videojs/vhs-utils/es/decode-b64-to-uint8-array.js\");\n/*! @name m3u8-parser @version 4.7.1 @license Apache-2.0 */\n\n\n\n\n\n\n/**\n * A stream that buffers string input and generates a `data` event for each\n * line.\n *\n * @class LineStream\n * @extends Stream\n */\n\nvar LineStream = /*#__PURE__*/function (_Stream) {\n  (0,_babel_runtime_helpers_inheritsLoose__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(LineStream, _Stream);\n\n  function LineStream() {\n    var _this;\n\n    _this = _Stream.call(this) || this;\n    _this.buffer = '';\n    return _this;\n  }\n  /**\n   * Add new data to be parsed.\n   *\n   * @param {string} data the text to process\n   */\n\n\n  var _proto = LineStream.prototype;\n\n  _proto.push = function push(data) {\n    var nextNewline;\n    this.buffer += data;\n    nextNewline = this.buffer.indexOf('\\n');\n\n    for (; nextNewline > -1; nextNewline = this.buffer.indexOf('\\n')) {\n      this.trigger('data', this.buffer.substring(0, nextNewline));\n      this.buffer = this.buffer.substring(nextNewline + 1);\n    }\n  };\n\n  return LineStream;\n}(_videojs_vhs_utils_es_stream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n\nvar TAB = String.fromCharCode(0x09);\n\nvar parseByterange = function parseByterange(byterangeString) {\n  // optionally match and capture 0+ digits before `@`\n  // optionally match and capture 0+ digits after `@`\n  var match = /([0-9.]*)?@?([0-9.]*)?/.exec(byterangeString || '');\n  var result = {};\n\n  if (match[1]) {\n    result.length = parseInt(match[1], 10);\n  }\n\n  if (match[2]) {\n    result.offset = parseInt(match[2], 10);\n  }\n\n  return result;\n};\n/**\n * \"forgiving\" attribute list psuedo-grammar:\n * attributes -> keyvalue (',' keyvalue)*\n * keyvalue   -> key '=' value\n * key        -> [^=]*\n * value      -> '\"' [^\"]* '\"' | [^,]*\n */\n\n\nvar attributeSeparator = function attributeSeparator() {\n  var key = '[^=]*';\n  var value = '\"[^\"]*\"|[^,]*';\n  var keyvalue = '(?:' + key + ')=(?:' + value + ')';\n  return new RegExp('(?:^|,)(' + keyvalue + ')');\n};\n/**\n * Parse attributes from a line given the separator\n *\n * @param {string} attributes the attribute line to parse\n */\n\n\nvar parseAttributes = function parseAttributes(attributes) {\n  // split the string using attributes as the separator\n  var attrs = attributes.split(attributeSeparator());\n  var result = {};\n  var i = attrs.length;\n  var attr;\n\n  while (i--) {\n    // filter out unmatched portions of the string\n    if (attrs[i] === '') {\n      continue;\n    } // split the key and value\n\n\n    attr = /([^=]*)=(.*)/.exec(attrs[i]).slice(1); // trim whitespace and remove optional quotes around the value\n\n    attr[0] = attr[0].replace(/^\\s+|\\s+$/g, '');\n    attr[1] = attr[1].replace(/^\\s+|\\s+$/g, '');\n    attr[1] = attr[1].replace(/^['\"](.*)['\"]$/g, '$1');\n    result[attr[0]] = attr[1];\n  }\n\n  return result;\n};\n/**\n * A line-level M3U8 parser event stream. It expects to receive input one\n * line at a time and performs a context-free parse of its contents. A stream\n * interpretation of a manifest can be useful if the manifest is expected to\n * be too large to fit comfortably into memory or the entirety of the input\n * is not immediately available. Otherwise, it's probably much easier to work\n * with a regular `Parser` object.\n *\n * Produces `data` events with an object that captures the parser's\n * interpretation of the input. That object has a property `tag` that is one\n * of `uri`, `comment`, or `tag`. URIs only have a single additional\n * property, `line`, which captures the entirety of the input without\n * interpretation. Comments similarly have a single additional property\n * `text` which is the input without the leading `#`.\n *\n * Tags always have a property `tagType` which is the lower-cased version of\n * the M3U8 directive without the `#EXT` or `#EXT-X-` prefix. For instance,\n * `#EXT-X-MEDIA-SEQUENCE` becomes `media-sequence` when parsed. Unrecognized\n * tags are given the tag type `unknown` and a single additional property\n * `data` with the remainder of the input.\n *\n * @class ParseStream\n * @extends Stream\n */\n\n\nvar ParseStream = /*#__PURE__*/function (_Stream) {\n  (0,_babel_runtime_helpers_inheritsLoose__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(ParseStream, _Stream);\n\n  function ParseStream() {\n    var _this;\n\n    _this = _Stream.call(this) || this;\n    _this.customParsers = [];\n    _this.tagMappers = [];\n    return _this;\n  }\n  /**\n   * Parses an additional line of input.\n   *\n   * @param {string} line a single line of an M3U8 file to parse\n   */\n\n\n  var _proto = ParseStream.prototype;\n\n  _proto.push = function push(line) {\n    var _this2 = this;\n\n    var match;\n    var event; // strip whitespace\n\n    line = line.trim();\n\n    if (line.length === 0) {\n      // ignore empty lines\n      return;\n    } // URIs\n\n\n    if (line[0] !== '#') {\n      this.trigger('data', {\n        type: 'uri',\n        uri: line\n      });\n      return;\n    } // map tags\n\n\n    var newLines = this.tagMappers.reduce(function (acc, mapper) {\n      var mappedLine = mapper(line); // skip if unchanged\n\n      if (mappedLine === line) {\n        return acc;\n      }\n\n      return acc.concat([mappedLine]);\n    }, [line]);\n    newLines.forEach(function (newLine) {\n      for (var i = 0; i < _this2.customParsers.length; i++) {\n        if (_this2.customParsers[i].call(_this2, newLine)) {\n          return;\n        }\n      } // Comments\n\n\n      if (newLine.indexOf('#EXT') !== 0) {\n        _this2.trigger('data', {\n          type: 'comment',\n          text: newLine.slice(1)\n        });\n\n        return;\n      } // strip off any carriage returns here so the regex matching\n      // doesn't have to account for them.\n\n\n      newLine = newLine.replace('\\r', ''); // Tags\n\n      match = /^#EXTM3U/.exec(newLine);\n\n      if (match) {\n        _this2.trigger('data', {\n          type: 'tag',\n          tagType: 'm3u'\n        });\n\n        return;\n      }\n\n      match = /^#EXTINF:?([0-9\\.]*)?,?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'inf'\n        };\n\n        if (match[1]) {\n          event.duration = parseFloat(match[1]);\n        }\n\n        if (match[2]) {\n          event.title = match[2];\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-TARGETDURATION:?([0-9.]*)?/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'targetduration'\n        };\n\n        if (match[1]) {\n          event.duration = parseInt(match[1], 10);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-VERSION:?([0-9.]*)?/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'version'\n        };\n\n        if (match[1]) {\n          event.version = parseInt(match[1], 10);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-MEDIA-SEQUENCE:?(\\-?[0-9.]*)?/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'media-sequence'\n        };\n\n        if (match[1]) {\n          event.number = parseInt(match[1], 10);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-DISCONTINUITY-SEQUENCE:?(\\-?[0-9.]*)?/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'discontinuity-sequence'\n        };\n\n        if (match[1]) {\n          event.number = parseInt(match[1], 10);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-PLAYLIST-TYPE:?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'playlist-type'\n        };\n\n        if (match[1]) {\n          event.playlistType = match[1];\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-BYTERANGE:?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = (0,_babel_runtime_helpers_extends__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(parseByterange(match[1]), {\n          type: 'tag',\n          tagType: 'byterange'\n        });\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-ALLOW-CACHE:?(YES|NO)?/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'allow-cache'\n        };\n\n        if (match[1]) {\n          event.allowed = !/NO/.test(match[1]);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-MAP:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'map'\n        };\n\n        if (match[1]) {\n          var attributes = parseAttributes(match[1]);\n\n          if (attributes.URI) {\n            event.uri = attributes.URI;\n          }\n\n          if (attributes.BYTERANGE) {\n            event.byterange = parseByterange(attributes.BYTERANGE);\n          }\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-STREAM-INF:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'stream-inf'\n        };\n\n        if (match[1]) {\n          event.attributes = parseAttributes(match[1]);\n\n          if (event.attributes.RESOLUTION) {\n            var split = event.attributes.RESOLUTION.split('x');\n            var resolution = {};\n\n            if (split[0]) {\n              resolution.width = parseInt(split[0], 10);\n            }\n\n            if (split[1]) {\n              resolution.height = parseInt(split[1], 10);\n            }\n\n            event.attributes.RESOLUTION = resolution;\n          }\n\n          if (event.attributes.BANDWIDTH) {\n            event.attributes.BANDWIDTH = parseInt(event.attributes.BANDWIDTH, 10);\n          }\n\n          if (event.attributes['PROGRAM-ID']) {\n            event.attributes['PROGRAM-ID'] = parseInt(event.attributes['PROGRAM-ID'], 10);\n          }\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-MEDIA:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'media'\n        };\n\n        if (match[1]) {\n          event.attributes = parseAttributes(match[1]);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-ENDLIST/.exec(newLine);\n\n      if (match) {\n        _this2.trigger('data', {\n          type: 'tag',\n          tagType: 'endlist'\n        });\n\n        return;\n      }\n\n      match = /^#EXT-X-DISCONTINUITY/.exec(newLine);\n\n      if (match) {\n        _this2.trigger('data', {\n          type: 'tag',\n          tagType: 'discontinuity'\n        });\n\n        return;\n      }\n\n      match = /^#EXT-X-PROGRAM-DATE-TIME:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'program-date-time'\n        };\n\n        if (match[1]) {\n          event.dateTimeString = match[1];\n          event.dateTimeObject = new Date(match[1]);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-KEY:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'key'\n        };\n\n        if (match[1]) {\n          event.attributes = parseAttributes(match[1]); // parse the IV string into a Uint32Array\n\n          if (event.attributes.IV) {\n            if (event.attributes.IV.substring(0, 2).toLowerCase() === '0x') {\n              event.attributes.IV = event.attributes.IV.substring(2);\n            }\n\n            event.attributes.IV = event.attributes.IV.match(/.{8}/g);\n            event.attributes.IV[0] = parseInt(event.attributes.IV[0], 16);\n            event.attributes.IV[1] = parseInt(event.attributes.IV[1], 16);\n            event.attributes.IV[2] = parseInt(event.attributes.IV[2], 16);\n            event.attributes.IV[3] = parseInt(event.attributes.IV[3], 16);\n            event.attributes.IV = new Uint32Array(event.attributes.IV);\n          }\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-START:?(.*)$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'start'\n        };\n\n        if (match[1]) {\n          event.attributes = parseAttributes(match[1]);\n          event.attributes['TIME-OFFSET'] = parseFloat(event.attributes['TIME-OFFSET']);\n          event.attributes.PRECISE = /YES/.test(event.attributes.PRECISE);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-CUE-OUT-CONT:?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'cue-out-cont'\n        };\n\n        if (match[1]) {\n          event.data = match[1];\n        } else {\n          event.data = '';\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-CUE-OUT:?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'cue-out'\n        };\n\n        if (match[1]) {\n          event.data = match[1];\n        } else {\n          event.data = '';\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-CUE-IN:?(.*)?$/.exec(newLine);\n\n      if (match) {\n        event = {\n          type: 'tag',\n          tagType: 'cue-in'\n        };\n\n        if (match[1]) {\n          event.data = match[1];\n        } else {\n          event.data = '';\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-SKIP:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'skip'\n        };\n        event.attributes = parseAttributes(match[1]);\n\n        if (event.attributes.hasOwnProperty('SKIPPED-SEGMENTS')) {\n          event.attributes['SKIPPED-SEGMENTS'] = parseInt(event.attributes['SKIPPED-SEGMENTS'], 10);\n        }\n\n        if (event.attributes.hasOwnProperty('RECENTLY-REMOVED-DATERANGES')) {\n          event.attributes['RECENTLY-REMOVED-DATERANGES'] = event.attributes['RECENTLY-REMOVED-DATERANGES'].split(TAB);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-PART:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'part'\n        };\n        event.attributes = parseAttributes(match[1]);\n        ['DURATION'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = parseFloat(event.attributes[key]);\n          }\n        });\n        ['INDEPENDENT', 'GAP'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = /YES/.test(event.attributes[key]);\n          }\n        });\n\n        if (event.attributes.hasOwnProperty('BYTERANGE')) {\n          event.attributes.byterange = parseByterange(event.attributes.BYTERANGE);\n        }\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-SERVER-CONTROL:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'server-control'\n        };\n        event.attributes = parseAttributes(match[1]);\n        ['CAN-SKIP-UNTIL', 'PART-HOLD-BACK', 'HOLD-BACK'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = parseFloat(event.attributes[key]);\n          }\n        });\n        ['CAN-SKIP-DATERANGES', 'CAN-BLOCK-RELOAD'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = /YES/.test(event.attributes[key]);\n          }\n        });\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-PART-INF:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'part-inf'\n        };\n        event.attributes = parseAttributes(match[1]);\n        ['PART-TARGET'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = parseFloat(event.attributes[key]);\n          }\n        });\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-PRELOAD-HINT:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'preload-hint'\n        };\n        event.attributes = parseAttributes(match[1]);\n        ['BYTERANGE-START', 'BYTERANGE-LENGTH'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = parseInt(event.attributes[key], 10);\n            var subkey = key === 'BYTERANGE-LENGTH' ? 'length' : 'offset';\n            event.attributes.byterange = event.attributes.byterange || {};\n            event.attributes.byterange[subkey] = event.attributes[key]; // only keep the parsed byterange object.\n\n            delete event.attributes[key];\n          }\n        });\n\n        _this2.trigger('data', event);\n\n        return;\n      }\n\n      match = /^#EXT-X-RENDITION-REPORT:(.*)$/.exec(newLine);\n\n      if (match && match[1]) {\n        event = {\n          type: 'tag',\n          tagType: 'rendition-report'\n        };\n        event.attributes = parseAttributes(match[1]);\n        ['LAST-MSN', 'LAST-PART'].forEach(function (key) {\n          if (event.attributes.hasOwnProperty(key)) {\n            event.attributes[key] = parseInt(event.attributes[key], 10);\n          }\n        });\n\n        _this2.trigger('data', event);\n\n        return;\n      } // unknown tag type\n\n\n      _this2.trigger('data', {\n        type: 'tag',\n        data: newLine.slice(4)\n      });\n    });\n  }\n  /**\n   * Add a parser for custom headers\n   *\n   * @param {Object}   options              a map of options for the added parser\n   * @param {RegExp}   options.expression   a regular expression to match the custom header\n   * @param {string}   options.customType   the custom type to register to the output\n   * @param {Function} [options.dataParser] function to parse the line into an object\n   * @param {boolean}  [options.segment]    should tag data be attached to the segment object\n   */\n  ;\n\n  _proto.addParser = function addParser(_ref) {\n    var _this3 = this;\n\n    var expression = _ref.expression,\n        customType = _ref.customType,\n        dataParser = _ref.dataParser,\n        segment = _ref.segment;\n\n    if (typeof dataParser !== 'function') {\n      dataParser = function dataParser(line) {\n        return line;\n      };\n    }\n\n    this.customParsers.push(function (line) {\n      var match = expression.exec(line);\n\n      if (match) {\n        _this3.trigger('data', {\n          type: 'custom',\n          data: dataParser(line),\n          customType: customType,\n          segment: segment\n        });\n\n        return true;\n      }\n    });\n  }\n  /**\n   * Add a custom header mapper\n   *\n   * @param {Object}   options\n   * @param {RegExp}   options.expression   a regular expression to match the custom header\n   * @param {Function} options.map          function to translate tag into a different tag\n   */\n  ;\n\n  _proto.addTagMapper = function addTagMapper(_ref2) {\n    var expression = _ref2.expression,\n        map = _ref2.map;\n\n    var mapFn = function mapFn(line) {\n      if (expression.test(line)) {\n        return map(line);\n      }\n\n      return line;\n    };\n\n    this.tagMappers.push(mapFn);\n  };\n\n  return ParseStream;\n}(_videojs_vhs_utils_es_stream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n\nvar camelCase = function camelCase(str) {\n  return str.toLowerCase().replace(/-(\\w)/g, function (a) {\n    return a[1].toUpperCase();\n  });\n};\n\nvar camelCaseKeys = function camelCaseKeys(attributes) {\n  var result = {};\n  Object.keys(attributes).forEach(function (key) {\n    result[camelCase(key)] = attributes[key];\n  });\n  return result;\n}; // set SERVER-CONTROL hold back based upon targetDuration and partTargetDuration\n// we need this helper because defaults are based upon targetDuration and\n// partTargetDuration being set, but they may not be if SERVER-CONTROL appears before\n// target durations are set.\n\n\nvar setHoldBack = function setHoldBack(manifest) {\n  var serverControl = manifest.serverControl,\n      targetDuration = manifest.targetDuration,\n      partTargetDuration = manifest.partTargetDuration;\n\n  if (!serverControl) {\n    return;\n  }\n\n  var tag = '#EXT-X-SERVER-CONTROL';\n  var hb = 'holdBack';\n  var phb = 'partHoldBack';\n  var minTargetDuration = targetDuration && targetDuration * 3;\n  var minPartDuration = partTargetDuration && partTargetDuration * 2;\n\n  if (targetDuration && !serverControl.hasOwnProperty(hb)) {\n    serverControl[hb] = minTargetDuration;\n    this.trigger('info', {\n      message: tag + \" defaulting HOLD-BACK to targetDuration * 3 (\" + minTargetDuration + \").\"\n    });\n  }\n\n  if (minTargetDuration && serverControl[hb] < minTargetDuration) {\n    this.trigger('warn', {\n      message: tag + \" clamping HOLD-BACK (\" + serverControl[hb] + \") to targetDuration * 3 (\" + minTargetDuration + \")\"\n    });\n    serverControl[hb] = minTargetDuration;\n  } // default no part hold back to part target duration * 3\n\n\n  if (partTargetDuration && !serverControl.hasOwnProperty(phb)) {\n    serverControl[phb] = partTargetDuration * 3;\n    this.trigger('info', {\n      message: tag + \" defaulting PART-HOLD-BACK to partTargetDuration * 3 (\" + serverControl[phb] + \").\"\n    });\n  } // if part hold back is too small default it to part target duration * 2\n\n\n  if (partTargetDuration && serverControl[phb] < minPartDuration) {\n    this.trigger('warn', {\n      message: tag + \" clamping PART-HOLD-BACK (\" + serverControl[phb] + \") to partTargetDuration * 2 (\" + minPartDuration + \").\"\n    });\n    serverControl[phb] = minPartDuration;\n  }\n};\n/**\n * A parser for M3U8 files. The current interpretation of the input is\n * exposed as a property `manifest` on parser objects. It's just two lines to\n * create and parse a manifest once you have the contents available as a string:\n *\n * ```js\n * var parser = new m3u8.Parser();\n * parser.push(xhr.responseText);\n * ```\n *\n * New input can later be applied to update the manifest object by calling\n * `push` again.\n *\n * The parser attempts to create a usable manifest object even if the\n * underlying input is somewhat nonsensical. It emits `info` and `warning`\n * events during the parse if it encounters input that seems invalid or\n * requires some property of the manifest object to be defaulted.\n *\n * @class Parser\n * @extends Stream\n */\n\n\nvar Parser = /*#__PURE__*/function (_Stream) {\n  (0,_babel_runtime_helpers_inheritsLoose__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Parser, _Stream);\n\n  function Parser() {\n    var _this;\n\n    _this = _Stream.call(this) || this;\n    _this.lineStream = new LineStream();\n    _this.parseStream = new ParseStream();\n\n    _this.lineStream.pipe(_this.parseStream);\n    /* eslint-disable consistent-this */\n\n\n    var self = (0,_babel_runtime_helpers_assertThisInitialized__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(_this);\n    /* eslint-enable consistent-this */\n\n\n    var uris = [];\n    var currentUri = {}; // if specified, the active EXT-X-MAP definition\n\n    var currentMap; // if specified, the active decryption key\n\n    var _key;\n\n    var hasParts = false;\n\n    var noop = function noop() {};\n\n    var defaultMediaGroups = {\n      'AUDIO': {},\n      'VIDEO': {},\n      'CLOSED-CAPTIONS': {},\n      'SUBTITLES': {}\n    }; // This is the Widevine UUID from DASH IF IOP. The same exact string is\n    // used in MPDs with Widevine encrypted streams.\n\n    var widevineUuid = 'urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed'; // group segments into numbered timelines delineated by discontinuities\n\n    var currentTimeline = 0; // the manifest is empty until the parse stream begins delivering data\n\n    _this.manifest = {\n      allowCache: true,\n      discontinuityStarts: [],\n      segments: []\n    }; // keep track of the last seen segment's byte range end, as segments are not required\n    // to provide the offset, in which case it defaults to the next byte after the\n    // previous segment\n\n    var lastByterangeEnd = 0; // keep track of the last seen part's byte range end.\n\n    var lastPartByterangeEnd = 0;\n\n    _this.on('end', function () {\n      // only add preloadSegment if we don't yet have a uri for it.\n      // and we actually have parts/preloadHints\n      if (currentUri.uri || !currentUri.parts && !currentUri.preloadHints) {\n        return;\n      }\n\n      if (!currentUri.map && currentMap) {\n        currentUri.map = currentMap;\n      }\n\n      if (!currentUri.key && _key) {\n        currentUri.key = _key;\n      }\n\n      if (!currentUri.timeline && typeof currentTimeline === 'number') {\n        currentUri.timeline = currentTimeline;\n      }\n\n      _this.manifest.preloadSegment = currentUri;\n    }); // update the manifest with the m3u8 entry from the parse stream\n\n\n    _this.parseStream.on('data', function (entry) {\n      var mediaGroup;\n      var rendition;\n      ({\n        tag: function tag() {\n          // switch based on the tag type\n          (({\n            version: function version() {\n              if (entry.version) {\n                this.manifest.version = entry.version;\n              }\n            },\n            'allow-cache': function allowCache() {\n              this.manifest.allowCache = entry.allowed;\n\n              if (!('allowed' in entry)) {\n                this.trigger('info', {\n                  message: 'defaulting allowCache to YES'\n                });\n                this.manifest.allowCache = true;\n              }\n            },\n            byterange: function byterange() {\n              var byterange = {};\n\n              if ('length' in entry) {\n                currentUri.byterange = byterange;\n                byterange.length = entry.length;\n\n                if (!('offset' in entry)) {\n                  /*\n                   * From the latest spec (as of this writing):\n                   * https://tools.ietf.org/html/draft-pantos-http-live-streaming-23#section-4.3.2.2\n                   *\n                   * Same text since EXT-X-BYTERANGE's introduction in draft 7:\n                   * https://tools.ietf.org/html/draft-pantos-http-live-streaming-07#section-3.3.1)\n                   *\n                   * \"If o [offset] is not present, the sub-range begins at the next byte\n                   * following the sub-range of the previous media segment.\"\n                   */\n                  entry.offset = lastByterangeEnd;\n                }\n              }\n\n              if ('offset' in entry) {\n                currentUri.byterange = byterange;\n                byterange.offset = entry.offset;\n              }\n\n              lastByterangeEnd = byterange.offset + byterange.length;\n            },\n            endlist: function endlist() {\n              this.manifest.endList = true;\n            },\n            inf: function inf() {\n              if (!('mediaSequence' in this.manifest)) {\n                this.manifest.mediaSequence = 0;\n                this.trigger('info', {\n                  message: 'defaulting media sequence to zero'\n                });\n              }\n\n              if (!('discontinuitySequence' in this.manifest)) {\n                this.manifest.discontinuitySequence = 0;\n                this.trigger('info', {\n                  message: 'defaulting discontinuity sequence to zero'\n                });\n              }\n\n              if (entry.duration > 0) {\n                currentUri.duration = entry.duration;\n              }\n\n              if (entry.duration === 0) {\n                currentUri.duration = 0.01;\n                this.trigger('info', {\n                  message: 'updating zero segment duration to a small value'\n                });\n              }\n\n              this.manifest.segments = uris;\n            },\n            key: function key() {\n              if (!entry.attributes) {\n                this.trigger('warn', {\n                  message: 'ignoring key declaration without attribute list'\n                });\n                return;\n              } // clear the active encryption key\n\n\n              if (entry.attributes.METHOD === 'NONE') {\n                _key = null;\n                return;\n              }\n\n              if (!entry.attributes.URI) {\n                this.trigger('warn', {\n                  message: 'ignoring key declaration without URI'\n                });\n                return;\n              }\n\n              if (entry.attributes.KEYFORMAT === 'com.apple.streamingkeydelivery') {\n                this.manifest.contentProtection = this.manifest.contentProtection || {}; // TODO: add full support for this.\n\n                this.manifest.contentProtection['com.apple.fps.1_0'] = {\n                  attributes: entry.attributes\n                };\n                return;\n              }\n\n              if (entry.attributes.KEYFORMAT === 'com.microsoft.playready') {\n                this.manifest.contentProtection = this.manifest.contentProtection || {}; // TODO: add full support for this.\n\n                this.manifest.contentProtection['com.microsoft.playready'] = {\n                  uri: entry.attributes.URI\n                };\n                return;\n              } // check if the content is encrypted for Widevine\n              // Widevine/HLS spec: https://storage.googleapis.com/wvdocs/Widevine_DRM_HLS.pdf\n\n\n              if (entry.attributes.KEYFORMAT === widevineUuid) {\n                var VALID_METHODS = ['SAMPLE-AES', 'SAMPLE-AES-CTR', 'SAMPLE-AES-CENC'];\n\n                if (VALID_METHODS.indexOf(entry.attributes.METHOD) === -1) {\n                  this.trigger('warn', {\n                    message: 'invalid key method provided for Widevine'\n                  });\n                  return;\n                }\n\n                if (entry.attributes.METHOD === 'SAMPLE-AES-CENC') {\n                  this.trigger('warn', {\n                    message: 'SAMPLE-AES-CENC is deprecated, please use SAMPLE-AES-CTR instead'\n                  });\n                }\n\n                if (entry.attributes.URI.substring(0, 23) !== 'data:text/plain;base64,') {\n                  this.trigger('warn', {\n                    message: 'invalid key URI provided for Widevine'\n                  });\n                  return;\n                }\n\n                if (!(entry.attributes.KEYID && entry.attributes.KEYID.substring(0, 2) === '0x')) {\n                  this.trigger('warn', {\n                    message: 'invalid key ID provided for Widevine'\n                  });\n                  return;\n                } // if Widevine key attributes are valid, store them as `contentProtection`\n                // on the manifest to emulate Widevine tag structure in a DASH mpd\n\n\n                this.manifest.contentProtection = this.manifest.contentProtection || {};\n                this.manifest.contentProtection['com.widevine.alpha'] = {\n                  attributes: {\n                    schemeIdUri: entry.attributes.KEYFORMAT,\n                    // remove '0x' from the key id string\n                    keyId: entry.attributes.KEYID.substring(2)\n                  },\n                  // decode the base64-encoded PSSH box\n                  pssh: (0,_videojs_vhs_utils_es_decode_b64_to_uint8_array_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(entry.attributes.URI.split(',')[1])\n                };\n                return;\n              }\n\n              if (!entry.attributes.METHOD) {\n                this.trigger('warn', {\n                  message: 'defaulting key method to AES-128'\n                });\n              } // setup an encryption key for upcoming segments\n\n\n              _key = {\n                method: entry.attributes.METHOD || 'AES-128',\n                uri: entry.attributes.URI\n              };\n\n              if (typeof entry.attributes.IV !== 'undefined') {\n                _key.iv = entry.attributes.IV;\n              }\n            },\n            'media-sequence': function mediaSequence() {\n              if (!isFinite(entry.number)) {\n                this.trigger('warn', {\n                  message: 'ignoring invalid media sequence: ' + entry.number\n                });\n                return;\n              }\n\n              this.manifest.mediaSequence = entry.number;\n            },\n            'discontinuity-sequence': function discontinuitySequence() {\n              if (!isFinite(entry.number)) {\n                this.trigger('warn', {\n                  message: 'ignoring invalid discontinuity sequence: ' + entry.number\n                });\n                return;\n              }\n\n              this.manifest.discontinuitySequence = entry.number;\n              currentTimeline = entry.number;\n            },\n            'playlist-type': function playlistType() {\n              if (!/VOD|EVENT/.test(entry.playlistType)) {\n                this.trigger('warn', {\n                  message: 'ignoring unknown playlist type: ' + entry.playlist\n                });\n                return;\n              }\n\n              this.manifest.playlistType = entry.playlistType;\n            },\n            map: function map() {\n              currentMap = {};\n\n              if (entry.uri) {\n                currentMap.uri = entry.uri;\n              }\n\n              if (entry.byterange) {\n                currentMap.byterange = entry.byterange;\n              }\n\n              if (_key) {\n                currentMap.key = _key;\n              }\n            },\n            'stream-inf': function streamInf() {\n              this.manifest.playlists = uris;\n              this.manifest.mediaGroups = this.manifest.mediaGroups || defaultMediaGroups;\n\n              if (!entry.attributes) {\n                this.trigger('warn', {\n                  message: 'ignoring empty stream-inf attributes'\n                });\n                return;\n              }\n\n              if (!currentUri.attributes) {\n                currentUri.attributes = {};\n              }\n\n              (0,_babel_runtime_helpers_extends__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(currentUri.attributes, entry.attributes);\n            },\n            media: function media() {\n              this.manifest.mediaGroups = this.manifest.mediaGroups || defaultMediaGroups;\n\n              if (!(entry.attributes && entry.attributes.TYPE && entry.attributes['GROUP-ID'] && entry.attributes.NAME)) {\n                this.trigger('warn', {\n                  message: 'ignoring incomplete or missing media group'\n                });\n                return;\n              } // find the media group, creating defaults as necessary\n\n\n              var mediaGroupType = this.manifest.mediaGroups[entry.attributes.TYPE];\n              mediaGroupType[entry.attributes['GROUP-ID']] = mediaGroupType[entry.attributes['GROUP-ID']] || {};\n              mediaGroup = mediaGroupType[entry.attributes['GROUP-ID']]; // collect the rendition metadata\n\n              rendition = {\n                default: /yes/i.test(entry.attributes.DEFAULT)\n              };\n\n              if (rendition.default) {\n                rendition.autoselect = true;\n              } else {\n                rendition.autoselect = /yes/i.test(entry.attributes.AUTOSELECT);\n              }\n\n              if (entry.attributes.LANGUAGE) {\n                rendition.language = entry.attributes.LANGUAGE;\n              }\n\n              if (entry.attributes.URI) {\n                rendition.uri = entry.attributes.URI;\n              }\n\n              if (entry.attributes['INSTREAM-ID']) {\n                rendition.instreamId = entry.attributes['INSTREAM-ID'];\n              }\n\n              if (entry.attributes.CHARACTERISTICS) {\n                rendition.characteristics = entry.attributes.CHARACTERISTICS;\n              }\n\n              if (entry.attributes.FORCED) {\n                rendition.forced = /yes/i.test(entry.attributes.FORCED);\n              } // insert the new rendition\n\n\n              mediaGroup[entry.attributes.NAME] = rendition;\n            },\n            discontinuity: function discontinuity() {\n              currentTimeline += 1;\n              currentUri.discontinuity = true;\n              this.manifest.discontinuityStarts.push(uris.length);\n            },\n            'program-date-time': function programDateTime() {\n              if (typeof this.manifest.dateTimeString === 'undefined') {\n                // PROGRAM-DATE-TIME is a media-segment tag, but for backwards\n                // compatibility, we add the first occurence of the PROGRAM-DATE-TIME tag\n                // to the manifest object\n                // TODO: Consider removing this in future major version\n                this.manifest.dateTimeString = entry.dateTimeString;\n                this.manifest.dateTimeObject = entry.dateTimeObject;\n              }\n\n              currentUri.dateTimeString = entry.dateTimeString;\n              currentUri.dateTimeObject = entry.dateTimeObject;\n            },\n            targetduration: function targetduration() {\n              if (!isFinite(entry.duration) || entry.duration < 0) {\n                this.trigger('warn', {\n                  message: 'ignoring invalid target duration: ' + entry.duration\n                });\n                return;\n              }\n\n              this.manifest.targetDuration = entry.duration;\n              setHoldBack.call(this, this.manifest);\n            },\n            start: function start() {\n              if (!entry.attributes || isNaN(entry.attributes['TIME-OFFSET'])) {\n                this.trigger('warn', {\n                  message: 'ignoring start declaration without appropriate attribute list'\n                });\n                return;\n              }\n\n              this.manifest.start = {\n                timeOffset: entry.attributes['TIME-OFFSET'],\n                precise: entry.attributes.PRECISE\n              };\n            },\n            'cue-out': function cueOut() {\n              currentUri.cueOut = entry.data;\n            },\n            'cue-out-cont': function cueOutCont() {\n              currentUri.cueOutCont = entry.data;\n            },\n            'cue-in': function cueIn() {\n              currentUri.cueIn = entry.data;\n            },\n            'skip': function skip() {\n              this.manifest.skip = camelCaseKeys(entry.attributes);\n              this.warnOnMissingAttributes_('#EXT-X-SKIP', entry.attributes, ['SKIPPED-SEGMENTS']);\n            },\n            'part': function part() {\n              var _this2 = this;\n\n              hasParts = true; // parts are always specifed before a segment\n\n              var segmentIndex = this.manifest.segments.length;\n              var part = camelCaseKeys(entry.attributes);\n              currentUri.parts = currentUri.parts || [];\n              currentUri.parts.push(part);\n\n              if (part.byterange) {\n                if (!part.byterange.hasOwnProperty('offset')) {\n                  part.byterange.offset = lastPartByterangeEnd;\n                }\n\n                lastPartByterangeEnd = part.byterange.offset + part.byterange.length;\n              }\n\n              var partIndex = currentUri.parts.length - 1;\n              this.warnOnMissingAttributes_(\"#EXT-X-PART #\" + partIndex + \" for segment #\" + segmentIndex, entry.attributes, ['URI', 'DURATION']);\n\n              if (this.manifest.renditionReports) {\n                this.manifest.renditionReports.forEach(function (r, i) {\n                  if (!r.hasOwnProperty('lastPart')) {\n                    _this2.trigger('warn', {\n                      message: \"#EXT-X-RENDITION-REPORT #\" + i + \" lacks required attribute(s): LAST-PART\"\n                    });\n                  }\n                });\n              }\n            },\n            'server-control': function serverControl() {\n              var attrs = this.manifest.serverControl = camelCaseKeys(entry.attributes);\n\n              if (!attrs.hasOwnProperty('canBlockReload')) {\n                attrs.canBlockReload = false;\n                this.trigger('info', {\n                  message: '#EXT-X-SERVER-CONTROL defaulting CAN-BLOCK-RELOAD to false'\n                });\n              }\n\n              setHoldBack.call(this, this.manifest);\n\n              if (attrs.canSkipDateranges && !attrs.hasOwnProperty('canSkipUntil')) {\n                this.trigger('warn', {\n                  message: '#EXT-X-SERVER-CONTROL lacks required attribute CAN-SKIP-UNTIL which is required when CAN-SKIP-DATERANGES is set'\n                });\n              }\n            },\n            'preload-hint': function preloadHint() {\n              // parts are always specifed before a segment\n              var segmentIndex = this.manifest.segments.length;\n              var hint = camelCaseKeys(entry.attributes);\n              var isPart = hint.type && hint.type === 'PART';\n              currentUri.preloadHints = currentUri.preloadHints || [];\n              currentUri.preloadHints.push(hint);\n\n              if (hint.byterange) {\n                if (!hint.byterange.hasOwnProperty('offset')) {\n                  // use last part byterange end or zero if not a part.\n                  hint.byterange.offset = isPart ? lastPartByterangeEnd : 0;\n\n                  if (isPart) {\n                    lastPartByterangeEnd = hint.byterange.offset + hint.byterange.length;\n                  }\n                }\n              }\n\n              var index = currentUri.preloadHints.length - 1;\n              this.warnOnMissingAttributes_(\"#EXT-X-PRELOAD-HINT #\" + index + \" for segment #\" + segmentIndex, entry.attributes, ['TYPE', 'URI']);\n\n              if (!hint.type) {\n                return;\n              } // search through all preload hints except for the current one for\n              // a duplicate type.\n\n\n              for (var i = 0; i < currentUri.preloadHints.length - 1; i++) {\n                var otherHint = currentUri.preloadHints[i];\n\n                if (!otherHint.type) {\n                  continue;\n                }\n\n                if (otherHint.type === hint.type) {\n                  this.trigger('warn', {\n                    message: \"#EXT-X-PRELOAD-HINT #\" + index + \" for segment #\" + segmentIndex + \" has the same TYPE \" + hint.type + \" as preload hint #\" + i\n                  });\n                }\n              }\n            },\n            'rendition-report': function renditionReport() {\n              var report = camelCaseKeys(entry.attributes);\n              this.manifest.renditionReports = this.manifest.renditionReports || [];\n              this.manifest.renditionReports.push(report);\n              var index = this.manifest.renditionReports.length - 1;\n              var required = ['LAST-MSN', 'URI'];\n\n              if (hasParts) {\n                required.push('LAST-PART');\n              }\n\n              this.warnOnMissingAttributes_(\"#EXT-X-RENDITION-REPORT #\" + index, entry.attributes, required);\n            },\n            'part-inf': function partInf() {\n              this.manifest.partInf = camelCaseKeys(entry.attributes);\n              this.warnOnMissingAttributes_('#EXT-X-PART-INF', entry.attributes, ['PART-TARGET']);\n\n              if (this.manifest.partInf.partTarget) {\n                this.manifest.partTargetDuration = this.manifest.partInf.partTarget;\n              }\n\n              setHoldBack.call(this, this.manifest);\n            }\n          })[entry.tagType] || noop).call(self);\n        },\n        uri: function uri() {\n          currentUri.uri = entry.uri;\n          uris.push(currentUri); // if no explicit duration was declared, use the target duration\n\n          if (this.manifest.targetDuration && !('duration' in currentUri)) {\n            this.trigger('warn', {\n              message: 'defaulting segment duration to the target duration'\n            });\n            currentUri.duration = this.manifest.targetDuration;\n          } // annotate with encryption information, if necessary\n\n\n          if (_key) {\n            currentUri.key = _key;\n          }\n\n          currentUri.timeline = currentTimeline; // annotate with initialization segment information, if necessary\n\n          if (currentMap) {\n            currentUri.map = currentMap;\n          } // reset the last byterange end as it needs to be 0 between parts\n\n\n          lastPartByterangeEnd = 0; // prepare for the next URI\n\n          currentUri = {};\n        },\n        comment: function comment() {// comments are not important for playback\n        },\n        custom: function custom() {\n          // if this is segment-level data attach the output to the segment\n          if (entry.segment) {\n            currentUri.custom = currentUri.custom || {};\n            currentUri.custom[entry.customType] = entry.data; // if this is manifest-level data attach to the top level manifest object\n          } else {\n            this.manifest.custom = this.manifest.custom || {};\n            this.manifest.custom[entry.customType] = entry.data;\n          }\n        }\n      })[entry.type].call(self);\n    });\n\n    return _this;\n  }\n\n  var _proto = Parser.prototype;\n\n  _proto.warnOnMissingAttributes_ = function warnOnMissingAttributes_(identifier, attributes, required) {\n    var missing = [];\n    required.forEach(function (key) {\n      if (!attributes.hasOwnProperty(key)) {\n        missing.push(key);\n      }\n    });\n\n    if (missing.length) {\n      this.trigger('warn', {\n        message: identifier + \" lacks required attribute(s): \" + missing.join(', ')\n      });\n    }\n  }\n  /**\n   * Parse the input string and update the manifest object.\n   *\n   * @param {string} chunk a potentially incomplete portion of the manifest\n   */\n  ;\n\n  _proto.push = function push(chunk) {\n    this.lineStream.push(chunk);\n  }\n  /**\n   * Flush any remaining input. This can be handy if the last line of an M3U8\n   * manifest did not contain a trailing newline but the file has been\n   * completely received.\n   */\n  ;\n\n  _proto.end = function end() {\n    // flush any buffered input\n    this.lineStream.push('\\n');\n    this.trigger('end');\n  }\n  /**\n   * Add an additional parser for non-standard tags\n   *\n   * @param {Object}   options              a map of options for the added parser\n   * @param {RegExp}   options.expression   a regular expression to match the custom header\n   * @param {string}   options.type         the type to register to the output\n   * @param {Function} [options.dataParser] function to parse the line into an object\n   * @param {boolean}  [options.segment]    should tag data be attached to the segment object\n   */\n  ;\n\n  _proto.addParser = function addParser(options) {\n    this.parseStream.addParser(options);\n  }\n  /**\n   * Add a custom header mapper\n   *\n   * @param {Object}   options\n   * @param {RegExp}   options.expression   a regular expression to match the custom header\n   * @param {Function} options.map          function to translate tag into a different tag\n   */\n  ;\n\n  _proto.addTagMapper = function addTagMapper(options) {\n    this.parseStream.addTagMapper(options);\n  };\n\n  return Parser;\n}(_videojs_vhs_utils_es_stream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n\n\n\n\n//# sourceURL=webpack://adserve/./node_modules/m3u8-parser/dist/m3u8-parser.es.js?");

/***/ }),

/***/ "./node_modules/mux.js/dist/mux.js":
/*!*****************************************!*\
  !*** ./node_modules/mux.js/dist/mux.js ***!
  \*****************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

eval("/*! @name mux.js @version 6.1.0 @license Apache-2.0 */\n(function (global, factory) {\n   true ? module.exports = factory(__webpack_require__(/*! global/window */ \"./node_modules/global/window.js\")) :\n  0;\n}(this, (function (window) { 'use strict';\n\n  function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\n  var window__default = /*#__PURE__*/_interopDefaultLegacy(window);\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   *\n   * A lightweight readable stream implemention that handles event dispatching.\n   * Objects that inherit from streams should call init in their constructors.\n   */\n\n  var Stream = function Stream() {\n    this.init = function () {\n      var listeners = {};\n      /**\n       * Add a listener for a specified event type.\n       * @param type {string} the event name\n       * @param listener {function} the callback to be invoked when an event of\n       * the specified type occurs\n       */\n\n      this.on = function (type, listener) {\n        if (!listeners[type]) {\n          listeners[type] = [];\n        }\n\n        listeners[type] = listeners[type].concat(listener);\n      };\n      /**\n       * Remove a listener for a specified event type.\n       * @param type {string} the event name\n       * @param listener {function} a function previously registered for this\n       * type of event through `on`\n       */\n\n\n      this.off = function (type, listener) {\n        var index;\n\n        if (!listeners[type]) {\n          return false;\n        }\n\n        index = listeners[type].indexOf(listener);\n        listeners[type] = listeners[type].slice();\n        listeners[type].splice(index, 1);\n        return index > -1;\n      };\n      /**\n       * Trigger an event of the specified type on this stream. Any additional\n       * arguments to this function are passed as parameters to event listeners.\n       * @param type {string} the event name\n       */\n\n\n      this.trigger = function (type) {\n        var callbacks, i, length, args;\n        callbacks = listeners[type];\n\n        if (!callbacks) {\n          return;\n        } // Slicing the arguments on every invocation of this method\n        // can add a significant amount of overhead. Avoid the\n        // intermediate object creation for the common case of a\n        // single callback argument\n\n\n        if (arguments.length === 2) {\n          length = callbacks.length;\n\n          for (i = 0; i < length; ++i) {\n            callbacks[i].call(this, arguments[1]);\n          }\n        } else {\n          args = [];\n          i = arguments.length;\n\n          for (i = 1; i < arguments.length; ++i) {\n            args.push(arguments[i]);\n          }\n\n          length = callbacks.length;\n\n          for (i = 0; i < length; ++i) {\n            callbacks[i].apply(this, args);\n          }\n        }\n      };\n      /**\n       * Destroys the stream and cleans up.\n       */\n\n\n      this.dispose = function () {\n        listeners = {};\n      };\n    };\n  };\n  /**\n   * Forwards all `data` events on this stream to the destination stream. The\n   * destination stream should provide a method `push` to receive the data\n   * events as they arrive.\n   * @param destination {stream} the stream that will receive all `data` events\n   * @param autoFlush {boolean} if false, we will not call `flush` on the destination\n   *                            when the current stream emits a 'done' event\n   * @see http://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\n   */\n\n\n  Stream.prototype.pipe = function (destination) {\n    this.on('data', function (data) {\n      destination.push(data);\n    });\n    this.on('done', function (flushSource) {\n      destination.flush(flushSource);\n    });\n    this.on('partialdone', function (flushSource) {\n      destination.partialFlush(flushSource);\n    });\n    this.on('endedtimeline', function (flushSource) {\n      destination.endTimeline(flushSource);\n    });\n    this.on('reset', function (flushSource) {\n      destination.reset(flushSource);\n    });\n    return destination;\n  }; // Default stream functions that are expected to be overridden to perform\n  // actual work. These are provided by the prototype as a sort of no-op\n  // implementation so that we don't have to check for their existence in the\n  // `pipe` function above.\n\n\n  Stream.prototype.push = function (data) {\n    this.trigger('data', data);\n  };\n\n  Stream.prototype.flush = function (flushSource) {\n    this.trigger('done', flushSource);\n  };\n\n  Stream.prototype.partialFlush = function (flushSource) {\n    this.trigger('partialdone', flushSource);\n  };\n\n  Stream.prototype.endTimeline = function (flushSource) {\n    this.trigger('endedtimeline', flushSource);\n  };\n\n  Stream.prototype.reset = function (flushSource) {\n    this.trigger('reset', flushSource);\n  };\n\n  var stream = Stream;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n  var ONE_SECOND_IN_TS$5 = 90000,\n      // 90kHz clock\n  secondsToVideoTs,\n      secondsToAudioTs,\n      videoTsToSeconds,\n      audioTsToSeconds,\n      audioTsToVideoTs,\n      videoTsToAudioTs,\n      metadataTsToSeconds;\n\n  secondsToVideoTs = function secondsToVideoTs(seconds) {\n    return seconds * ONE_SECOND_IN_TS$5;\n  };\n\n  secondsToAudioTs = function secondsToAudioTs(seconds, sampleRate) {\n    return seconds * sampleRate;\n  };\n\n  videoTsToSeconds = function videoTsToSeconds(timestamp) {\n    return timestamp / ONE_SECOND_IN_TS$5;\n  };\n\n  audioTsToSeconds = function audioTsToSeconds(timestamp, sampleRate) {\n    return timestamp / sampleRate;\n  };\n\n  audioTsToVideoTs = function audioTsToVideoTs(timestamp, sampleRate) {\n    return secondsToVideoTs(audioTsToSeconds(timestamp, sampleRate));\n  };\n\n  videoTsToAudioTs = function videoTsToAudioTs(timestamp, sampleRate) {\n    return secondsToAudioTs(videoTsToSeconds(timestamp), sampleRate);\n  };\n  /**\n   * Adjust ID3 tag or caption timing information by the timeline pts values\n   * (if keepOriginalTimestamps is false) and convert to seconds\n   */\n\n\n  metadataTsToSeconds = function metadataTsToSeconds(timestamp, timelineStartPts, keepOriginalTimestamps) {\n    return videoTsToSeconds(keepOriginalTimestamps ? timestamp : timestamp - timelineStartPts);\n  };\n\n  var clock = {\n    ONE_SECOND_IN_TS: ONE_SECOND_IN_TS$5,\n    secondsToVideoTs: secondsToVideoTs,\n    secondsToAudioTs: secondsToAudioTs,\n    videoTsToSeconds: videoTsToSeconds,\n    audioTsToSeconds: audioTsToSeconds,\n    audioTsToVideoTs: audioTsToVideoTs,\n    videoTsToAudioTs: videoTsToAudioTs,\n    metadataTsToSeconds: metadataTsToSeconds\n  };\n\n  var ONE_SECOND_IN_TS$4 = clock.ONE_SECOND_IN_TS;\n\n  var _AdtsStream;\n\n  var ADTS_SAMPLING_FREQUENCIES$1 = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n  /*\n   * Accepts a ElementaryStream and emits data events with parsed\n   * AAC Audio Frames of the individual packets. Input audio in ADTS\n   * format is unpacked and re-emitted as AAC frames.\n   *\n   * @see http://wiki.multimedia.cx/index.php?title=ADTS\n   * @see http://wiki.multimedia.cx/?title=Understanding_AAC\n   */\n\n  _AdtsStream = function AdtsStream(handlePartialSegments) {\n    var buffer,\n        frameNum = 0;\n\n    _AdtsStream.prototype.init.call(this);\n\n    this.skipWarn_ = function (start, end) {\n      this.trigger('log', {\n        level: 'warn',\n        message: \"adts skiping bytes \" + start + \" to \" + end + \" in frame \" + frameNum + \" outside syncword\"\n      });\n    };\n\n    this.push = function (packet) {\n      var i = 0,\n          frameLength,\n          protectionSkipBytes,\n          oldBuffer,\n          sampleCount,\n          adtsFrameDuration;\n\n      if (!handlePartialSegments) {\n        frameNum = 0;\n      }\n\n      if (packet.type !== 'audio') {\n        // ignore non-audio data\n        return;\n      } // Prepend any data in the buffer to the input data so that we can parse\n      // aac frames the cross a PES packet boundary\n\n\n      if (buffer && buffer.length) {\n        oldBuffer = buffer;\n        buffer = new Uint8Array(oldBuffer.byteLength + packet.data.byteLength);\n        buffer.set(oldBuffer);\n        buffer.set(packet.data, oldBuffer.byteLength);\n      } else {\n        buffer = packet.data;\n      } // unpack any ADTS frames which have been fully received\n      // for details on the ADTS header, see http://wiki.multimedia.cx/index.php?title=ADTS\n\n\n      var skip; // We use i + 7 here because we want to be able to parse the entire header.\n      // If we don't have enough bytes to do that, then we definitely won't have a full frame.\n\n      while (i + 7 < buffer.length) {\n        // Look for the start of an ADTS header..\n        if (buffer[i] !== 0xFF || (buffer[i + 1] & 0xF6) !== 0xF0) {\n          if (typeof skip !== 'number') {\n            skip = i;\n          } // If a valid header was not found,  jump one forward and attempt to\n          // find a valid ADTS header starting at the next byte\n\n\n          i++;\n          continue;\n        }\n\n        if (typeof skip === 'number') {\n          this.skipWarn_(skip, i);\n          skip = null;\n        } // The protection skip bit tells us if we have 2 bytes of CRC data at the\n        // end of the ADTS header\n\n\n        protectionSkipBytes = (~buffer[i + 1] & 0x01) * 2; // Frame length is a 13 bit integer starting 16 bits from the\n        // end of the sync sequence\n        // NOTE: frame length includes the size of the header\n\n        frameLength = (buffer[i + 3] & 0x03) << 11 | buffer[i + 4] << 3 | (buffer[i + 5] & 0xe0) >> 5;\n        sampleCount = ((buffer[i + 6] & 0x03) + 1) * 1024;\n        adtsFrameDuration = sampleCount * ONE_SECOND_IN_TS$4 / ADTS_SAMPLING_FREQUENCIES$1[(buffer[i + 2] & 0x3c) >>> 2]; // If we don't have enough data to actually finish this ADTS frame,\n        // then we have to wait for more data\n\n        if (buffer.byteLength - i < frameLength) {\n          break;\n        } // Otherwise, deliver the complete AAC frame\n\n\n        this.trigger('data', {\n          pts: packet.pts + frameNum * adtsFrameDuration,\n          dts: packet.dts + frameNum * adtsFrameDuration,\n          sampleCount: sampleCount,\n          audioobjecttype: (buffer[i + 2] >>> 6 & 0x03) + 1,\n          channelcount: (buffer[i + 2] & 1) << 2 | (buffer[i + 3] & 0xc0) >>> 6,\n          samplerate: ADTS_SAMPLING_FREQUENCIES$1[(buffer[i + 2] & 0x3c) >>> 2],\n          samplingfrequencyindex: (buffer[i + 2] & 0x3c) >>> 2,\n          // assume ISO/IEC 14496-12 AudioSampleEntry default of 16\n          samplesize: 16,\n          // data is the frame without it's header\n          data: buffer.subarray(i + 7 + protectionSkipBytes, i + frameLength)\n        });\n        frameNum++;\n        i += frameLength;\n      }\n\n      if (typeof skip === 'number') {\n        this.skipWarn_(skip, i);\n        skip = null;\n      } // remove processed bytes from the buffer.\n\n\n      buffer = buffer.subarray(i);\n    };\n\n    this.flush = function () {\n      frameNum = 0;\n      this.trigger('done');\n    };\n\n    this.reset = function () {\n      buffer = void 0;\n      this.trigger('reset');\n    };\n\n    this.endTimeline = function () {\n      buffer = void 0;\n      this.trigger('endedtimeline');\n    };\n  };\n\n  _AdtsStream.prototype = new stream();\n  var adts = _AdtsStream;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var ExpGolomb;\n  /**\n   * Parser for exponential Golomb codes, a variable-bitwidth number encoding\n   * scheme used by h264.\n   */\n\n  ExpGolomb = function ExpGolomb(workingData) {\n    var // the number of bytes left to examine in workingData\n    workingBytesAvailable = workingData.byteLength,\n        // the current word being examined\n    workingWord = 0,\n        // :uint\n    // the number of bits left to examine in the current word\n    workingBitsAvailable = 0; // :uint;\n    // ():uint\n\n    this.length = function () {\n      return 8 * workingBytesAvailable;\n    }; // ():uint\n\n\n    this.bitsAvailable = function () {\n      return 8 * workingBytesAvailable + workingBitsAvailable;\n    }; // ():void\n\n\n    this.loadWord = function () {\n      var position = workingData.byteLength - workingBytesAvailable,\n          workingBytes = new Uint8Array(4),\n          availableBytes = Math.min(4, workingBytesAvailable);\n\n      if (availableBytes === 0) {\n        throw new Error('no bytes available');\n      }\n\n      workingBytes.set(workingData.subarray(position, position + availableBytes));\n      workingWord = new DataView(workingBytes.buffer).getUint32(0); // track the amount of workingData that has been processed\n\n      workingBitsAvailable = availableBytes * 8;\n      workingBytesAvailable -= availableBytes;\n    }; // (count:int):void\n\n\n    this.skipBits = function (count) {\n      var skipBytes; // :int\n\n      if (workingBitsAvailable > count) {\n        workingWord <<= count;\n        workingBitsAvailable -= count;\n      } else {\n        count -= workingBitsAvailable;\n        skipBytes = Math.floor(count / 8);\n        count -= skipBytes * 8;\n        workingBytesAvailable -= skipBytes;\n        this.loadWord();\n        workingWord <<= count;\n        workingBitsAvailable -= count;\n      }\n    }; // (size:int):uint\n\n\n    this.readBits = function (size) {\n      var bits = Math.min(workingBitsAvailable, size),\n          // :uint\n      valu = workingWord >>> 32 - bits; // :uint\n      // if size > 31, handle error\n\n      workingBitsAvailable -= bits;\n\n      if (workingBitsAvailable > 0) {\n        workingWord <<= bits;\n      } else if (workingBytesAvailable > 0) {\n        this.loadWord();\n      }\n\n      bits = size - bits;\n\n      if (bits > 0) {\n        return valu << bits | this.readBits(bits);\n      }\n\n      return valu;\n    }; // ():uint\n\n\n    this.skipLeadingZeros = function () {\n      var leadingZeroCount; // :uint\n\n      for (leadingZeroCount = 0; leadingZeroCount < workingBitsAvailable; ++leadingZeroCount) {\n        if ((workingWord & 0x80000000 >>> leadingZeroCount) !== 0) {\n          // the first bit of working word is 1\n          workingWord <<= leadingZeroCount;\n          workingBitsAvailable -= leadingZeroCount;\n          return leadingZeroCount;\n        }\n      } // we exhausted workingWord and still have not found a 1\n\n\n      this.loadWord();\n      return leadingZeroCount + this.skipLeadingZeros();\n    }; // ():void\n\n\n    this.skipUnsignedExpGolomb = function () {\n      this.skipBits(1 + this.skipLeadingZeros());\n    }; // ():void\n\n\n    this.skipExpGolomb = function () {\n      this.skipBits(1 + this.skipLeadingZeros());\n    }; // ():uint\n\n\n    this.readUnsignedExpGolomb = function () {\n      var clz = this.skipLeadingZeros(); // :uint\n\n      return this.readBits(clz + 1) - 1;\n    }; // ():int\n\n\n    this.readExpGolomb = function () {\n      var valu = this.readUnsignedExpGolomb(); // :int\n\n      if (0x01 & valu) {\n        // the number is odd if the low order bit is set\n        return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\n      }\n\n      return -1 * (valu >>> 1); // divide by two then make it negative\n    }; // Some convenience functions\n    // :Boolean\n\n\n    this.readBoolean = function () {\n      return this.readBits(1) === 1;\n    }; // ():int\n\n\n    this.readUnsignedByte = function () {\n      return this.readBits(8);\n    };\n\n    this.loadWord();\n  };\n\n  var expGolomb = ExpGolomb;\n\n  var _H264Stream, _NalByteStream;\n\n  var PROFILES_WITH_OPTIONAL_SPS_DATA;\n  /**\n   * Accepts a NAL unit byte stream and unpacks the embedded NAL units.\n   */\n\n  _NalByteStream = function NalByteStream() {\n    var syncPoint = 0,\n        i,\n        buffer;\n\n    _NalByteStream.prototype.init.call(this);\n    /*\n     * Scans a byte stream and triggers a data event with the NAL units found.\n     * @param {Object} data Event received from H264Stream\n     * @param {Uint8Array} data.data The h264 byte stream to be scanned\n     *\n     * @see H264Stream.push\n     */\n\n\n    this.push = function (data) {\n      var swapBuffer;\n\n      if (!buffer) {\n        buffer = data.data;\n      } else {\n        swapBuffer = new Uint8Array(buffer.byteLength + data.data.byteLength);\n        swapBuffer.set(buffer);\n        swapBuffer.set(data.data, buffer.byteLength);\n        buffer = swapBuffer;\n      }\n\n      var len = buffer.byteLength; // Rec. ITU-T H.264, Annex B\n      // scan for NAL unit boundaries\n      // a match looks like this:\n      // 0 0 1 .. NAL .. 0 0 1\n      // ^ sync point        ^ i\n      // or this:\n      // 0 0 1 .. NAL .. 0 0 0\n      // ^ sync point        ^ i\n      // advance the sync point to a NAL start, if necessary\n\n      for (; syncPoint < len - 3; syncPoint++) {\n        if (buffer[syncPoint + 2] === 1) {\n          // the sync point is properly aligned\n          i = syncPoint + 5;\n          break;\n        }\n      }\n\n      while (i < len) {\n        // look at the current byte to determine if we've hit the end of\n        // a NAL unit boundary\n        switch (buffer[i]) {\n          case 0:\n            // skip past non-sync sequences\n            if (buffer[i - 1] !== 0) {\n              i += 2;\n              break;\n            } else if (buffer[i - 2] !== 0) {\n              i++;\n              break;\n            } // deliver the NAL unit if it isn't empty\n\n\n            if (syncPoint + 3 !== i - 2) {\n              this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n            } // drop trailing zeroes\n\n\n            do {\n              i++;\n            } while (buffer[i] !== 1 && i < len);\n\n            syncPoint = i - 2;\n            i += 3;\n            break;\n\n          case 1:\n            // skip past non-sync sequences\n            if (buffer[i - 1] !== 0 || buffer[i - 2] !== 0) {\n              i += 3;\n              break;\n            } // deliver the NAL unit\n\n\n            this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n            syncPoint = i - 2;\n            i += 3;\n            break;\n\n          default:\n            // the current byte isn't a one or zero, so it cannot be part\n            // of a sync sequence\n            i += 3;\n            break;\n        }\n      } // filter out the NAL units that were delivered\n\n\n      buffer = buffer.subarray(syncPoint);\n      i -= syncPoint;\n      syncPoint = 0;\n    };\n\n    this.reset = function () {\n      buffer = null;\n      syncPoint = 0;\n      this.trigger('reset');\n    };\n\n    this.flush = function () {\n      // deliver the last buffered NAL unit\n      if (buffer && buffer.byteLength > 3) {\n        this.trigger('data', buffer.subarray(syncPoint + 3));\n      } // reset the stream state\n\n\n      buffer = null;\n      syncPoint = 0;\n      this.trigger('done');\n    };\n\n    this.endTimeline = function () {\n      this.flush();\n      this.trigger('endedtimeline');\n    };\n  };\n\n  _NalByteStream.prototype = new stream(); // values of profile_idc that indicate additional fields are included in the SPS\n  // see Recommendation ITU-T H.264 (4/2013),\n  // 7.3.2.1.1 Sequence parameter set data syntax\n\n  PROFILES_WITH_OPTIONAL_SPS_DATA = {\n    100: true,\n    110: true,\n    122: true,\n    244: true,\n    44: true,\n    83: true,\n    86: true,\n    118: true,\n    128: true,\n    // TODO: the three profiles below don't\n    // appear to have sps data in the specificiation anymore?\n    138: true,\n    139: true,\n    134: true\n  };\n  /**\n   * Accepts input from a ElementaryStream and produces H.264 NAL unit data\n   * events.\n   */\n\n  _H264Stream = function H264Stream() {\n    var nalByteStream = new _NalByteStream(),\n        self,\n        trackId,\n        currentPts,\n        currentDts,\n        discardEmulationPreventionBytes,\n        readSequenceParameterSet,\n        skipScalingList;\n\n    _H264Stream.prototype.init.call(this);\n\n    self = this;\n    /*\n     * Pushes a packet from a stream onto the NalByteStream\n     *\n     * @param {Object} packet - A packet received from a stream\n     * @param {Uint8Array} packet.data - The raw bytes of the packet\n     * @param {Number} packet.dts - Decode timestamp of the packet\n     * @param {Number} packet.pts - Presentation timestamp of the packet\n     * @param {Number} packet.trackId - The id of the h264 track this packet came from\n     * @param {('video'|'audio')} packet.type - The type of packet\n     *\n     */\n\n    this.push = function (packet) {\n      if (packet.type !== 'video') {\n        return;\n      }\n\n      trackId = packet.trackId;\n      currentPts = packet.pts;\n      currentDts = packet.dts;\n      nalByteStream.push(packet);\n    };\n    /*\n     * Identify NAL unit types and pass on the NALU, trackId, presentation and decode timestamps\n     * for the NALUs to the next stream component.\n     * Also, preprocess caption and sequence parameter NALUs.\n     *\n     * @param {Uint8Array} data - A NAL unit identified by `NalByteStream.push`\n     * @see NalByteStream.push\n     */\n\n\n    nalByteStream.on('data', function (data) {\n      var event = {\n        trackId: trackId,\n        pts: currentPts,\n        dts: currentDts,\n        data: data,\n        nalUnitTypeCode: data[0] & 0x1f\n      };\n\n      switch (event.nalUnitTypeCode) {\n        case 0x05:\n          event.nalUnitType = 'slice_layer_without_partitioning_rbsp_idr';\n          break;\n\n        case 0x06:\n          event.nalUnitType = 'sei_rbsp';\n          event.escapedRBSP = discardEmulationPreventionBytes(data.subarray(1));\n          break;\n\n        case 0x07:\n          event.nalUnitType = 'seq_parameter_set_rbsp';\n          event.escapedRBSP = discardEmulationPreventionBytes(data.subarray(1));\n          event.config = readSequenceParameterSet(event.escapedRBSP);\n          break;\n\n        case 0x08:\n          event.nalUnitType = 'pic_parameter_set_rbsp';\n          break;\n\n        case 0x09:\n          event.nalUnitType = 'access_unit_delimiter_rbsp';\n          break;\n      } // This triggers data on the H264Stream\n\n\n      self.trigger('data', event);\n    });\n    nalByteStream.on('done', function () {\n      self.trigger('done');\n    });\n    nalByteStream.on('partialdone', function () {\n      self.trigger('partialdone');\n    });\n    nalByteStream.on('reset', function () {\n      self.trigger('reset');\n    });\n    nalByteStream.on('endedtimeline', function () {\n      self.trigger('endedtimeline');\n    });\n\n    this.flush = function () {\n      nalByteStream.flush();\n    };\n\n    this.partialFlush = function () {\n      nalByteStream.partialFlush();\n    };\n\n    this.reset = function () {\n      nalByteStream.reset();\n    };\n\n    this.endTimeline = function () {\n      nalByteStream.endTimeline();\n    };\n    /**\n     * Advance the ExpGolomb decoder past a scaling list. The scaling\n     * list is optionally transmitted as part of a sequence parameter\n     * set and is not relevant to transmuxing.\n     * @param count {number} the number of entries in this scaling list\n     * @param expGolombDecoder {object} an ExpGolomb pointed to the\n     * start of a scaling list\n     * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n     */\n\n\n    skipScalingList = function skipScalingList(count, expGolombDecoder) {\n      var lastScale = 8,\n          nextScale = 8,\n          j,\n          deltaScale;\n\n      for (j = 0; j < count; j++) {\n        if (nextScale !== 0) {\n          deltaScale = expGolombDecoder.readExpGolomb();\n          nextScale = (lastScale + deltaScale + 256) % 256;\n        }\n\n        lastScale = nextScale === 0 ? lastScale : nextScale;\n      }\n    };\n    /**\n     * Expunge any \"Emulation Prevention\" bytes from a \"Raw Byte\n     * Sequence Payload\"\n     * @param data {Uint8Array} the bytes of a RBSP from a NAL\n     * unit\n     * @return {Uint8Array} the RBSP without any Emulation\n     * Prevention Bytes\n     */\n\n\n    discardEmulationPreventionBytes = function discardEmulationPreventionBytes(data) {\n      var length = data.byteLength,\n          emulationPreventionBytesPositions = [],\n          i = 1,\n          newLength,\n          newData; // Find all `Emulation Prevention Bytes`\n\n      while (i < length - 2) {\n        if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n          emulationPreventionBytesPositions.push(i + 2);\n          i += 2;\n        } else {\n          i++;\n        }\n      } // If no Emulation Prevention Bytes were found just return the original\n      // array\n\n\n      if (emulationPreventionBytesPositions.length === 0) {\n        return data;\n      } // Create a new array to hold the NAL unit data\n\n\n      newLength = length - emulationPreventionBytesPositions.length;\n      newData = new Uint8Array(newLength);\n      var sourceIndex = 0;\n\n      for (i = 0; i < newLength; sourceIndex++, i++) {\n        if (sourceIndex === emulationPreventionBytesPositions[0]) {\n          // Skip this byte\n          sourceIndex++; // Remove this position index\n\n          emulationPreventionBytesPositions.shift();\n        }\n\n        newData[i] = data[sourceIndex];\n      }\n\n      return newData;\n    };\n    /**\n     * Read a sequence parameter set and return some interesting video\n     * properties. A sequence parameter set is the H264 metadata that\n     * describes the properties of upcoming video frames.\n     * @param data {Uint8Array} the bytes of a sequence parameter set\n     * @return {object} an object with configuration parsed from the\n     * sequence parameter set, including the dimensions of the\n     * associated video frames.\n     */\n\n\n    readSequenceParameterSet = function readSequenceParameterSet(data) {\n      var frameCropLeftOffset = 0,\n          frameCropRightOffset = 0,\n          frameCropTopOffset = 0,\n          frameCropBottomOffset = 0,\n          expGolombDecoder,\n          profileIdc,\n          levelIdc,\n          profileCompatibility,\n          chromaFormatIdc,\n          picOrderCntType,\n          numRefFramesInPicOrderCntCycle,\n          picWidthInMbsMinus1,\n          picHeightInMapUnitsMinus1,\n          frameMbsOnlyFlag,\n          scalingListCount,\n          sarRatio = [1, 1],\n          aspectRatioIdc,\n          i;\n      expGolombDecoder = new expGolomb(data);\n      profileIdc = expGolombDecoder.readUnsignedByte(); // profile_idc\n\n      profileCompatibility = expGolombDecoder.readUnsignedByte(); // constraint_set[0-5]_flag\n\n      levelIdc = expGolombDecoder.readUnsignedByte(); // level_idc u(8)\n\n      expGolombDecoder.skipUnsignedExpGolomb(); // seq_parameter_set_id\n      // some profiles have more optional data we don't need\n\n      if (PROFILES_WITH_OPTIONAL_SPS_DATA[profileIdc]) {\n        chromaFormatIdc = expGolombDecoder.readUnsignedExpGolomb();\n\n        if (chromaFormatIdc === 3) {\n          expGolombDecoder.skipBits(1); // separate_colour_plane_flag\n        }\n\n        expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_luma_minus8\n\n        expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_chroma_minus8\n\n        expGolombDecoder.skipBits(1); // qpprime_y_zero_transform_bypass_flag\n\n        if (expGolombDecoder.readBoolean()) {\n          // seq_scaling_matrix_present_flag\n          scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\n\n          for (i = 0; i < scalingListCount; i++) {\n            if (expGolombDecoder.readBoolean()) {\n              // seq_scaling_list_present_flag[ i ]\n              if (i < 6) {\n                skipScalingList(16, expGolombDecoder);\n              } else {\n                skipScalingList(64, expGolombDecoder);\n              }\n            }\n          }\n        }\n      }\n\n      expGolombDecoder.skipUnsignedExpGolomb(); // log2_max_frame_num_minus4\n\n      picOrderCntType = expGolombDecoder.readUnsignedExpGolomb();\n\n      if (picOrderCntType === 0) {\n        expGolombDecoder.readUnsignedExpGolomb(); // log2_max_pic_order_cnt_lsb_minus4\n      } else if (picOrderCntType === 1) {\n        expGolombDecoder.skipBits(1); // delta_pic_order_always_zero_flag\n\n        expGolombDecoder.skipExpGolomb(); // offset_for_non_ref_pic\n\n        expGolombDecoder.skipExpGolomb(); // offset_for_top_to_bottom_field\n\n        numRefFramesInPicOrderCntCycle = expGolombDecoder.readUnsignedExpGolomb();\n\n        for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n          expGolombDecoder.skipExpGolomb(); // offset_for_ref_frame[ i ]\n        }\n      }\n\n      expGolombDecoder.skipUnsignedExpGolomb(); // max_num_ref_frames\n\n      expGolombDecoder.skipBits(1); // gaps_in_frame_num_value_allowed_flag\n\n      picWidthInMbsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n      picHeightInMapUnitsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n      frameMbsOnlyFlag = expGolombDecoder.readBits(1);\n\n      if (frameMbsOnlyFlag === 0) {\n        expGolombDecoder.skipBits(1); // mb_adaptive_frame_field_flag\n      }\n\n      expGolombDecoder.skipBits(1); // direct_8x8_inference_flag\n\n      if (expGolombDecoder.readBoolean()) {\n        // frame_cropping_flag\n        frameCropLeftOffset = expGolombDecoder.readUnsignedExpGolomb();\n        frameCropRightOffset = expGolombDecoder.readUnsignedExpGolomb();\n        frameCropTopOffset = expGolombDecoder.readUnsignedExpGolomb();\n        frameCropBottomOffset = expGolombDecoder.readUnsignedExpGolomb();\n      }\n\n      if (expGolombDecoder.readBoolean()) {\n        // vui_parameters_present_flag\n        if (expGolombDecoder.readBoolean()) {\n          // aspect_ratio_info_present_flag\n          aspectRatioIdc = expGolombDecoder.readUnsignedByte();\n\n          switch (aspectRatioIdc) {\n            case 1:\n              sarRatio = [1, 1];\n              break;\n\n            case 2:\n              sarRatio = [12, 11];\n              break;\n\n            case 3:\n              sarRatio = [10, 11];\n              break;\n\n            case 4:\n              sarRatio = [16, 11];\n              break;\n\n            case 5:\n              sarRatio = [40, 33];\n              break;\n\n            case 6:\n              sarRatio = [24, 11];\n              break;\n\n            case 7:\n              sarRatio = [20, 11];\n              break;\n\n            case 8:\n              sarRatio = [32, 11];\n              break;\n\n            case 9:\n              sarRatio = [80, 33];\n              break;\n\n            case 10:\n              sarRatio = [18, 11];\n              break;\n\n            case 11:\n              sarRatio = [15, 11];\n              break;\n\n            case 12:\n              sarRatio = [64, 33];\n              break;\n\n            case 13:\n              sarRatio = [160, 99];\n              break;\n\n            case 14:\n              sarRatio = [4, 3];\n              break;\n\n            case 15:\n              sarRatio = [3, 2];\n              break;\n\n            case 16:\n              sarRatio = [2, 1];\n              break;\n\n            case 255:\n              {\n                sarRatio = [expGolombDecoder.readUnsignedByte() << 8 | expGolombDecoder.readUnsignedByte(), expGolombDecoder.readUnsignedByte() << 8 | expGolombDecoder.readUnsignedByte()];\n                break;\n              }\n          }\n\n          if (sarRatio) {\n            sarRatio[0] / sarRatio[1];\n          }\n        }\n      }\n\n      return {\n        profileIdc: profileIdc,\n        levelIdc: levelIdc,\n        profileCompatibility: profileCompatibility,\n        width: (picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2,\n        height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - frameCropTopOffset * 2 - frameCropBottomOffset * 2,\n        // sar is sample aspect ratio\n        sarRatio: sarRatio\n      };\n    };\n  };\n\n  _H264Stream.prototype = new stream();\n  var h264 = {\n    H264Stream: _H264Stream,\n    NalByteStream: _NalByteStream\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var codecs = {\n    Adts: adts,\n    h264: h264\n  };\n\n  var MAX_UINT32$1 = Math.pow(2, 32);\n\n  var getUint64$4 = function getUint64(uint8) {\n    var dv = new DataView(uint8.buffer, uint8.byteOffset, uint8.byteLength);\n    var value;\n\n    if (dv.getBigUint64) {\n      value = dv.getBigUint64(0);\n\n      if (value < Number.MAX_SAFE_INTEGER) {\n        return Number(value);\n      }\n\n      return value;\n    }\n\n    return dv.getUint32(0) * MAX_UINT32$1 + dv.getUint32(4);\n  };\n\n  var numbers = {\n    getUint64: getUint64$4,\n    MAX_UINT32: MAX_UINT32$1\n  };\n\n  var MAX_UINT32 = numbers.MAX_UINT32;\n  var box, dinf, esds, ftyp, mdat, mfhd, minf, moof, moov, mvex, mvhd, trak, tkhd, mdia, mdhd, hdlr, sdtp, stbl, stsd, traf, trex, trun$1, types, MAJOR_BRAND, MINOR_VERSION, AVC1_BRAND, VIDEO_HDLR, AUDIO_HDLR, HDLR_TYPES, VMHD, SMHD, DREF, STCO, STSC, STSZ, STTS; // pre-calculate constants\n\n  (function () {\n    var i;\n    types = {\n      avc1: [],\n      // codingname\n      avcC: [],\n      btrt: [],\n      dinf: [],\n      dref: [],\n      esds: [],\n      ftyp: [],\n      hdlr: [],\n      mdat: [],\n      mdhd: [],\n      mdia: [],\n      mfhd: [],\n      minf: [],\n      moof: [],\n      moov: [],\n      mp4a: [],\n      // codingname\n      mvex: [],\n      mvhd: [],\n      pasp: [],\n      sdtp: [],\n      smhd: [],\n      stbl: [],\n      stco: [],\n      stsc: [],\n      stsd: [],\n      stsz: [],\n      stts: [],\n      styp: [],\n      tfdt: [],\n      tfhd: [],\n      traf: [],\n      trak: [],\n      trun: [],\n      trex: [],\n      tkhd: [],\n      vmhd: []\n    }; // In environments where Uint8Array is undefined (e.g., IE8), skip set up so that we\n    // don't throw an error\n\n    if (typeof Uint8Array === 'undefined') {\n      return;\n    }\n\n    for (i in types) {\n      if (types.hasOwnProperty(i)) {\n        types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n      }\n    }\n\n    MAJOR_BRAND = new Uint8Array(['i'.charCodeAt(0), 's'.charCodeAt(0), 'o'.charCodeAt(0), 'm'.charCodeAt(0)]);\n    AVC1_BRAND = new Uint8Array(['a'.charCodeAt(0), 'v'.charCodeAt(0), 'c'.charCodeAt(0), '1'.charCodeAt(0)]);\n    MINOR_VERSION = new Uint8Array([0, 0, 0, 1]);\n    VIDEO_HDLR = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n    ]);\n    AUDIO_HDLR = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n    ]);\n    HDLR_TYPES = {\n      video: VIDEO_HDLR,\n      audio: AUDIO_HDLR\n    };\n    DREF = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // entry_count\n    0x00, 0x00, 0x00, 0x0c, // entry_size\n    0x75, 0x72, 0x6c, 0x20, // 'url' type\n    0x00, // version 0\n    0x00, 0x00, 0x01 // entry_flags\n    ]);\n    SMHD = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, // balance, 0 means centered\n    0x00, 0x00 // reserved\n    ]);\n    STCO = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    STSC = STCO;\n    STSZ = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n    ]);\n    STTS = STCO;\n    VMHD = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x01, // flags\n    0x00, 0x00, // graphicsmode\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n    ]);\n  })();\n\n  box = function box(type) {\n    var payload = [],\n        size = 0,\n        i,\n        result,\n        view;\n\n    for (i = 1; i < arguments.length; i++) {\n      payload.push(arguments[i]);\n    }\n\n    i = payload.length; // calculate the total size we need to allocate\n\n    while (i--) {\n      size += payload[i].byteLength;\n    }\n\n    result = new Uint8Array(size + 8);\n    view = new DataView(result.buffer, result.byteOffset, result.byteLength);\n    view.setUint32(0, result.byteLength);\n    result.set(type, 4); // copy the payload into the result\n\n    for (i = 0, size = 8; i < payload.length; i++) {\n      result.set(payload[i], size);\n      size += payload[i].byteLength;\n    }\n\n    return result;\n  };\n\n  dinf = function dinf() {\n    return box(types.dinf, box(types.dref, DREF));\n  };\n\n  esds = function esds(track) {\n    return box(types.esds, new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    // ES_Descriptor\n    0x03, // tag, ES_DescrTag\n    0x19, // length\n    0x00, 0x00, // ES_ID\n    0x00, // streamDependenceFlag, URL_flag, reserved, streamPriority\n    // DecoderConfigDescriptor\n    0x04, // tag, DecoderConfigDescrTag\n    0x11, // length\n    0x40, // object type\n    0x15, // streamType\n    0x00, 0x06, 0x00, // bufferSizeDB\n    0x00, 0x00, 0xda, 0xc0, // maxBitrate\n    0x00, 0x00, 0xda, 0xc0, // avgBitrate\n    // DecoderSpecificInfo\n    0x05, // tag, DecoderSpecificInfoTag\n    0x02, // length\n    // ISO/IEC 14496-3, AudioSpecificConfig\n    // for samplingFrequencyIndex see ISO/IEC 13818-7:2006, 8.1.3.2.2, Table 35\n    track.audioobjecttype << 3 | track.samplingfrequencyindex >>> 1, track.samplingfrequencyindex << 7 | track.channelcount << 3, 0x06, 0x01, 0x02 // GASpecificConfig\n    ]));\n  };\n\n  ftyp = function ftyp() {\n    return box(types.ftyp, MAJOR_BRAND, MINOR_VERSION, MAJOR_BRAND, AVC1_BRAND);\n  };\n\n  hdlr = function hdlr(type) {\n    return box(types.hdlr, HDLR_TYPES[type]);\n  };\n\n  mdat = function mdat(data) {\n    return box(types.mdat, data);\n  };\n\n  mdhd = function mdhd(track) {\n    var result = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x03, // modification_time\n    0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n    track.duration >>> 24 & 0xFF, track.duration >>> 16 & 0xFF, track.duration >>> 8 & 0xFF, track.duration & 0xFF, // duration\n    0x55, 0xc4, // 'und' language (undetermined)\n    0x00, 0x00]); // Use the sample rate from the track metadata, when it is\n    // defined. The sample rate can be parsed out of an ADTS header, for\n    // instance.\n\n    if (track.samplerate) {\n      result[12] = track.samplerate >>> 24 & 0xFF;\n      result[13] = track.samplerate >>> 16 & 0xFF;\n      result[14] = track.samplerate >>> 8 & 0xFF;\n      result[15] = track.samplerate & 0xFF;\n    }\n\n    return box(types.mdhd, result);\n  };\n\n  mdia = function mdia(track) {\n    return box(types.mdia, mdhd(track), hdlr(track.type), minf(track));\n  };\n\n  mfhd = function mfhd(sequenceNumber) {\n    return box(types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // flags\n    (sequenceNumber & 0xFF000000) >> 24, (sequenceNumber & 0xFF0000) >> 16, (sequenceNumber & 0xFF00) >> 8, sequenceNumber & 0xFF // sequence_number\n    ]));\n  };\n\n  minf = function minf(track) {\n    return box(types.minf, track.type === 'video' ? box(types.vmhd, VMHD) : box(types.smhd, SMHD), dinf(), stbl(track));\n  };\n\n  moof = function moof(sequenceNumber, tracks) {\n    var trackFragments = [],\n        i = tracks.length; // build traf boxes for each track fragment\n\n    while (i--) {\n      trackFragments[i] = traf(tracks[i]);\n    }\n\n    return box.apply(null, [types.moof, mfhd(sequenceNumber)].concat(trackFragments));\n  };\n  /**\n   * Returns a movie box.\n   * @param tracks {array} the tracks associated with this movie\n   * @see ISO/IEC 14496-12:2012(E), section 8.2.1\n   */\n\n\n  moov = function moov(tracks) {\n    var i = tracks.length,\n        boxes = [];\n\n    while (i--) {\n      boxes[i] = trak(tracks[i]);\n    }\n\n    return box.apply(null, [types.moov, mvhd(0xffffffff)].concat(boxes).concat(mvex(tracks)));\n  };\n\n  mvex = function mvex(tracks) {\n    var i = tracks.length,\n        boxes = [];\n\n    while (i--) {\n      boxes[i] = trex(tracks[i]);\n    }\n\n    return box.apply(null, [types.mvex].concat(boxes));\n  };\n\n  mvhd = function mvhd(duration) {\n    var bytes = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // creation_time\n    0x00, 0x00, 0x00, 0x02, // modification_time\n    0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n    (duration & 0xFF000000) >> 24, (duration & 0xFF0000) >> 16, (duration & 0xFF00) >> 8, duration & 0xFF, // duration\n    0x00, 0x01, 0x00, 0x00, // 1.0 rate\n    0x01, 0x00, // 1.0 volume\n    0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n    0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n    return box(types.mvhd, bytes);\n  };\n\n  sdtp = function sdtp(track) {\n    var samples = track.samples || [],\n        bytes = new Uint8Array(4 + samples.length),\n        flags,\n        i; // leave the full box header (4 bytes) all zero\n    // write the sample table\n\n    for (i = 0; i < samples.length; i++) {\n      flags = samples[i].flags;\n      bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n    }\n\n    return box(types.sdtp, bytes);\n  };\n\n  stbl = function stbl(track) {\n    return box(types.stbl, stsd(track), box(types.stts, STTS), box(types.stsc, STSC), box(types.stsz, STSZ), box(types.stco, STCO));\n  };\n\n  (function () {\n    var videoSample, audioSample;\n\n    stsd = function stsd(track) {\n      return box(types.stsd, new Uint8Array([0x00, // version 0\n      0x00, 0x00, 0x00, // flags\n      0x00, 0x00, 0x00, 0x01]), track.type === 'video' ? videoSample(track) : audioSample(track));\n    };\n\n    videoSample = function videoSample(track) {\n      var sps = track.sps || [],\n          pps = track.pps || [],\n          sequenceParameterSets = [],\n          pictureParameterSets = [],\n          i,\n          avc1Box; // assemble the SPSs\n\n      for (i = 0; i < sps.length; i++) {\n        sequenceParameterSets.push((sps[i].byteLength & 0xFF00) >>> 8);\n        sequenceParameterSets.push(sps[i].byteLength & 0xFF); // sequenceParameterSetLength\n\n        sequenceParameterSets = sequenceParameterSets.concat(Array.prototype.slice.call(sps[i])); // SPS\n      } // assemble the PPSs\n\n\n      for (i = 0; i < pps.length; i++) {\n        pictureParameterSets.push((pps[i].byteLength & 0xFF00) >>> 8);\n        pictureParameterSets.push(pps[i].byteLength & 0xFF);\n        pictureParameterSets = pictureParameterSets.concat(Array.prototype.slice.call(pps[i]));\n      }\n\n      avc1Box = [types.avc1, new Uint8Array([0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // data_reference_index\n      0x00, 0x00, // pre_defined\n      0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n      (track.width & 0xff00) >> 8, track.width & 0xff, // width\n      (track.height & 0xff00) >> 8, track.height & 0xff, // height\n      0x00, 0x48, 0x00, 0x00, // horizresolution\n      0x00, 0x48, 0x00, 0x00, // vertresolution\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // frame_count\n      0x13, 0x76, 0x69, 0x64, 0x65, 0x6f, 0x6a, 0x73, 0x2d, 0x63, 0x6f, 0x6e, 0x74, 0x72, 0x69, 0x62, 0x2d, 0x68, 0x6c, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname\n      0x00, 0x18, // depth = 24\n      0x11, 0x11 // pre_defined = -1\n      ]), box(types.avcC, new Uint8Array([0x01, // configurationVersion\n      track.profileIdc, // AVCProfileIndication\n      track.profileCompatibility, // profile_compatibility\n      track.levelIdc, // AVCLevelIndication\n      0xff // lengthSizeMinusOne, hard-coded to 4 bytes\n      ].concat([sps.length], // numOfSequenceParameterSets\n      sequenceParameterSets, // \"SPS\"\n      [pps.length], // numOfPictureParameterSets\n      pictureParameterSets // \"PPS\"\n      ))), box(types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n      0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n      0x00, 0x2d, 0xc6, 0xc0 // avgBitrate\n      ]))];\n\n      if (track.sarRatio) {\n        var hSpacing = track.sarRatio[0],\n            vSpacing = track.sarRatio[1];\n        avc1Box.push(box(types.pasp, new Uint8Array([(hSpacing & 0xFF000000) >> 24, (hSpacing & 0xFF0000) >> 16, (hSpacing & 0xFF00) >> 8, hSpacing & 0xFF, (vSpacing & 0xFF000000) >> 24, (vSpacing & 0xFF0000) >> 16, (vSpacing & 0xFF00) >> 8, vSpacing & 0xFF])));\n      }\n\n      return box.apply(null, avc1Box);\n    };\n\n    audioSample = function audioSample(track) {\n      return box(types.mp4a, new Uint8Array([// SampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // data_reference_index\n      // AudioSampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      (track.channelcount & 0xff00) >> 8, track.channelcount & 0xff, // channelcount\n      (track.samplesize & 0xff00) >> 8, track.samplesize & 0xff, // samplesize\n      0x00, 0x00, // pre_defined\n      0x00, 0x00, // reserved\n      (track.samplerate & 0xff00) >> 8, track.samplerate & 0xff, 0x00, 0x00 // samplerate, 16.16\n      // MP4AudioSampleEntry, ISO/IEC 14496-14\n      ]), esds(track));\n    };\n  })();\n\n  tkhd = function tkhd(track) {\n    var result = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x07, // flags\n    0x00, 0x00, 0x00, 0x00, // creation_time\n    0x00, 0x00, 0x00, 0x00, // modification_time\n    (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x00, // reserved\n    (track.duration & 0xFF000000) >> 24, (track.duration & 0xFF0000) >> 16, (track.duration & 0xFF00) >> 8, track.duration & 0xFF, // duration\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, // layer\n    0x00, 0x00, // alternate_group\n    0x01, 0x00, // non-audio track volume\n    0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    (track.width & 0xFF00) >> 8, track.width & 0xFF, 0x00, 0x00, // width\n    (track.height & 0xFF00) >> 8, track.height & 0xFF, 0x00, 0x00 // height\n    ]);\n    return box(types.tkhd, result);\n  };\n  /**\n   * Generate a track fragment (traf) box. A traf box collects metadata\n   * about tracks in a movie fragment (moof) box.\n   */\n\n\n  traf = function traf(track) {\n    var trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun, sampleDependencyTable, dataOffset, upperWordBaseMediaDecodeTime, lowerWordBaseMediaDecodeTime;\n    trackFragmentHeader = box(types.tfhd, new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x3a, // flags\n    (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x01, // sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x00, 0x00, 0x00 // default_sample_flags\n    ]));\n    upperWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime / MAX_UINT32);\n    lowerWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime % MAX_UINT32);\n    trackFragmentDecodeTime = box(types.tfdt, new Uint8Array([0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    // baseMediaDecodeTime\n    upperWordBaseMediaDecodeTime >>> 24 & 0xFF, upperWordBaseMediaDecodeTime >>> 16 & 0xFF, upperWordBaseMediaDecodeTime >>> 8 & 0xFF, upperWordBaseMediaDecodeTime & 0xFF, lowerWordBaseMediaDecodeTime >>> 24 & 0xFF, lowerWordBaseMediaDecodeTime >>> 16 & 0xFF, lowerWordBaseMediaDecodeTime >>> 8 & 0xFF, lowerWordBaseMediaDecodeTime & 0xFF])); // the data offset specifies the number of bytes from the start of\n    // the containing moof to the first payload byte of the associated\n    // mdat\n\n    dataOffset = 32 + // tfhd\n    20 + // tfdt\n    8 + // traf header\n    16 + // mfhd\n    8 + // moof header\n    8; // mdat header\n    // audio tracks require less metadata\n\n    if (track.type === 'audio') {\n      trackFragmentRun = trun$1(track, dataOffset);\n      return box(types.traf, trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun);\n    } // video tracks should contain an independent and disposable samples\n    // box (sdtp)\n    // generate one and adjust offsets to match\n\n\n    sampleDependencyTable = sdtp(track);\n    trackFragmentRun = trun$1(track, sampleDependencyTable.length + dataOffset);\n    return box(types.traf, trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun, sampleDependencyTable);\n  };\n  /**\n   * Generate a track box.\n   * @param track {object} a track definition\n   * @return {Uint8Array} the track box\n   */\n\n\n  trak = function trak(track) {\n    track.duration = track.duration || 0xffffffff;\n    return box(types.trak, tkhd(track), mdia(track));\n  };\n\n  trex = function trex(track) {\n    var result = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    (track.id & 0xFF000000) >> 24, (track.id & 0xFF0000) >> 16, (track.id & 0xFF00) >> 8, track.id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n    ]); // the last two bytes of default_sample_flags is the sample\n    // degradation priority, a hint about the importance of this sample\n    // relative to others. Lower the degradation priority for all sample\n    // types other than video.\n\n    if (track.type !== 'video') {\n      result[result.length - 1] = 0x00;\n    }\n\n    return box(types.trex, result);\n  };\n\n  (function () {\n    var audioTrun, videoTrun, trunHeader; // This method assumes all samples are uniform. That is, if a\n    // duration is present for the first sample, it will be present for\n    // all subsequent samples.\n    // see ISO/IEC 14496-12:2012, Section 8.8.8.1\n\n    trunHeader = function trunHeader(samples, offset) {\n      var durationPresent = 0,\n          sizePresent = 0,\n          flagsPresent = 0,\n          compositionTimeOffset = 0; // trun flag constants\n\n      if (samples.length) {\n        if (samples[0].duration !== undefined) {\n          durationPresent = 0x1;\n        }\n\n        if (samples[0].size !== undefined) {\n          sizePresent = 0x2;\n        }\n\n        if (samples[0].flags !== undefined) {\n          flagsPresent = 0x4;\n        }\n\n        if (samples[0].compositionTimeOffset !== undefined) {\n          compositionTimeOffset = 0x8;\n        }\n      }\n\n      return [0x00, // version 0\n      0x00, durationPresent | sizePresent | flagsPresent | compositionTimeOffset, 0x01, // flags\n      (samples.length & 0xFF000000) >>> 24, (samples.length & 0xFF0000) >>> 16, (samples.length & 0xFF00) >>> 8, samples.length & 0xFF, // sample_count\n      (offset & 0xFF000000) >>> 24, (offset & 0xFF0000) >>> 16, (offset & 0xFF00) >>> 8, offset & 0xFF // data_offset\n      ];\n    };\n\n    videoTrun = function videoTrun(track, offset) {\n      var bytesOffest, bytes, header, samples, sample, i;\n      samples = track.samples || [];\n      offset += 8 + 12 + 16 * samples.length;\n      header = trunHeader(samples, offset);\n      bytes = new Uint8Array(header.length + samples.length * 16);\n      bytes.set(header);\n      bytesOffest = header.length;\n\n      for (i = 0; i < samples.length; i++) {\n        sample = samples[i];\n        bytes[bytesOffest++] = (sample.duration & 0xFF000000) >>> 24;\n        bytes[bytesOffest++] = (sample.duration & 0xFF0000) >>> 16;\n        bytes[bytesOffest++] = (sample.duration & 0xFF00) >>> 8;\n        bytes[bytesOffest++] = sample.duration & 0xFF; // sample_duration\n\n        bytes[bytesOffest++] = (sample.size & 0xFF000000) >>> 24;\n        bytes[bytesOffest++] = (sample.size & 0xFF0000) >>> 16;\n        bytes[bytesOffest++] = (sample.size & 0xFF00) >>> 8;\n        bytes[bytesOffest++] = sample.size & 0xFF; // sample_size\n\n        bytes[bytesOffest++] = sample.flags.isLeading << 2 | sample.flags.dependsOn;\n        bytes[bytesOffest++] = sample.flags.isDependedOn << 6 | sample.flags.hasRedundancy << 4 | sample.flags.paddingValue << 1 | sample.flags.isNonSyncSample;\n        bytes[bytesOffest++] = sample.flags.degradationPriority & 0xF0 << 8;\n        bytes[bytesOffest++] = sample.flags.degradationPriority & 0x0F; // sample_flags\n\n        bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF000000) >>> 24;\n        bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF0000) >>> 16;\n        bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF00) >>> 8;\n        bytes[bytesOffest++] = sample.compositionTimeOffset & 0xFF; // sample_composition_time_offset\n      }\n\n      return box(types.trun, bytes);\n    };\n\n    audioTrun = function audioTrun(track, offset) {\n      var bytes, bytesOffest, header, samples, sample, i;\n      samples = track.samples || [];\n      offset += 8 + 12 + 8 * samples.length;\n      header = trunHeader(samples, offset);\n      bytes = new Uint8Array(header.length + samples.length * 8);\n      bytes.set(header);\n      bytesOffest = header.length;\n\n      for (i = 0; i < samples.length; i++) {\n        sample = samples[i];\n        bytes[bytesOffest++] = (sample.duration & 0xFF000000) >>> 24;\n        bytes[bytesOffest++] = (sample.duration & 0xFF0000) >>> 16;\n        bytes[bytesOffest++] = (sample.duration & 0xFF00) >>> 8;\n        bytes[bytesOffest++] = sample.duration & 0xFF; // sample_duration\n\n        bytes[bytesOffest++] = (sample.size & 0xFF000000) >>> 24;\n        bytes[bytesOffest++] = (sample.size & 0xFF0000) >>> 16;\n        bytes[bytesOffest++] = (sample.size & 0xFF00) >>> 8;\n        bytes[bytesOffest++] = sample.size & 0xFF; // sample_size\n      }\n\n      return box(types.trun, bytes);\n    };\n\n    trun$1 = function trun(track, offset) {\n      if (track.type === 'audio') {\n        return audioTrun(track, offset);\n      }\n\n      return videoTrun(track, offset);\n    };\n  })();\n\n  var mp4Generator = {\n    ftyp: ftyp,\n    mdat: mdat,\n    moof: moof,\n    moov: moov,\n    initSegment: function initSegment(tracks) {\n      var fileType = ftyp(),\n          movie = moov(tracks),\n          result;\n      result = new Uint8Array(fileType.byteLength + movie.byteLength);\n      result.set(fileType);\n      result.set(movie, fileType.byteLength);\n      return result;\n    }\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n  var toUnsigned$3 = function toUnsigned(value) {\n    return value >>> 0;\n  };\n\n  var toHexString$1 = function toHexString(value) {\n    return ('00' + value.toString(16)).slice(-2);\n  };\n\n  var bin = {\n    toUnsigned: toUnsigned$3,\n    toHexString: toHexString$1\n  };\n\n  var parseType$2 = function parseType(buffer) {\n    var result = '';\n    result += String.fromCharCode(buffer[0]);\n    result += String.fromCharCode(buffer[1]);\n    result += String.fromCharCode(buffer[2]);\n    result += String.fromCharCode(buffer[3]);\n    return result;\n  };\n\n  var parseType_1 = parseType$2;\n\n  var toUnsigned$2 = bin.toUnsigned;\n\n  var findBox = function findBox(data, path) {\n    var results = [],\n        i,\n        size,\n        type,\n        end,\n        subresults;\n\n    if (!path.length) {\n      // short-circuit the search for empty paths\n      return null;\n    }\n\n    for (i = 0; i < data.byteLength;) {\n      size = toUnsigned$2(data[i] << 24 | data[i + 1] << 16 | data[i + 2] << 8 | data[i + 3]);\n      type = parseType_1(data.subarray(i + 4, i + 8));\n      end = size > 1 ? i + size : data.byteLength;\n\n      if (type === path[0]) {\n        if (path.length === 1) {\n          // this is the end of the path and we've found the box we were\n          // looking for\n          results.push(data.subarray(i + 8, end));\n        } else {\n          // recursively search for the next box along the path\n          subresults = findBox(data.subarray(i + 8, end), path.slice(1));\n\n          if (subresults.length) {\n            results = results.concat(subresults);\n          }\n        }\n      }\n\n      i = end;\n    } // we've finished searching all of data\n\n\n    return results;\n  };\n\n  var findBox_1 = findBox;\n\n  var tfhd = function tfhd(data) {\n    var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4)),\n      trackId: view.getUint32(4)\n    },\n        baseDataOffsetPresent = result.flags[2] & 0x01,\n        sampleDescriptionIndexPresent = result.flags[2] & 0x02,\n        defaultSampleDurationPresent = result.flags[2] & 0x08,\n        defaultSampleSizePresent = result.flags[2] & 0x10,\n        defaultSampleFlagsPresent = result.flags[2] & 0x20,\n        durationIsEmpty = result.flags[0] & 0x010000,\n        defaultBaseIsMoof = result.flags[0] & 0x020000,\n        i;\n    i = 8;\n\n    if (baseDataOffsetPresent) {\n      i += 4; // truncate top 4 bytes\n      // FIXME: should we read the full 64 bits?\n\n      result.baseDataOffset = view.getUint32(12);\n      i += 4;\n    }\n\n    if (sampleDescriptionIndexPresent) {\n      result.sampleDescriptionIndex = view.getUint32(i);\n      i += 4;\n    }\n\n    if (defaultSampleDurationPresent) {\n      result.defaultSampleDuration = view.getUint32(i);\n      i += 4;\n    }\n\n    if (defaultSampleSizePresent) {\n      result.defaultSampleSize = view.getUint32(i);\n      i += 4;\n    }\n\n    if (defaultSampleFlagsPresent) {\n      result.defaultSampleFlags = view.getUint32(i);\n    }\n\n    if (durationIsEmpty) {\n      result.durationIsEmpty = true;\n    }\n\n    if (!baseDataOffsetPresent && defaultBaseIsMoof) {\n      result.baseDataOffsetIsMoof = true;\n    }\n\n    return result;\n  };\n\n  var parseTfhd = tfhd;\n\n  var parseSampleFlags = function parseSampleFlags(flags) {\n    return {\n      isLeading: (flags[0] & 0x0c) >>> 2,\n      dependsOn: flags[0] & 0x03,\n      isDependedOn: (flags[1] & 0xc0) >>> 6,\n      hasRedundancy: (flags[1] & 0x30) >>> 4,\n      paddingValue: (flags[1] & 0x0e) >>> 1,\n      isNonSyncSample: flags[1] & 0x01,\n      degradationPriority: flags[2] << 8 | flags[3]\n    };\n  };\n\n  var parseSampleFlags_1 = parseSampleFlags;\n\n  var trun = function trun(data) {\n    var result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4)),\n      samples: []\n    },\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        // Flag interpretation\n    dataOffsetPresent = result.flags[2] & 0x01,\n        // compare with 2nd byte of 0x1\n    firstSampleFlagsPresent = result.flags[2] & 0x04,\n        // compare with 2nd byte of 0x4\n    sampleDurationPresent = result.flags[1] & 0x01,\n        // compare with 2nd byte of 0x100\n    sampleSizePresent = result.flags[1] & 0x02,\n        // compare with 2nd byte of 0x200\n    sampleFlagsPresent = result.flags[1] & 0x04,\n        // compare with 2nd byte of 0x400\n    sampleCompositionTimeOffsetPresent = result.flags[1] & 0x08,\n        // compare with 2nd byte of 0x800\n    sampleCount = view.getUint32(4),\n        offset = 8,\n        sample;\n\n    if (dataOffsetPresent) {\n      // 32 bit signed integer\n      result.dataOffset = view.getInt32(offset);\n      offset += 4;\n    } // Overrides the flags for the first sample only. The order of\n    // optional values will be: duration, size, compositionTimeOffset\n\n\n    if (firstSampleFlagsPresent && sampleCount) {\n      sample = {\n        flags: parseSampleFlags_1(data.subarray(offset, offset + 4))\n      };\n      offset += 4;\n\n      if (sampleDurationPresent) {\n        sample.duration = view.getUint32(offset);\n        offset += 4;\n      }\n\n      if (sampleSizePresent) {\n        sample.size = view.getUint32(offset);\n        offset += 4;\n      }\n\n      if (sampleCompositionTimeOffsetPresent) {\n        if (result.version === 1) {\n          sample.compositionTimeOffset = view.getInt32(offset);\n        } else {\n          sample.compositionTimeOffset = view.getUint32(offset);\n        }\n\n        offset += 4;\n      }\n\n      result.samples.push(sample);\n      sampleCount--;\n    }\n\n    while (sampleCount--) {\n      sample = {};\n\n      if (sampleDurationPresent) {\n        sample.duration = view.getUint32(offset);\n        offset += 4;\n      }\n\n      if (sampleSizePresent) {\n        sample.size = view.getUint32(offset);\n        offset += 4;\n      }\n\n      if (sampleFlagsPresent) {\n        sample.flags = parseSampleFlags_1(data.subarray(offset, offset + 4));\n        offset += 4;\n      }\n\n      if (sampleCompositionTimeOffsetPresent) {\n        if (result.version === 1) {\n          sample.compositionTimeOffset = view.getInt32(offset);\n        } else {\n          sample.compositionTimeOffset = view.getUint32(offset);\n        }\n\n        offset += 4;\n      }\n\n      result.samples.push(sample);\n    }\n\n    return result;\n  };\n\n  var parseTrun = trun;\n\n  var toUnsigned$1 = bin.toUnsigned;\n  var getUint64$3 = numbers.getUint64;\n\n  var tfdt = function tfdt(data) {\n    var result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4))\n    };\n\n    if (result.version === 1) {\n      result.baseMediaDecodeTime = getUint64$3(data.subarray(4));\n    } else {\n      result.baseMediaDecodeTime = toUnsigned$1(data[4] << 24 | data[5] << 16 | data[6] << 8 | data[7]);\n    }\n\n    return result;\n  };\n\n  var parseTfdt = tfdt;\n\n  var toUnsigned = bin.toUnsigned;\n  var toHexString = bin.toHexString;\n  var getUint64$2 = numbers.getUint64;\n  var timescale, startTime, compositionStartTime, getVideoTrackIds, getTracks, getTimescaleFromMediaHeader;\n  /**\n   * Parses an MP4 initialization segment and extracts the timescale\n   * values for any declared tracks. Timescale values indicate the\n   * number of clock ticks per second to assume for time-based values\n   * elsewhere in the MP4.\n   *\n   * To determine the start time of an MP4, you need two pieces of\n   * information: the timescale unit and the earliest base media decode\n   * time. Multiple timescales can be specified within an MP4 but the\n   * base media decode time is always expressed in the timescale from\n   * the media header box for the track:\n   * ```\n   * moov > trak > mdia > mdhd.timescale\n   * ```\n   * @param init {Uint8Array} the bytes of the init segment\n   * @return {object} a hash of track ids to timescale values or null if\n   * the init segment is malformed.\n   */\n\n  timescale = function timescale(init) {\n    var result = {},\n        traks = findBox_1(init, ['moov', 'trak']); // mdhd timescale\n\n    return traks.reduce(function (result, trak) {\n      var tkhd, version, index, id, mdhd;\n      tkhd = findBox_1(trak, ['tkhd'])[0];\n\n      if (!tkhd) {\n        return null;\n      }\n\n      version = tkhd[0];\n      index = version === 0 ? 12 : 20;\n      id = toUnsigned(tkhd[index] << 24 | tkhd[index + 1] << 16 | tkhd[index + 2] << 8 | tkhd[index + 3]);\n      mdhd = findBox_1(trak, ['mdia', 'mdhd'])[0];\n\n      if (!mdhd) {\n        return null;\n      }\n\n      version = mdhd[0];\n      index = version === 0 ? 12 : 20;\n      result[id] = toUnsigned(mdhd[index] << 24 | mdhd[index + 1] << 16 | mdhd[index + 2] << 8 | mdhd[index + 3]);\n      return result;\n    }, result);\n  };\n  /**\n   * Determine the base media decode start time, in seconds, for an MP4\n   * fragment. If multiple fragments are specified, the earliest time is\n   * returned.\n   *\n   * The base media decode time can be parsed from track fragment\n   * metadata:\n   * ```\n   * moof > traf > tfdt.baseMediaDecodeTime\n   * ```\n   * It requires the timescale value from the mdhd to interpret.\n   *\n   * @param timescale {object} a hash of track ids to timescale values.\n   * @return {number} the earliest base media decode start time for the\n   * fragment, in seconds\n   */\n\n\n  startTime = function startTime(timescale, fragment) {\n    var trafs; // we need info from two childrend of each track fragment box\n\n    trafs = findBox_1(fragment, ['moof', 'traf']); // determine the start times for each track\n\n    var lowestTime = trafs.reduce(function (acc, traf) {\n      var tfhd = findBox_1(traf, ['tfhd'])[0]; // get the track id from the tfhd\n\n      var id = toUnsigned(tfhd[4] << 24 | tfhd[5] << 16 | tfhd[6] << 8 | tfhd[7]); // assume a 90kHz clock if no timescale was specified\n\n      var scale = timescale[id] || 90e3; // get the base media decode time from the tfdt\n\n      var tfdt = findBox_1(traf, ['tfdt'])[0];\n      var dv = new DataView(tfdt.buffer, tfdt.byteOffset, tfdt.byteLength);\n      var baseTime; // version 1 is 64 bit\n\n      if (tfdt[0] === 1) {\n        baseTime = getUint64$2(tfdt.subarray(4, 12));\n      } else {\n        baseTime = dv.getUint32(4);\n      } // convert base time to seconds if it is a valid number.\n\n\n      var seconds;\n\n      if (typeof baseTime === 'bigint') {\n        seconds = baseTime / window__default['default'].BigInt(scale);\n      } else if (typeof baseTime === 'number' && !isNaN(baseTime)) {\n        seconds = baseTime / scale;\n      }\n\n      if (seconds < Number.MAX_SAFE_INTEGER) {\n        seconds = Number(seconds);\n      }\n\n      if (seconds < acc) {\n        acc = seconds;\n      }\n\n      return acc;\n    }, Infinity);\n    return typeof lowestTime === 'bigint' || isFinite(lowestTime) ? lowestTime : 0;\n  };\n  /**\n   * Determine the composition start, in seconds, for an MP4\n   * fragment.\n   *\n   * The composition start time of a fragment can be calculated using the base\n   * media decode time, composition time offset, and timescale, as follows:\n   *\n   * compositionStartTime = (baseMediaDecodeTime + compositionTimeOffset) / timescale\n   *\n   * All of the aforementioned information is contained within a media fragment's\n   * `traf` box, except for timescale info, which comes from the initialization\n   * segment, so a track id (also contained within a `traf`) is also necessary to\n   * associate it with a timescale\n   *\n   *\n   * @param timescales {object} - a hash of track ids to timescale values.\n   * @param fragment {Unit8Array} - the bytes of a media segment\n   * @return {number} the composition start time for the fragment, in seconds\n   **/\n\n\n  compositionStartTime = function compositionStartTime(timescales, fragment) {\n    var trafBoxes = findBox_1(fragment, ['moof', 'traf']);\n    var baseMediaDecodeTime = 0;\n    var compositionTimeOffset = 0;\n    var trackId;\n\n    if (trafBoxes && trafBoxes.length) {\n      // The spec states that track run samples contained within a `traf` box are contiguous, but\n      // it does not explicitly state whether the `traf` boxes themselves are contiguous.\n      // We will assume that they are, so we only need the first to calculate start time.\n      var tfhd = findBox_1(trafBoxes[0], ['tfhd'])[0];\n      var trun = findBox_1(trafBoxes[0], ['trun'])[0];\n      var tfdt = findBox_1(trafBoxes[0], ['tfdt'])[0];\n\n      if (tfhd) {\n        var parsedTfhd = parseTfhd(tfhd);\n        trackId = parsedTfhd.trackId;\n      }\n\n      if (tfdt) {\n        var parsedTfdt = parseTfdt(tfdt);\n        baseMediaDecodeTime = parsedTfdt.baseMediaDecodeTime;\n      }\n\n      if (trun) {\n        var parsedTrun = parseTrun(trun);\n\n        if (parsedTrun.samples && parsedTrun.samples.length) {\n          compositionTimeOffset = parsedTrun.samples[0].compositionTimeOffset || 0;\n        }\n      }\n    } // Get timescale for this specific track. Assume a 90kHz clock if no timescale was\n    // specified.\n\n\n    var timescale = timescales[trackId] || 90e3; // return the composition start time, in seconds\n\n    if (typeof baseMediaDecodeTime === 'bigint') {\n      compositionTimeOffset = window__default['default'].BigInt(compositionTimeOffset);\n      timescale = window__default['default'].BigInt(timescale);\n    }\n\n    var result = (baseMediaDecodeTime + compositionTimeOffset) / timescale;\n\n    if (typeof result === 'bigint' && result < Number.MAX_SAFE_INTEGER) {\n      result = Number(result);\n    }\n\n    return result;\n  };\n  /**\n    * Find the trackIds of the video tracks in this source.\n    * Found by parsing the Handler Reference and Track Header Boxes:\n    *   moov > trak > mdia > hdlr\n    *   moov > trak > tkhd\n    *\n    * @param {Uint8Array} init - The bytes of the init segment for this source\n    * @return {Number[]} A list of trackIds\n    *\n    * @see ISO-BMFF-12/2015, Section 8.4.3\n   **/\n\n\n  getVideoTrackIds = function getVideoTrackIds(init) {\n    var traks = findBox_1(init, ['moov', 'trak']);\n    var videoTrackIds = [];\n    traks.forEach(function (trak) {\n      var hdlrs = findBox_1(trak, ['mdia', 'hdlr']);\n      var tkhds = findBox_1(trak, ['tkhd']);\n      hdlrs.forEach(function (hdlr, index) {\n        var handlerType = parseType_1(hdlr.subarray(8, 12));\n        var tkhd = tkhds[index];\n        var view;\n        var version;\n        var trackId;\n\n        if (handlerType === 'vide') {\n          view = new DataView(tkhd.buffer, tkhd.byteOffset, tkhd.byteLength);\n          version = view.getUint8(0);\n          trackId = version === 0 ? view.getUint32(12) : view.getUint32(20);\n          videoTrackIds.push(trackId);\n        }\n      });\n    });\n    return videoTrackIds;\n  };\n\n  getTimescaleFromMediaHeader = function getTimescaleFromMediaHeader(mdhd) {\n    // mdhd is a FullBox, meaning it will have its own version as the first byte\n    var version = mdhd[0];\n    var index = version === 0 ? 12 : 20;\n    return toUnsigned(mdhd[index] << 24 | mdhd[index + 1] << 16 | mdhd[index + 2] << 8 | mdhd[index + 3]);\n  };\n  /**\n   * Get all the video, audio, and hint tracks from a non fragmented\n   * mp4 segment\n   */\n\n\n  getTracks = function getTracks(init) {\n    var traks = findBox_1(init, ['moov', 'trak']);\n    var tracks = [];\n    traks.forEach(function (trak) {\n      var track = {};\n      var tkhd = findBox_1(trak, ['tkhd'])[0];\n      var view, tkhdVersion; // id\n\n      if (tkhd) {\n        view = new DataView(tkhd.buffer, tkhd.byteOffset, tkhd.byteLength);\n        tkhdVersion = view.getUint8(0);\n        track.id = tkhdVersion === 0 ? view.getUint32(12) : view.getUint32(20);\n      }\n\n      var hdlr = findBox_1(trak, ['mdia', 'hdlr'])[0]; // type\n\n      if (hdlr) {\n        var type = parseType_1(hdlr.subarray(8, 12));\n\n        if (type === 'vide') {\n          track.type = 'video';\n        } else if (type === 'soun') {\n          track.type = 'audio';\n        } else {\n          track.type = type;\n        }\n      } // codec\n\n\n      var stsd = findBox_1(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n\n      if (stsd) {\n        var sampleDescriptions = stsd.subarray(8); // gives the codec type string\n\n        track.codec = parseType_1(sampleDescriptions.subarray(4, 8));\n        var codecBox = findBox_1(sampleDescriptions, [track.codec])[0];\n        var codecConfig, codecConfigType;\n\n        if (codecBox) {\n          // https://tools.ietf.org/html/rfc6381#section-3.3\n          if (/^[asm]vc[1-9]$/i.test(track.codec)) {\n            // we don't need anything but the \"config\" parameter of the\n            // avc1 codecBox\n            codecConfig = codecBox.subarray(78);\n            codecConfigType = parseType_1(codecConfig.subarray(4, 8));\n\n            if (codecConfigType === 'avcC' && codecConfig.length > 11) {\n              track.codec += '.'; // left padded with zeroes for single digit hex\n              // profile idc\n\n              track.codec += toHexString(codecConfig[9]); // the byte containing the constraint_set flags\n\n              track.codec += toHexString(codecConfig[10]); // level idc\n\n              track.codec += toHexString(codecConfig[11]);\n            } else {\n              // TODO: show a warning that we couldn't parse the codec\n              // and are using the default\n              track.codec = 'avc1.4d400d';\n            }\n          } else if (/^mp4[a,v]$/i.test(track.codec)) {\n            // we do not need anything but the streamDescriptor of the mp4a codecBox\n            codecConfig = codecBox.subarray(28);\n            codecConfigType = parseType_1(codecConfig.subarray(4, 8));\n\n            if (codecConfigType === 'esds' && codecConfig.length > 20 && codecConfig[19] !== 0) {\n              track.codec += '.' + toHexString(codecConfig[19]); // this value is only a single digit\n\n              track.codec += '.' + toHexString(codecConfig[20] >>> 2 & 0x3f).replace(/^0/, '');\n            } else {\n              // TODO: show a warning that we couldn't parse the codec\n              // and are using the default\n              track.codec = 'mp4a.40.2';\n            }\n          } else {\n            // flac, opus, etc\n            track.codec = track.codec.toLowerCase();\n          }\n        }\n      }\n\n      var mdhd = findBox_1(trak, ['mdia', 'mdhd'])[0];\n\n      if (mdhd) {\n        track.timescale = getTimescaleFromMediaHeader(mdhd);\n      }\n\n      tracks.push(track);\n    });\n    return tracks;\n  };\n\n  var probe$2 = {\n    // export mp4 inspector's findBox and parseType for backwards compatibility\n    findBox: findBox_1,\n    parseType: parseType_1,\n    timescale: timescale,\n    startTime: startTime,\n    compositionStartTime: compositionStartTime,\n    videoTrackIds: getVideoTrackIds,\n    tracks: getTracks,\n    getTimescaleFromMediaHeader: getTimescaleFromMediaHeader\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n  // Convert an array of nal units into an array of frames with each frame being\n  // composed of the nal units that make up that frame\n  // Also keep track of cummulative data about the frame from the nal units such\n  // as the frame duration, starting pts, etc.\n  var groupNalsIntoFrames = function groupNalsIntoFrames(nalUnits) {\n    var i,\n        currentNal,\n        currentFrame = [],\n        frames = []; // TODO added for LHLS, make sure this is OK\n\n    frames.byteLength = 0;\n    frames.nalCount = 0;\n    frames.duration = 0;\n    currentFrame.byteLength = 0;\n\n    for (i = 0; i < nalUnits.length; i++) {\n      currentNal = nalUnits[i]; // Split on 'aud'-type nal units\n\n      if (currentNal.nalUnitType === 'access_unit_delimiter_rbsp') {\n        // Since the very first nal unit is expected to be an AUD\n        // only push to the frames array when currentFrame is not empty\n        if (currentFrame.length) {\n          currentFrame.duration = currentNal.dts - currentFrame.dts; // TODO added for LHLS, make sure this is OK\n\n          frames.byteLength += currentFrame.byteLength;\n          frames.nalCount += currentFrame.length;\n          frames.duration += currentFrame.duration;\n          frames.push(currentFrame);\n        }\n\n        currentFrame = [currentNal];\n        currentFrame.byteLength = currentNal.data.byteLength;\n        currentFrame.pts = currentNal.pts;\n        currentFrame.dts = currentNal.dts;\n      } else {\n        // Specifically flag key frames for ease of use later\n        if (currentNal.nalUnitType === 'slice_layer_without_partitioning_rbsp_idr') {\n          currentFrame.keyFrame = true;\n        }\n\n        currentFrame.duration = currentNal.dts - currentFrame.dts;\n        currentFrame.byteLength += currentNal.data.byteLength;\n        currentFrame.push(currentNal);\n      }\n    } // For the last frame, use the duration of the previous frame if we\n    // have nothing better to go on\n\n\n    if (frames.length && (!currentFrame.duration || currentFrame.duration <= 0)) {\n      currentFrame.duration = frames[frames.length - 1].duration;\n    } // Push the final frame\n    // TODO added for LHLS, make sure this is OK\n\n\n    frames.byteLength += currentFrame.byteLength;\n    frames.nalCount += currentFrame.length;\n    frames.duration += currentFrame.duration;\n    frames.push(currentFrame);\n    return frames;\n  }; // Convert an array of frames into an array of Gop with each Gop being composed\n  // of the frames that make up that Gop\n  // Also keep track of cummulative data about the Gop from the frames such as the\n  // Gop duration, starting pts, etc.\n\n\n  var groupFramesIntoGops = function groupFramesIntoGops(frames) {\n    var i,\n        currentFrame,\n        currentGop = [],\n        gops = []; // We must pre-set some of the values on the Gop since we\n    // keep running totals of these values\n\n    currentGop.byteLength = 0;\n    currentGop.nalCount = 0;\n    currentGop.duration = 0;\n    currentGop.pts = frames[0].pts;\n    currentGop.dts = frames[0].dts; // store some metadata about all the Gops\n\n    gops.byteLength = 0;\n    gops.nalCount = 0;\n    gops.duration = 0;\n    gops.pts = frames[0].pts;\n    gops.dts = frames[0].dts;\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n\n      if (currentFrame.keyFrame) {\n        // Since the very first frame is expected to be an keyframe\n        // only push to the gops array when currentGop is not empty\n        if (currentGop.length) {\n          gops.push(currentGop);\n          gops.byteLength += currentGop.byteLength;\n          gops.nalCount += currentGop.nalCount;\n          gops.duration += currentGop.duration;\n        }\n\n        currentGop = [currentFrame];\n        currentGop.nalCount = currentFrame.length;\n        currentGop.byteLength = currentFrame.byteLength;\n        currentGop.pts = currentFrame.pts;\n        currentGop.dts = currentFrame.dts;\n        currentGop.duration = currentFrame.duration;\n      } else {\n        currentGop.duration += currentFrame.duration;\n        currentGop.nalCount += currentFrame.length;\n        currentGop.byteLength += currentFrame.byteLength;\n        currentGop.push(currentFrame);\n      }\n    }\n\n    if (gops.length && currentGop.duration <= 0) {\n      currentGop.duration = gops[gops.length - 1].duration;\n    }\n\n    gops.byteLength += currentGop.byteLength;\n    gops.nalCount += currentGop.nalCount;\n    gops.duration += currentGop.duration; // push the final Gop\n\n    gops.push(currentGop);\n    return gops;\n  };\n  /*\n   * Search for the first keyframe in the GOPs and throw away all frames\n   * until that keyframe. Then extend the duration of the pulled keyframe\n   * and pull the PTS and DTS of the keyframe so that it covers the time\n   * range of the frames that were disposed.\n   *\n   * @param {Array} gops video GOPs\n   * @returns {Array} modified video GOPs\n   */\n\n\n  var extendFirstKeyFrame = function extendFirstKeyFrame(gops) {\n    var currentGop;\n\n    if (!gops[0][0].keyFrame && gops.length > 1) {\n      // Remove the first GOP\n      currentGop = gops.shift();\n      gops.byteLength -= currentGop.byteLength;\n      gops.nalCount -= currentGop.nalCount; // Extend the first frame of what is now the\n      // first gop to cover the time period of the\n      // frames we just removed\n\n      gops[0][0].dts = currentGop.dts;\n      gops[0][0].pts = currentGop.pts;\n      gops[0][0].duration += currentGop.duration;\n    }\n\n    return gops;\n  };\n  /**\n   * Default sample object\n   * see ISO/IEC 14496-12:2012, section 8.6.4.3\n   */\n\n\n  var createDefaultSample = function createDefaultSample() {\n    return {\n      size: 0,\n      flags: {\n        isLeading: 0,\n        dependsOn: 1,\n        isDependedOn: 0,\n        hasRedundancy: 0,\n        degradationPriority: 0,\n        isNonSyncSample: 1\n      }\n    };\n  };\n  /*\n   * Collates information from a video frame into an object for eventual\n   * entry into an MP4 sample table.\n   *\n   * @param {Object} frame the video frame\n   * @param {Number} dataOffset the byte offset to position the sample\n   * @return {Object} object containing sample table info for a frame\n   */\n\n\n  var sampleForFrame = function sampleForFrame(frame, dataOffset) {\n    var sample = createDefaultSample();\n    sample.dataOffset = dataOffset;\n    sample.compositionTimeOffset = frame.pts - frame.dts;\n    sample.duration = frame.duration;\n    sample.size = 4 * frame.length; // Space for nal unit size\n\n    sample.size += frame.byteLength;\n\n    if (frame.keyFrame) {\n      sample.flags.dependsOn = 2;\n      sample.flags.isNonSyncSample = 0;\n    }\n\n    return sample;\n  }; // generate the track's sample table from an array of gops\n\n\n  var generateSampleTable$1 = function generateSampleTable(gops, baseDataOffset) {\n    var h,\n        i,\n        sample,\n        currentGop,\n        currentFrame,\n        dataOffset = baseDataOffset || 0,\n        samples = [];\n\n    for (h = 0; h < gops.length; h++) {\n      currentGop = gops[h];\n\n      for (i = 0; i < currentGop.length; i++) {\n        currentFrame = currentGop[i];\n        sample = sampleForFrame(currentFrame, dataOffset);\n        dataOffset += sample.size;\n        samples.push(sample);\n      }\n    }\n\n    return samples;\n  }; // generate the track's raw mdat data from an array of gops\n\n\n  var concatenateNalData = function concatenateNalData(gops) {\n    var h,\n        i,\n        j,\n        currentGop,\n        currentFrame,\n        currentNal,\n        dataOffset = 0,\n        nalsByteLength = gops.byteLength,\n        numberOfNals = gops.nalCount,\n        totalByteLength = nalsByteLength + 4 * numberOfNals,\n        data = new Uint8Array(totalByteLength),\n        view = new DataView(data.buffer); // For each Gop..\n\n    for (h = 0; h < gops.length; h++) {\n      currentGop = gops[h]; // For each Frame..\n\n      for (i = 0; i < currentGop.length; i++) {\n        currentFrame = currentGop[i]; // For each NAL..\n\n        for (j = 0; j < currentFrame.length; j++) {\n          currentNal = currentFrame[j];\n          view.setUint32(dataOffset, currentNal.data.byteLength);\n          dataOffset += 4;\n          data.set(currentNal.data, dataOffset);\n          dataOffset += currentNal.data.byteLength;\n        }\n      }\n    }\n\n    return data;\n  }; // generate the track's sample table from a frame\n\n\n  var generateSampleTableForFrame = function generateSampleTableForFrame(frame, baseDataOffset) {\n    var sample,\n        dataOffset = baseDataOffset || 0,\n        samples = [];\n    sample = sampleForFrame(frame, dataOffset);\n    samples.push(sample);\n    return samples;\n  }; // generate the track's raw mdat data from a frame\n\n\n  var concatenateNalDataForFrame = function concatenateNalDataForFrame(frame) {\n    var i,\n        currentNal,\n        dataOffset = 0,\n        nalsByteLength = frame.byteLength,\n        numberOfNals = frame.length,\n        totalByteLength = nalsByteLength + 4 * numberOfNals,\n        data = new Uint8Array(totalByteLength),\n        view = new DataView(data.buffer); // For each NAL..\n\n    for (i = 0; i < frame.length; i++) {\n      currentNal = frame[i];\n      view.setUint32(dataOffset, currentNal.data.byteLength);\n      dataOffset += 4;\n      data.set(currentNal.data, dataOffset);\n      dataOffset += currentNal.data.byteLength;\n    }\n\n    return data;\n  };\n\n  var frameUtils = {\n    groupNalsIntoFrames: groupNalsIntoFrames,\n    groupFramesIntoGops: groupFramesIntoGops,\n    extendFirstKeyFrame: extendFirstKeyFrame,\n    generateSampleTable: generateSampleTable$1,\n    concatenateNalData: concatenateNalData,\n    generateSampleTableForFrame: generateSampleTableForFrame,\n    concatenateNalDataForFrame: concatenateNalDataForFrame\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n  var highPrefix = [33, 16, 5, 32, 164, 27];\n  var lowPrefix = [33, 65, 108, 84, 1, 2, 4, 8, 168, 2, 4, 8, 17, 191, 252];\n\n  var zeroFill = function zeroFill(count) {\n    var a = [];\n\n    while (count--) {\n      a.push(0);\n    }\n\n    return a;\n  };\n\n  var makeTable = function makeTable(metaTable) {\n    return Object.keys(metaTable).reduce(function (obj, key) {\n      obj[key] = new Uint8Array(metaTable[key].reduce(function (arr, part) {\n        return arr.concat(part);\n      }, []));\n      return obj;\n    }, {});\n  };\n\n  var silence;\n\n  var silence_1 = function silence_1() {\n    if (!silence) {\n      // Frames-of-silence to use for filling in missing AAC frames\n      var coneOfSilence = {\n        96000: [highPrefix, [227, 64], zeroFill(154), [56]],\n        88200: [highPrefix, [231], zeroFill(170), [56]],\n        64000: [highPrefix, [248, 192], zeroFill(240), [56]],\n        48000: [highPrefix, [255, 192], zeroFill(268), [55, 148, 128], zeroFill(54), [112]],\n        44100: [highPrefix, [255, 192], zeroFill(268), [55, 163, 128], zeroFill(84), [112]],\n        32000: [highPrefix, [255, 192], zeroFill(268), [55, 234], zeroFill(226), [112]],\n        24000: [highPrefix, [255, 192], zeroFill(268), [55, 255, 128], zeroFill(268), [111, 112], zeroFill(126), [224]],\n        16000: [highPrefix, [255, 192], zeroFill(268), [55, 255, 128], zeroFill(268), [111, 255], zeroFill(269), [223, 108], zeroFill(195), [1, 192]],\n        12000: [lowPrefix, zeroFill(268), [3, 127, 248], zeroFill(268), [6, 255, 240], zeroFill(268), [13, 255, 224], zeroFill(268), [27, 253, 128], zeroFill(259), [56]],\n        11025: [lowPrefix, zeroFill(268), [3, 127, 248], zeroFill(268), [6, 255, 240], zeroFill(268), [13, 255, 224], zeroFill(268), [27, 255, 192], zeroFill(268), [55, 175, 128], zeroFill(108), [112]],\n        8000: [lowPrefix, zeroFill(268), [3, 121, 16], zeroFill(47), [7]]\n      };\n      silence = makeTable(coneOfSilence);\n    }\n\n    return silence;\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  /**\n   * Sum the `byteLength` properties of the data in each AAC frame\n   */\n\n  var sumFrameByteLengths = function sumFrameByteLengths(array) {\n    var i,\n        currentObj,\n        sum = 0; // sum the byteLength's all each nal unit in the frame\n\n    for (i = 0; i < array.length; i++) {\n      currentObj = array[i];\n      sum += currentObj.data.byteLength;\n    }\n\n    return sum;\n  }; // Possibly pad (prefix) the audio track with silence if appending this track\n  // would lead to the introduction of a gap in the audio buffer\n\n\n  var prefixWithSilence = function prefixWithSilence(track, frames, audioAppendStartTs, videoBaseMediaDecodeTime) {\n    var baseMediaDecodeTimeTs,\n        frameDuration = 0,\n        audioGapDuration = 0,\n        audioFillFrameCount = 0,\n        audioFillDuration = 0,\n        silentFrame,\n        i,\n        firstFrame;\n\n    if (!frames.length) {\n      return;\n    }\n\n    baseMediaDecodeTimeTs = clock.audioTsToVideoTs(track.baseMediaDecodeTime, track.samplerate); // determine frame clock duration based on sample rate, round up to avoid overfills\n\n    frameDuration = Math.ceil(clock.ONE_SECOND_IN_TS / (track.samplerate / 1024));\n\n    if (audioAppendStartTs && videoBaseMediaDecodeTime) {\n      // insert the shortest possible amount (audio gap or audio to video gap)\n      audioGapDuration = baseMediaDecodeTimeTs - Math.max(audioAppendStartTs, videoBaseMediaDecodeTime); // number of full frames in the audio gap\n\n      audioFillFrameCount = Math.floor(audioGapDuration / frameDuration);\n      audioFillDuration = audioFillFrameCount * frameDuration;\n    } // don't attempt to fill gaps smaller than a single frame or larger\n    // than a half second\n\n\n    if (audioFillFrameCount < 1 || audioFillDuration > clock.ONE_SECOND_IN_TS / 2) {\n      return;\n    }\n\n    silentFrame = silence_1()[track.samplerate];\n\n    if (!silentFrame) {\n      // we don't have a silent frame pregenerated for the sample rate, so use a frame\n      // from the content instead\n      silentFrame = frames[0].data;\n    }\n\n    for (i = 0; i < audioFillFrameCount; i++) {\n      firstFrame = frames[0];\n      frames.splice(0, 0, {\n        data: silentFrame,\n        dts: firstFrame.dts - frameDuration,\n        pts: firstFrame.pts - frameDuration\n      });\n    }\n\n    track.baseMediaDecodeTime -= Math.floor(clock.videoTsToAudioTs(audioFillDuration, track.samplerate));\n    return audioFillDuration;\n  }; // If the audio segment extends before the earliest allowed dts\n  // value, remove AAC frames until starts at or after the earliest\n  // allowed DTS so that we don't end up with a negative baseMedia-\n  // DecodeTime for the audio track\n\n\n  var trimAdtsFramesByEarliestDts = function trimAdtsFramesByEarliestDts(adtsFrames, track, earliestAllowedDts) {\n    if (track.minSegmentDts >= earliestAllowedDts) {\n      return adtsFrames;\n    } // We will need to recalculate the earliest segment Dts\n\n\n    track.minSegmentDts = Infinity;\n    return adtsFrames.filter(function (currentFrame) {\n      // If this is an allowed frame, keep it and record it's Dts\n      if (currentFrame.dts >= earliestAllowedDts) {\n        track.minSegmentDts = Math.min(track.minSegmentDts, currentFrame.dts);\n        track.minSegmentPts = track.minSegmentDts;\n        return true;\n      } // Otherwise, discard it\n\n\n      return false;\n    });\n  }; // generate the track's raw mdat data from an array of frames\n\n\n  var generateSampleTable = function generateSampleTable(frames) {\n    var i,\n        currentFrame,\n        samples = [];\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n      samples.push({\n        size: currentFrame.data.byteLength,\n        duration: 1024 // For AAC audio, all samples contain 1024 samples\n\n      });\n    }\n\n    return samples;\n  }; // generate the track's sample table from an array of frames\n\n\n  var concatenateFrameData = function concatenateFrameData(frames) {\n    var i,\n        currentFrame,\n        dataOffset = 0,\n        data = new Uint8Array(sumFrameByteLengths(frames));\n\n    for (i = 0; i < frames.length; i++) {\n      currentFrame = frames[i];\n      data.set(currentFrame.data, dataOffset);\n      dataOffset += currentFrame.data.byteLength;\n    }\n\n    return data;\n  };\n\n  var audioFrameUtils = {\n    prefixWithSilence: prefixWithSilence,\n    trimAdtsFramesByEarliestDts: trimAdtsFramesByEarliestDts,\n    generateSampleTable: generateSampleTable,\n    concatenateFrameData: concatenateFrameData\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var ONE_SECOND_IN_TS$3 = clock.ONE_SECOND_IN_TS;\n  /**\n   * Store information about the start and end of the track and the\n   * duration for each frame/sample we process in order to calculate\n   * the baseMediaDecodeTime\n   */\n\n  var collectDtsInfo = function collectDtsInfo(track, data) {\n    if (typeof data.pts === 'number') {\n      if (track.timelineStartInfo.pts === undefined) {\n        track.timelineStartInfo.pts = data.pts;\n      }\n\n      if (track.minSegmentPts === undefined) {\n        track.minSegmentPts = data.pts;\n      } else {\n        track.minSegmentPts = Math.min(track.minSegmentPts, data.pts);\n      }\n\n      if (track.maxSegmentPts === undefined) {\n        track.maxSegmentPts = data.pts;\n      } else {\n        track.maxSegmentPts = Math.max(track.maxSegmentPts, data.pts);\n      }\n    }\n\n    if (typeof data.dts === 'number') {\n      if (track.timelineStartInfo.dts === undefined) {\n        track.timelineStartInfo.dts = data.dts;\n      }\n\n      if (track.minSegmentDts === undefined) {\n        track.minSegmentDts = data.dts;\n      } else {\n        track.minSegmentDts = Math.min(track.minSegmentDts, data.dts);\n      }\n\n      if (track.maxSegmentDts === undefined) {\n        track.maxSegmentDts = data.dts;\n      } else {\n        track.maxSegmentDts = Math.max(track.maxSegmentDts, data.dts);\n      }\n    }\n  };\n  /**\n   * Clear values used to calculate the baseMediaDecodeTime between\n   * tracks\n   */\n\n\n  var clearDtsInfo = function clearDtsInfo(track) {\n    delete track.minSegmentDts;\n    delete track.maxSegmentDts;\n    delete track.minSegmentPts;\n    delete track.maxSegmentPts;\n  };\n  /**\n   * Calculate the track's baseMediaDecodeTime based on the earliest\n   * DTS the transmuxer has ever seen and the minimum DTS for the\n   * current track\n   * @param track {object} track metadata configuration\n   * @param keepOriginalTimestamps {boolean} If true, keep the timestamps\n   *        in the source; false to adjust the first segment to start at 0.\n   */\n\n\n  var calculateTrackBaseMediaDecodeTime = function calculateTrackBaseMediaDecodeTime(track, keepOriginalTimestamps) {\n    var baseMediaDecodeTime,\n        scale,\n        minSegmentDts = track.minSegmentDts; // Optionally adjust the time so the first segment starts at zero.\n\n    if (!keepOriginalTimestamps) {\n      minSegmentDts -= track.timelineStartInfo.dts;\n    } // track.timelineStartInfo.baseMediaDecodeTime is the location, in time, where\n    // we want the start of the first segment to be placed\n\n\n    baseMediaDecodeTime = track.timelineStartInfo.baseMediaDecodeTime; // Add to that the distance this segment is from the very first\n\n    baseMediaDecodeTime += minSegmentDts; // baseMediaDecodeTime must not become negative\n\n    baseMediaDecodeTime = Math.max(0, baseMediaDecodeTime);\n\n    if (track.type === 'audio') {\n      // Audio has a different clock equal to the sampling_rate so we need to\n      // scale the PTS values into the clock rate of the track\n      scale = track.samplerate / ONE_SECOND_IN_TS$3;\n      baseMediaDecodeTime *= scale;\n      baseMediaDecodeTime = Math.floor(baseMediaDecodeTime);\n    }\n\n    return baseMediaDecodeTime;\n  };\n\n  var trackDecodeInfo = {\n    clearDtsInfo: clearDtsInfo,\n    calculateTrackBaseMediaDecodeTime: calculateTrackBaseMediaDecodeTime,\n    collectDtsInfo: collectDtsInfo\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   *\n   * Reads in-band caption information from a video elementary\n   * stream. Captions must follow the CEA-708 standard for injection\n   * into an MPEG-2 transport streams.\n   * @see https://en.wikipedia.org/wiki/CEA-708\n   * @see https://www.gpo.gov/fdsys/pkg/CFR-2007-title47-vol1/pdf/CFR-2007-title47-vol1-sec15-119.pdf\n   */\n  // payload type field to indicate how they are to be\n  // interpreted. CEAS-708 caption content is always transmitted with\n  // payload type 0x04.\n\n  var USER_DATA_REGISTERED_ITU_T_T35 = 4,\n      RBSP_TRAILING_BITS = 128;\n  /**\n    * Parse a supplemental enhancement information (SEI) NAL unit.\n    * Stops parsing once a message of type ITU T T35 has been found.\n    *\n    * @param bytes {Uint8Array} the bytes of a SEI NAL unit\n    * @return {object} the parsed SEI payload\n    * @see Rec. ITU-T H.264, 7.3.2.3.1\n    */\n\n  var parseSei = function parseSei(bytes) {\n    var i = 0,\n        result = {\n      payloadType: -1,\n      payloadSize: 0\n    },\n        payloadType = 0,\n        payloadSize = 0; // go through the sei_rbsp parsing each each individual sei_message\n\n    while (i < bytes.byteLength) {\n      // stop once we have hit the end of the sei_rbsp\n      if (bytes[i] === RBSP_TRAILING_BITS) {\n        break;\n      } // Parse payload type\n\n\n      while (bytes[i] === 0xFF) {\n        payloadType += 255;\n        i++;\n      }\n\n      payloadType += bytes[i++]; // Parse payload size\n\n      while (bytes[i] === 0xFF) {\n        payloadSize += 255;\n        i++;\n      }\n\n      payloadSize += bytes[i++]; // this sei_message is a 608/708 caption so save it and break\n      // there can only ever be one caption message in a frame's sei\n\n      if (!result.payload && payloadType === USER_DATA_REGISTERED_ITU_T_T35) {\n        var userIdentifier = String.fromCharCode(bytes[i + 3], bytes[i + 4], bytes[i + 5], bytes[i + 6]);\n\n        if (userIdentifier === 'GA94') {\n          result.payloadType = payloadType;\n          result.payloadSize = payloadSize;\n          result.payload = bytes.subarray(i, i + payloadSize);\n          break;\n        } else {\n          result.payload = void 0;\n        }\n      } // skip the payload and parse the next message\n\n\n      i += payloadSize;\n      payloadType = 0;\n      payloadSize = 0;\n    }\n\n    return result;\n  }; // see ANSI/SCTE 128-1 (2013), section 8.1\n\n\n  var parseUserData = function parseUserData(sei) {\n    // itu_t_t35_contry_code must be 181 (United States) for\n    // captions\n    if (sei.payload[0] !== 181) {\n      return null;\n    } // itu_t_t35_provider_code should be 49 (ATSC) for captions\n\n\n    if ((sei.payload[1] << 8 | sei.payload[2]) !== 49) {\n      return null;\n    } // the user_identifier should be \"GA94\" to indicate ATSC1 data\n\n\n    if (String.fromCharCode(sei.payload[3], sei.payload[4], sei.payload[5], sei.payload[6]) !== 'GA94') {\n      return null;\n    } // finally, user_data_type_code should be 0x03 for caption data\n\n\n    if (sei.payload[7] !== 0x03) {\n      return null;\n    } // return the user_data_type_structure and strip the trailing\n    // marker bits\n\n\n    return sei.payload.subarray(8, sei.payload.length - 1);\n  }; // see CEA-708-D, section 4.4\n\n\n  var parseCaptionPackets = function parseCaptionPackets(pts, userData) {\n    var results = [],\n        i,\n        count,\n        offset,\n        data; // if this is just filler, return immediately\n\n    if (!(userData[0] & 0x40)) {\n      return results;\n    } // parse out the cc_data_1 and cc_data_2 fields\n\n\n    count = userData[0] & 0x1f;\n\n    for (i = 0; i < count; i++) {\n      offset = i * 3;\n      data = {\n        type: userData[offset + 2] & 0x03,\n        pts: pts\n      }; // capture cc data when cc_valid is 1\n\n      if (userData[offset + 2] & 0x04) {\n        data.ccData = userData[offset + 3] << 8 | userData[offset + 4];\n        results.push(data);\n      }\n    }\n\n    return results;\n  };\n\n  var discardEmulationPreventionBytes$1 = function discardEmulationPreventionBytes(data) {\n    var length = data.byteLength,\n        emulationPreventionBytesPositions = [],\n        i = 1,\n        newLength,\n        newData; // Find all `Emulation Prevention Bytes`\n\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        emulationPreventionBytesPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    } // If no Emulation Prevention Bytes were found just return the original\n    // array\n\n\n    if (emulationPreventionBytesPositions.length === 0) {\n      return data;\n    } // Create a new array to hold the NAL unit data\n\n\n    newLength = length - emulationPreventionBytesPositions.length;\n    newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === emulationPreventionBytesPositions[0]) {\n        // Skip this byte\n        sourceIndex++; // Remove this position index\n\n        emulationPreventionBytesPositions.shift();\n      }\n\n      newData[i] = data[sourceIndex];\n    }\n\n    return newData;\n  }; // exports\n\n\n  var captionPacketParser = {\n    parseSei: parseSei,\n    parseUserData: parseUserData,\n    parseCaptionPackets: parseCaptionPackets,\n    discardEmulationPreventionBytes: discardEmulationPreventionBytes$1,\n    USER_DATA_REGISTERED_ITU_T_T35: USER_DATA_REGISTERED_ITU_T_T35\n  };\n\n  // Link To Transport\n  // -----------------\n\n\n  var CaptionStream$1 = function CaptionStream(options) {\n    options = options || {};\n    CaptionStream.prototype.init.call(this); // parse708captions flag, default to true\n\n    this.parse708captions_ = typeof options.parse708captions === 'boolean' ? options.parse708captions : true;\n    this.captionPackets_ = [];\n    this.ccStreams_ = [new Cea608Stream(0, 0), // eslint-disable-line no-use-before-define\n    new Cea608Stream(0, 1), // eslint-disable-line no-use-before-define\n    new Cea608Stream(1, 0), // eslint-disable-line no-use-before-define\n    new Cea608Stream(1, 1) // eslint-disable-line no-use-before-define\n    ];\n\n    if (this.parse708captions_) {\n      this.cc708Stream_ = new Cea708Stream({\n        captionServices: options.captionServices\n      }); // eslint-disable-line no-use-before-define\n    }\n\n    this.reset(); // forward data and done events from CCs to this CaptionStream\n\n    this.ccStreams_.forEach(function (cc) {\n      cc.on('data', this.trigger.bind(this, 'data'));\n      cc.on('partialdone', this.trigger.bind(this, 'partialdone'));\n      cc.on('done', this.trigger.bind(this, 'done'));\n    }, this);\n\n    if (this.parse708captions_) {\n      this.cc708Stream_.on('data', this.trigger.bind(this, 'data'));\n      this.cc708Stream_.on('partialdone', this.trigger.bind(this, 'partialdone'));\n      this.cc708Stream_.on('done', this.trigger.bind(this, 'done'));\n    }\n  };\n\n  CaptionStream$1.prototype = new stream();\n\n  CaptionStream$1.prototype.push = function (event) {\n    var sei, userData, newCaptionPackets; // only examine SEI NALs\n\n    if (event.nalUnitType !== 'sei_rbsp') {\n      return;\n    } // parse the sei\n\n\n    sei = captionPacketParser.parseSei(event.escapedRBSP); // no payload data, skip\n\n    if (!sei.payload) {\n      return;\n    } // ignore everything but user_data_registered_itu_t_t35\n\n\n    if (sei.payloadType !== captionPacketParser.USER_DATA_REGISTERED_ITU_T_T35) {\n      return;\n    } // parse out the user data payload\n\n\n    userData = captionPacketParser.parseUserData(sei); // ignore unrecognized userData\n\n    if (!userData) {\n      return;\n    } // Sometimes, the same segment # will be downloaded twice. To stop the\n    // caption data from being processed twice, we track the latest dts we've\n    // received and ignore everything with a dts before that. However, since\n    // data for a specific dts can be split across packets on either side of\n    // a segment boundary, we need to make sure we *don't* ignore the packets\n    // from the *next* segment that have dts === this.latestDts_. By constantly\n    // tracking the number of packets received with dts === this.latestDts_, we\n    // know how many should be ignored once we start receiving duplicates.\n\n\n    if (event.dts < this.latestDts_) {\n      // We've started getting older data, so set the flag.\n      this.ignoreNextEqualDts_ = true;\n      return;\n    } else if (event.dts === this.latestDts_ && this.ignoreNextEqualDts_) {\n      this.numSameDts_--;\n\n      if (!this.numSameDts_) {\n        // We've received the last duplicate packet, time to start processing again\n        this.ignoreNextEqualDts_ = false;\n      }\n\n      return;\n    } // parse out CC data packets and save them for later\n\n\n    newCaptionPackets = captionPacketParser.parseCaptionPackets(event.pts, userData);\n    this.captionPackets_ = this.captionPackets_.concat(newCaptionPackets);\n\n    if (this.latestDts_ !== event.dts) {\n      this.numSameDts_ = 0;\n    }\n\n    this.numSameDts_++;\n    this.latestDts_ = event.dts;\n  };\n\n  CaptionStream$1.prototype.flushCCStreams = function (flushType) {\n    this.ccStreams_.forEach(function (cc) {\n      return flushType === 'flush' ? cc.flush() : cc.partialFlush();\n    }, this);\n  };\n\n  CaptionStream$1.prototype.flushStream = function (flushType) {\n    // make sure we actually parsed captions before proceeding\n    if (!this.captionPackets_.length) {\n      this.flushCCStreams(flushType);\n      return;\n    } // In Chrome, the Array#sort function is not stable so add a\n    // presortIndex that we can use to ensure we get a stable-sort\n\n\n    this.captionPackets_.forEach(function (elem, idx) {\n      elem.presortIndex = idx;\n    }); // sort caption byte-pairs based on their PTS values\n\n    this.captionPackets_.sort(function (a, b) {\n      if (a.pts === b.pts) {\n        return a.presortIndex - b.presortIndex;\n      }\n\n      return a.pts - b.pts;\n    });\n    this.captionPackets_.forEach(function (packet) {\n      if (packet.type < 2) {\n        // Dispatch packet to the right Cea608Stream\n        this.dispatchCea608Packet(packet);\n      } else {\n        // Dispatch packet to the Cea708Stream\n        this.dispatchCea708Packet(packet);\n      }\n    }, this);\n    this.captionPackets_.length = 0;\n    this.flushCCStreams(flushType);\n  };\n\n  CaptionStream$1.prototype.flush = function () {\n    return this.flushStream('flush');\n  }; // Only called if handling partial data\n\n\n  CaptionStream$1.prototype.partialFlush = function () {\n    return this.flushStream('partialFlush');\n  };\n\n  CaptionStream$1.prototype.reset = function () {\n    this.latestDts_ = null;\n    this.ignoreNextEqualDts_ = false;\n    this.numSameDts_ = 0;\n    this.activeCea608Channel_ = [null, null];\n    this.ccStreams_.forEach(function (ccStream) {\n      ccStream.reset();\n    });\n  }; // From the CEA-608 spec:\n\n  /*\n   * When XDS sub-packets are interleaved with other services, the end of each sub-packet shall be followed\n   * by a control pair to change to a different service. When any of the control codes from 0x10 to 0x1F is\n   * used to begin a control code pair, it indicates the return to captioning or Text data. The control code pair\n   * and subsequent data should then be processed according to the FCC rules. It may be necessary for the\n   * line 21 data encoder to automatically insert a control code pair (i.e. RCL, RU2, RU3, RU4, RDC, or RTD)\n   * to switch to captioning or Text.\n  */\n  // With that in mind, we ignore any data between an XDS control code and a\n  // subsequent closed-captioning control code.\n\n\n  CaptionStream$1.prototype.dispatchCea608Packet = function (packet) {\n    // NOTE: packet.type is the CEA608 field\n    if (this.setsTextOrXDSActive(packet)) {\n      this.activeCea608Channel_[packet.type] = null;\n    } else if (this.setsChannel1Active(packet)) {\n      this.activeCea608Channel_[packet.type] = 0;\n    } else if (this.setsChannel2Active(packet)) {\n      this.activeCea608Channel_[packet.type] = 1;\n    }\n\n    if (this.activeCea608Channel_[packet.type] === null) {\n      // If we haven't received anything to set the active channel, or the\n      // packets are Text/XDS data, discard the data; we don't want jumbled\n      // captions\n      return;\n    }\n\n    this.ccStreams_[(packet.type << 1) + this.activeCea608Channel_[packet.type]].push(packet);\n  };\n\n  CaptionStream$1.prototype.setsChannel1Active = function (packet) {\n    return (packet.ccData & 0x7800) === 0x1000;\n  };\n\n  CaptionStream$1.prototype.setsChannel2Active = function (packet) {\n    return (packet.ccData & 0x7800) === 0x1800;\n  };\n\n  CaptionStream$1.prototype.setsTextOrXDSActive = function (packet) {\n    return (packet.ccData & 0x7100) === 0x0100 || (packet.ccData & 0x78fe) === 0x102a || (packet.ccData & 0x78fe) === 0x182a;\n  };\n\n  CaptionStream$1.prototype.dispatchCea708Packet = function (packet) {\n    if (this.parse708captions_) {\n      this.cc708Stream_.push(packet);\n    }\n  }; // ----------------------\n  // Session to Application\n  // ----------------------\n  // This hash maps special and extended character codes to their\n  // proper Unicode equivalent. The first one-byte key is just a\n  // non-standard character code. The two-byte keys that follow are\n  // the extended CEA708 character codes, along with the preceding\n  // 0x10 extended character byte to distinguish these codes from\n  // non-extended character codes. Every CEA708 character code that\n  // is not in this object maps directly to a standard unicode\n  // character code.\n  // The transparent space and non-breaking transparent space are\n  // technically not fully supported since there is no code to\n  // make them transparent, so they have normal non-transparent\n  // stand-ins.\n  // The special closed caption (CC) character isn't a standard\n  // unicode character, so a fairly similar unicode character was\n  // chosen in it's place.\n\n\n  var CHARACTER_TRANSLATION_708 = {\n    0x7f: 0x266a,\n    // ♪\n    0x1020: 0x20,\n    // Transparent Space\n    0x1021: 0xa0,\n    // Nob-breaking Transparent Space\n    0x1025: 0x2026,\n    // …\n    0x102a: 0x0160,\n    // Š\n    0x102c: 0x0152,\n    // Œ\n    0x1030: 0x2588,\n    // █\n    0x1031: 0x2018,\n    // ‘\n    0x1032: 0x2019,\n    // ’\n    0x1033: 0x201c,\n    // “\n    0x1034: 0x201d,\n    // ”\n    0x1035: 0x2022,\n    // •\n    0x1039: 0x2122,\n    // ™\n    0x103a: 0x0161,\n    // š\n    0x103c: 0x0153,\n    // œ\n    0x103d: 0x2120,\n    // ℠\n    0x103f: 0x0178,\n    // Ÿ\n    0x1076: 0x215b,\n    // ⅛\n    0x1077: 0x215c,\n    // ⅜\n    0x1078: 0x215d,\n    // ⅝\n    0x1079: 0x215e,\n    // ⅞\n    0x107a: 0x23d0,\n    // ⏐\n    0x107b: 0x23a4,\n    // ⎤\n    0x107c: 0x23a3,\n    // ⎣\n    0x107d: 0x23af,\n    // ⎯\n    0x107e: 0x23a6,\n    // ⎦\n    0x107f: 0x23a1,\n    // ⎡\n    0x10a0: 0x3138 // ㄸ (CC char)\n\n  };\n\n  var get708CharFromCode = function get708CharFromCode(code) {\n    var newCode = CHARACTER_TRANSLATION_708[code] || code;\n\n    if (code & 0x1000 && code === newCode) {\n      // Invalid extended code\n      return '';\n    }\n\n    return String.fromCharCode(newCode);\n  };\n\n  var within708TextBlock = function within708TextBlock(b) {\n    return 0x20 <= b && b <= 0x7f || 0xa0 <= b && b <= 0xff;\n  };\n\n  var Cea708Window = function Cea708Window(windowNum) {\n    this.windowNum = windowNum;\n    this.reset();\n  };\n\n  Cea708Window.prototype.reset = function () {\n    this.clearText();\n    this.pendingNewLine = false;\n    this.winAttr = {};\n    this.penAttr = {};\n    this.penLoc = {};\n    this.penColor = {}; // These default values are arbitrary,\n    // defineWindow will usually override them\n\n    this.visible = 0;\n    this.rowLock = 0;\n    this.columnLock = 0;\n    this.priority = 0;\n    this.relativePositioning = 0;\n    this.anchorVertical = 0;\n    this.anchorHorizontal = 0;\n    this.anchorPoint = 0;\n    this.rowCount = 1;\n    this.virtualRowCount = this.rowCount + 1;\n    this.columnCount = 41;\n    this.windowStyle = 0;\n    this.penStyle = 0;\n  };\n\n  Cea708Window.prototype.getText = function () {\n    return this.rows.join('\\n');\n  };\n\n  Cea708Window.prototype.clearText = function () {\n    this.rows = [''];\n    this.rowIdx = 0;\n  };\n\n  Cea708Window.prototype.newLine = function (pts) {\n    if (this.rows.length >= this.virtualRowCount && typeof this.beforeRowOverflow === 'function') {\n      this.beforeRowOverflow(pts);\n    }\n\n    if (this.rows.length > 0) {\n      this.rows.push('');\n      this.rowIdx++;\n    } // Show all virtual rows since there's no visible scrolling\n\n\n    while (this.rows.length > this.virtualRowCount) {\n      this.rows.shift();\n      this.rowIdx--;\n    }\n  };\n\n  Cea708Window.prototype.isEmpty = function () {\n    if (this.rows.length === 0) {\n      return true;\n    } else if (this.rows.length === 1) {\n      return this.rows[0] === '';\n    }\n\n    return false;\n  };\n\n  Cea708Window.prototype.addText = function (text) {\n    this.rows[this.rowIdx] += text;\n  };\n\n  Cea708Window.prototype.backspace = function () {\n    if (!this.isEmpty()) {\n      var row = this.rows[this.rowIdx];\n      this.rows[this.rowIdx] = row.substr(0, row.length - 1);\n    }\n  };\n\n  var Cea708Service = function Cea708Service(serviceNum, encoding, stream) {\n    this.serviceNum = serviceNum;\n    this.text = '';\n    this.currentWindow = new Cea708Window(-1);\n    this.windows = [];\n    this.stream = stream; // Try to setup a TextDecoder if an `encoding` value was provided\n\n    if (typeof encoding === 'string') {\n      this.createTextDecoder(encoding);\n    }\n  };\n  /**\n   * Initialize service windows\n   * Must be run before service use\n   *\n   * @param  {Integer}  pts               PTS value\n   * @param  {Function} beforeRowOverflow Function to execute before row overflow of a window\n   */\n\n\n  Cea708Service.prototype.init = function (pts, beforeRowOverflow) {\n    this.startPts = pts;\n\n    for (var win = 0; win < 8; win++) {\n      this.windows[win] = new Cea708Window(win);\n\n      if (typeof beforeRowOverflow === 'function') {\n        this.windows[win].beforeRowOverflow = beforeRowOverflow;\n      }\n    }\n  };\n  /**\n   * Set current window of service to be affected by commands\n   *\n   * @param  {Integer} windowNum Window number\n   */\n\n\n  Cea708Service.prototype.setCurrentWindow = function (windowNum) {\n    this.currentWindow = this.windows[windowNum];\n  };\n  /**\n   * Try to create a TextDecoder if it is natively supported\n   */\n\n\n  Cea708Service.prototype.createTextDecoder = function (encoding) {\n    if (typeof TextDecoder === 'undefined') {\n      this.stream.trigger('log', {\n        level: 'warn',\n        message: 'The `encoding` option is unsupported without TextDecoder support'\n      });\n    } else {\n      try {\n        this.textDecoder_ = new TextDecoder(encoding);\n      } catch (error) {\n        this.stream.trigger('log', {\n          level: 'warn',\n          message: 'TextDecoder could not be created with ' + encoding + ' encoding. ' + error\n        });\n      }\n    }\n  };\n\n  var Cea708Stream = function Cea708Stream(options) {\n    options = options || {};\n    Cea708Stream.prototype.init.call(this);\n    var self = this;\n    var captionServices = options.captionServices || {};\n    var captionServiceEncodings = {};\n    var serviceProps; // Get service encodings from captionServices option block\n\n    Object.keys(captionServices).forEach(function (serviceName) {\n      serviceProps = captionServices[serviceName];\n\n      if (/^SERVICE/.test(serviceName)) {\n        captionServiceEncodings[serviceName] = serviceProps.encoding;\n      }\n    });\n    this.serviceEncodings = captionServiceEncodings;\n    this.current708Packet = null;\n    this.services = {};\n\n    this.push = function (packet) {\n      if (packet.type === 3) {\n        // 708 packet start\n        self.new708Packet();\n        self.add708Bytes(packet);\n      } else {\n        if (self.current708Packet === null) {\n          // This should only happen at the start of a file if there's no packet start.\n          self.new708Packet();\n        }\n\n        self.add708Bytes(packet);\n      }\n    };\n  };\n\n  Cea708Stream.prototype = new stream();\n  /**\n   * Push current 708 packet, create new 708 packet.\n   */\n\n  Cea708Stream.prototype.new708Packet = function () {\n    if (this.current708Packet !== null) {\n      this.push708Packet();\n    }\n\n    this.current708Packet = {\n      data: [],\n      ptsVals: []\n    };\n  };\n  /**\n   * Add pts and both bytes from packet into current 708 packet.\n   */\n\n\n  Cea708Stream.prototype.add708Bytes = function (packet) {\n    var data = packet.ccData;\n    var byte0 = data >>> 8;\n    var byte1 = data & 0xff; // I would just keep a list of packets instead of bytes, but it isn't clear in the spec\n    // that service blocks will always line up with byte pairs.\n\n    this.current708Packet.ptsVals.push(packet.pts);\n    this.current708Packet.data.push(byte0);\n    this.current708Packet.data.push(byte1);\n  };\n  /**\n   * Parse completed 708 packet into service blocks and push each service block.\n   */\n\n\n  Cea708Stream.prototype.push708Packet = function () {\n    var packet708 = this.current708Packet;\n    var packetData = packet708.data;\n    var serviceNum = null;\n    var blockSize = null;\n    var i = 0;\n    var b = packetData[i++];\n    packet708.seq = b >> 6;\n    packet708.sizeCode = b & 0x3f; // 0b00111111;\n\n    for (; i < packetData.length; i++) {\n      b = packetData[i++];\n      serviceNum = b >> 5;\n      blockSize = b & 0x1f; // 0b00011111\n\n      if (serviceNum === 7 && blockSize > 0) {\n        // Extended service num\n        b = packetData[i++];\n        serviceNum = b;\n      }\n\n      this.pushServiceBlock(serviceNum, i, blockSize);\n\n      if (blockSize > 0) {\n        i += blockSize - 1;\n      }\n    }\n  };\n  /**\n   * Parse service block, execute commands, read text.\n   *\n   * Note: While many of these commands serve important purposes,\n   * many others just parse out the parameters or attributes, but\n   * nothing is done with them because this is not a full and complete\n   * implementation of the entire 708 spec.\n   *\n   * @param  {Integer} serviceNum Service number\n   * @param  {Integer} start      Start index of the 708 packet data\n   * @param  {Integer} size       Block size\n   */\n\n\n  Cea708Stream.prototype.pushServiceBlock = function (serviceNum, start, size) {\n    var b;\n    var i = start;\n    var packetData = this.current708Packet.data;\n    var service = this.services[serviceNum];\n\n    if (!service) {\n      service = this.initService(serviceNum, i);\n    }\n\n    for (; i < start + size && i < packetData.length; i++) {\n      b = packetData[i];\n\n      if (within708TextBlock(b)) {\n        i = this.handleText(i, service);\n      } else if (b === 0x18) {\n        i = this.multiByteCharacter(i, service);\n      } else if (b === 0x10) {\n        i = this.extendedCommands(i, service);\n      } else if (0x80 <= b && b <= 0x87) {\n        i = this.setCurrentWindow(i, service);\n      } else if (0x98 <= b && b <= 0x9f) {\n        i = this.defineWindow(i, service);\n      } else if (b === 0x88) {\n        i = this.clearWindows(i, service);\n      } else if (b === 0x8c) {\n        i = this.deleteWindows(i, service);\n      } else if (b === 0x89) {\n        i = this.displayWindows(i, service);\n      } else if (b === 0x8a) {\n        i = this.hideWindows(i, service);\n      } else if (b === 0x8b) {\n        i = this.toggleWindows(i, service);\n      } else if (b === 0x97) {\n        i = this.setWindowAttributes(i, service);\n      } else if (b === 0x90) {\n        i = this.setPenAttributes(i, service);\n      } else if (b === 0x91) {\n        i = this.setPenColor(i, service);\n      } else if (b === 0x92) {\n        i = this.setPenLocation(i, service);\n      } else if (b === 0x8f) {\n        service = this.reset(i, service);\n      } else if (b === 0x08) {\n        // BS: Backspace\n        service.currentWindow.backspace();\n      } else if (b === 0x0c) {\n        // FF: Form feed\n        service.currentWindow.clearText();\n      } else if (b === 0x0d) {\n        // CR: Carriage return\n        service.currentWindow.pendingNewLine = true;\n      } else if (b === 0x0e) {\n        // HCR: Horizontal carriage return\n        service.currentWindow.clearText();\n      } else if (b === 0x8d) {\n        // DLY: Delay, nothing to do\n        i++;\n      } else ;\n    }\n  };\n  /**\n   * Execute an extended command\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.extendedCommands = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n\n    if (within708TextBlock(b)) {\n      i = this.handleText(i, service, {\n        isExtended: true\n      });\n    }\n\n    return i;\n  };\n  /**\n   * Get PTS value of a given byte index\n   *\n   * @param  {Integer} byteIndex  Index of the byte\n   * @return {Integer}            PTS\n   */\n\n\n  Cea708Stream.prototype.getPts = function (byteIndex) {\n    // There's 1 pts value per 2 bytes\n    return this.current708Packet.ptsVals[Math.floor(byteIndex / 2)];\n  };\n  /**\n   * Initializes a service\n   *\n   * @param  {Integer} serviceNum Service number\n   * @return {Service}            Initialized service object\n   */\n\n\n  Cea708Stream.prototype.initService = function (serviceNum, i) {\n    var serviceName = 'SERVICE' + serviceNum;\n    var self = this;\n    var serviceName;\n    var encoding;\n\n    if (serviceName in this.serviceEncodings) {\n      encoding = this.serviceEncodings[serviceName];\n    }\n\n    this.services[serviceNum] = new Cea708Service(serviceNum, encoding, self);\n    this.services[serviceNum].init(this.getPts(i), function (pts) {\n      self.flushDisplayed(pts, self.services[serviceNum]);\n    });\n    return this.services[serviceNum];\n  };\n  /**\n   * Execute text writing to current window\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.handleText = function (i, service, options) {\n    var isExtended = options && options.isExtended;\n    var isMultiByte = options && options.isMultiByte;\n    var packetData = this.current708Packet.data;\n    var extended = isExtended ? 0x1000 : 0x0000;\n    var currentByte = packetData[i];\n    var nextByte = packetData[i + 1];\n    var win = service.currentWindow;\n    var char;\n    var charCodeArray; // Use the TextDecoder if one was created for this service\n\n    if (service.textDecoder_ && !isExtended) {\n      if (isMultiByte) {\n        charCodeArray = [currentByte, nextByte];\n        i++;\n      } else {\n        charCodeArray = [currentByte];\n      }\n\n      char = service.textDecoder_.decode(new Uint8Array(charCodeArray));\n    } else {\n      char = get708CharFromCode(extended | currentByte);\n    }\n\n    if (win.pendingNewLine && !win.isEmpty()) {\n      win.newLine(this.getPts(i));\n    }\n\n    win.pendingNewLine = false;\n    win.addText(char);\n    return i;\n  };\n  /**\n   * Handle decoding of multibyte character\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.multiByteCharacter = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var firstByte = packetData[i + 1];\n    var secondByte = packetData[i + 2];\n\n    if (within708TextBlock(firstByte) && within708TextBlock(secondByte)) {\n      i = this.handleText(++i, service, {\n        isMultiByte: true\n      });\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the CW# command.\n   *\n   * Set the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.setCurrentWindow = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var windowNum = b & 0x07;\n    service.setCurrentWindow(windowNum);\n    return i;\n  };\n  /**\n   * Parse and execute the DF# command.\n   *\n   * Define a window and set it as the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.defineWindow = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var windowNum = b & 0x07;\n    service.setCurrentWindow(windowNum);\n    var win = service.currentWindow;\n    b = packetData[++i];\n    win.visible = (b & 0x20) >> 5; // v\n\n    win.rowLock = (b & 0x10) >> 4; // rl\n\n    win.columnLock = (b & 0x08) >> 3; // cl\n\n    win.priority = b & 0x07; // p\n\n    b = packetData[++i];\n    win.relativePositioning = (b & 0x80) >> 7; // rp\n\n    win.anchorVertical = b & 0x7f; // av\n\n    b = packetData[++i];\n    win.anchorHorizontal = b; // ah\n\n    b = packetData[++i];\n    win.anchorPoint = (b & 0xf0) >> 4; // ap\n\n    win.rowCount = b & 0x0f; // rc\n\n    b = packetData[++i];\n    win.columnCount = b & 0x3f; // cc\n\n    b = packetData[++i];\n    win.windowStyle = (b & 0x38) >> 3; // ws\n\n    win.penStyle = b & 0x07; // ps\n    // The spec says there are (rowCount+1) \"virtual rows\"\n\n    win.virtualRowCount = win.rowCount + 1;\n    return i;\n  };\n  /**\n   * Parse and execute the SWA command.\n   *\n   * Set attributes of the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.setWindowAttributes = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var winAttr = service.currentWindow.winAttr;\n    b = packetData[++i];\n    winAttr.fillOpacity = (b & 0xc0) >> 6; // fo\n\n    winAttr.fillRed = (b & 0x30) >> 4; // fr\n\n    winAttr.fillGreen = (b & 0x0c) >> 2; // fg\n\n    winAttr.fillBlue = b & 0x03; // fb\n\n    b = packetData[++i];\n    winAttr.borderType = (b & 0xc0) >> 6; // bt\n\n    winAttr.borderRed = (b & 0x30) >> 4; // br\n\n    winAttr.borderGreen = (b & 0x0c) >> 2; // bg\n\n    winAttr.borderBlue = b & 0x03; // bb\n\n    b = packetData[++i];\n    winAttr.borderType += (b & 0x80) >> 5; // bt\n\n    winAttr.wordWrap = (b & 0x40) >> 6; // ww\n\n    winAttr.printDirection = (b & 0x30) >> 4; // pd\n\n    winAttr.scrollDirection = (b & 0x0c) >> 2; // sd\n\n    winAttr.justify = b & 0x03; // j\n\n    b = packetData[++i];\n    winAttr.effectSpeed = (b & 0xf0) >> 4; // es\n\n    winAttr.effectDirection = (b & 0x0c) >> 2; // ed\n\n    winAttr.displayEffect = b & 0x03; // de\n\n    return i;\n  };\n  /**\n   * Gather text from all displayed windows and push a caption to output.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   */\n\n\n  Cea708Stream.prototype.flushDisplayed = function (pts, service) {\n    var displayedText = []; // TODO: Positioning not supported, displaying multiple windows will not necessarily\n    // display text in the correct order, but sample files so far have not shown any issue.\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (service.windows[winId].visible && !service.windows[winId].isEmpty()) {\n        displayedText.push(service.windows[winId].getText());\n      }\n    }\n\n    service.endPts = pts;\n    service.text = displayedText.join('\\n\\n');\n    this.pushCaption(service);\n    service.startPts = pts;\n  };\n  /**\n   * Push a caption to output if the caption contains text.\n   *\n   * @param  {Service} service  The service object to be affected\n   */\n\n\n  Cea708Stream.prototype.pushCaption = function (service) {\n    if (service.text !== '') {\n      this.trigger('data', {\n        startPts: service.startPts,\n        endPts: service.endPts,\n        text: service.text,\n        stream: 'cc708_' + service.serviceNum\n      });\n      service.text = '';\n      service.startPts = service.endPts;\n    }\n  };\n  /**\n   * Parse and execute the DSW command.\n   *\n   * Set visible property of windows based on the parsed bitmask.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.displayWindows = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (b & 0x01 << winId) {\n        service.windows[winId].visible = 1;\n      }\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the HDW command.\n   *\n   * Set visible property of windows based on the parsed bitmask.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.hideWindows = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (b & 0x01 << winId) {\n        service.windows[winId].visible = 0;\n      }\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the TGW command.\n   *\n   * Set visible property of windows based on the parsed bitmask.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.toggleWindows = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (b & 0x01 << winId) {\n        service.windows[winId].visible ^= 1;\n      }\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the CLW command.\n   *\n   * Clear text of windows based on the parsed bitmask.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.clearWindows = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (b & 0x01 << winId) {\n        service.windows[winId].clearText();\n      }\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the DLW command.\n   *\n   * Re-initialize windows based on the parsed bitmask.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.deleteWindows = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[++i];\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n\n    for (var winId = 0; winId < 8; winId++) {\n      if (b & 0x01 << winId) {\n        service.windows[winId].reset();\n      }\n    }\n\n    return i;\n  };\n  /**\n   * Parse and execute the SPA command.\n   *\n   * Set pen attributes of the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.setPenAttributes = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var penAttr = service.currentWindow.penAttr;\n    b = packetData[++i];\n    penAttr.textTag = (b & 0xf0) >> 4; // tt\n\n    penAttr.offset = (b & 0x0c) >> 2; // o\n\n    penAttr.penSize = b & 0x03; // s\n\n    b = packetData[++i];\n    penAttr.italics = (b & 0x80) >> 7; // i\n\n    penAttr.underline = (b & 0x40) >> 6; // u\n\n    penAttr.edgeType = (b & 0x38) >> 3; // et\n\n    penAttr.fontStyle = b & 0x07; // fs\n\n    return i;\n  };\n  /**\n   * Parse and execute the SPC command.\n   *\n   * Set pen color of the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.setPenColor = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var penColor = service.currentWindow.penColor;\n    b = packetData[++i];\n    penColor.fgOpacity = (b & 0xc0) >> 6; // fo\n\n    penColor.fgRed = (b & 0x30) >> 4; // fr\n\n    penColor.fgGreen = (b & 0x0c) >> 2; // fg\n\n    penColor.fgBlue = b & 0x03; // fb\n\n    b = packetData[++i];\n    penColor.bgOpacity = (b & 0xc0) >> 6; // bo\n\n    penColor.bgRed = (b & 0x30) >> 4; // br\n\n    penColor.bgGreen = (b & 0x0c) >> 2; // bg\n\n    penColor.bgBlue = b & 0x03; // bb\n\n    b = packetData[++i];\n    penColor.edgeRed = (b & 0x30) >> 4; // er\n\n    penColor.edgeGreen = (b & 0x0c) >> 2; // eg\n\n    penColor.edgeBlue = b & 0x03; // eb\n\n    return i;\n  };\n  /**\n   * Parse and execute the SPL command.\n   *\n   * Set pen location of the current window.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Integer}          New index after parsing\n   */\n\n\n  Cea708Stream.prototype.setPenLocation = function (i, service) {\n    var packetData = this.current708Packet.data;\n    var b = packetData[i];\n    var penLoc = service.currentWindow.penLoc; // Positioning isn't really supported at the moment, so this essentially just inserts a linebreak\n\n    service.currentWindow.pendingNewLine = true;\n    b = packetData[++i];\n    penLoc.row = b & 0x0f; // r\n\n    b = packetData[++i];\n    penLoc.column = b & 0x3f; // c\n\n    return i;\n  };\n  /**\n   * Execute the RST command.\n   *\n   * Reset service to a clean slate. Re-initialize.\n   *\n   * @param  {Integer} i        Current index in the 708 packet\n   * @param  {Service} service  The service object to be affected\n   * @return {Service}          Re-initialized service\n   */\n\n\n  Cea708Stream.prototype.reset = function (i, service) {\n    var pts = this.getPts(i);\n    this.flushDisplayed(pts, service);\n    return this.initService(service.serviceNum, i);\n  }; // This hash maps non-ASCII, special, and extended character codes to their\n  // proper Unicode equivalent. The first keys that are only a single byte\n  // are the non-standard ASCII characters, which simply map the CEA608 byte\n  // to the standard ASCII/Unicode. The two-byte keys that follow are the CEA608\n  // character codes, but have their MSB bitmasked with 0x03 so that a lookup\n  // can be performed regardless of the field and data channel on which the\n  // character code was received.\n\n\n  var CHARACTER_TRANSLATION = {\n    0x2a: 0xe1,\n    // á\n    0x5c: 0xe9,\n    // é\n    0x5e: 0xed,\n    // í\n    0x5f: 0xf3,\n    // ó\n    0x60: 0xfa,\n    // ú\n    0x7b: 0xe7,\n    // ç\n    0x7c: 0xf7,\n    // ÷\n    0x7d: 0xd1,\n    // Ñ\n    0x7e: 0xf1,\n    // ñ\n    0x7f: 0x2588,\n    // █\n    0x0130: 0xae,\n    // ®\n    0x0131: 0xb0,\n    // °\n    0x0132: 0xbd,\n    // ½\n    0x0133: 0xbf,\n    // ¿\n    0x0134: 0x2122,\n    // ™\n    0x0135: 0xa2,\n    // ¢\n    0x0136: 0xa3,\n    // £\n    0x0137: 0x266a,\n    // ♪\n    0x0138: 0xe0,\n    // à\n    0x0139: 0xa0,\n    //\n    0x013a: 0xe8,\n    // è\n    0x013b: 0xe2,\n    // â\n    0x013c: 0xea,\n    // ê\n    0x013d: 0xee,\n    // î\n    0x013e: 0xf4,\n    // ô\n    0x013f: 0xfb,\n    // û\n    0x0220: 0xc1,\n    // Á\n    0x0221: 0xc9,\n    // É\n    0x0222: 0xd3,\n    // Ó\n    0x0223: 0xda,\n    // Ú\n    0x0224: 0xdc,\n    // Ü\n    0x0225: 0xfc,\n    // ü\n    0x0226: 0x2018,\n    // ‘\n    0x0227: 0xa1,\n    // ¡\n    0x0228: 0x2a,\n    // *\n    0x0229: 0x27,\n    // '\n    0x022a: 0x2014,\n    // —\n    0x022b: 0xa9,\n    // ©\n    0x022c: 0x2120,\n    // ℠\n    0x022d: 0x2022,\n    // •\n    0x022e: 0x201c,\n    // “\n    0x022f: 0x201d,\n    // ”\n    0x0230: 0xc0,\n    // À\n    0x0231: 0xc2,\n    // Â\n    0x0232: 0xc7,\n    // Ç\n    0x0233: 0xc8,\n    // È\n    0x0234: 0xca,\n    // Ê\n    0x0235: 0xcb,\n    // Ë\n    0x0236: 0xeb,\n    // ë\n    0x0237: 0xce,\n    // Î\n    0x0238: 0xcf,\n    // Ï\n    0x0239: 0xef,\n    // ï\n    0x023a: 0xd4,\n    // Ô\n    0x023b: 0xd9,\n    // Ù\n    0x023c: 0xf9,\n    // ù\n    0x023d: 0xdb,\n    // Û\n    0x023e: 0xab,\n    // «\n    0x023f: 0xbb,\n    // »\n    0x0320: 0xc3,\n    // Ã\n    0x0321: 0xe3,\n    // ã\n    0x0322: 0xcd,\n    // Í\n    0x0323: 0xcc,\n    // Ì\n    0x0324: 0xec,\n    // ì\n    0x0325: 0xd2,\n    // Ò\n    0x0326: 0xf2,\n    // ò\n    0x0327: 0xd5,\n    // Õ\n    0x0328: 0xf5,\n    // õ\n    0x0329: 0x7b,\n    // {\n    0x032a: 0x7d,\n    // }\n    0x032b: 0x5c,\n    // \\\n    0x032c: 0x5e,\n    // ^\n    0x032d: 0x5f,\n    // _\n    0x032e: 0x7c,\n    // |\n    0x032f: 0x7e,\n    // ~\n    0x0330: 0xc4,\n    // Ä\n    0x0331: 0xe4,\n    // ä\n    0x0332: 0xd6,\n    // Ö\n    0x0333: 0xf6,\n    // ö\n    0x0334: 0xdf,\n    // ß\n    0x0335: 0xa5,\n    // ¥\n    0x0336: 0xa4,\n    // ¤\n    0x0337: 0x2502,\n    // │\n    0x0338: 0xc5,\n    // Å\n    0x0339: 0xe5,\n    // å\n    0x033a: 0xd8,\n    // Ø\n    0x033b: 0xf8,\n    // ø\n    0x033c: 0x250c,\n    // ┌\n    0x033d: 0x2510,\n    // ┐\n    0x033e: 0x2514,\n    // └\n    0x033f: 0x2518 // ┘\n\n  };\n\n  var getCharFromCode = function getCharFromCode(code) {\n    if (code === null) {\n      return '';\n    }\n\n    code = CHARACTER_TRANSLATION[code] || code;\n    return String.fromCharCode(code);\n  }; // the index of the last row in a CEA-608 display buffer\n\n\n  var BOTTOM_ROW = 14; // This array is used for mapping PACs -> row #, since there's no way of\n  // getting it through bit logic.\n\n  var ROWS = [0x1100, 0x1120, 0x1200, 0x1220, 0x1500, 0x1520, 0x1600, 0x1620, 0x1700, 0x1720, 0x1000, 0x1300, 0x1320, 0x1400, 0x1420]; // CEA-608 captions are rendered onto a 34x15 matrix of character\n  // cells. The \"bottom\" row is the last element in the outer array.\n\n  var createDisplayBuffer = function createDisplayBuffer() {\n    var result = [],\n        i = BOTTOM_ROW + 1;\n\n    while (i--) {\n      result.push('');\n    }\n\n    return result;\n  };\n\n  var Cea608Stream = function Cea608Stream(field, dataChannel) {\n    Cea608Stream.prototype.init.call(this);\n    this.field_ = field || 0;\n    this.dataChannel_ = dataChannel || 0;\n    this.name_ = 'CC' + ((this.field_ << 1 | this.dataChannel_) + 1);\n    this.setConstants();\n    this.reset();\n\n    this.push = function (packet) {\n      var data, swap, char0, char1, text; // remove the parity bits\n\n      data = packet.ccData & 0x7f7f; // ignore duplicate control codes; the spec demands they're sent twice\n\n      if (data === this.lastControlCode_) {\n        this.lastControlCode_ = null;\n        return;\n      } // Store control codes\n\n\n      if ((data & 0xf000) === 0x1000) {\n        this.lastControlCode_ = data;\n      } else if (data !== this.PADDING_) {\n        this.lastControlCode_ = null;\n      }\n\n      char0 = data >>> 8;\n      char1 = data & 0xff;\n\n      if (data === this.PADDING_) {\n        return;\n      } else if (data === this.RESUME_CAPTION_LOADING_) {\n        this.mode_ = 'popOn';\n      } else if (data === this.END_OF_CAPTION_) {\n        // If an EOC is received while in paint-on mode, the displayed caption\n        // text should be swapped to non-displayed memory as if it was a pop-on\n        // caption. Because of that, we should explicitly switch back to pop-on\n        // mode\n        this.mode_ = 'popOn';\n        this.clearFormatting(packet.pts); // if a caption was being displayed, it's gone now\n\n        this.flushDisplayed(packet.pts); // flip memory\n\n        swap = this.displayed_;\n        this.displayed_ = this.nonDisplayed_;\n        this.nonDisplayed_ = swap; // start measuring the time to display the caption\n\n        this.startPts_ = packet.pts;\n      } else if (data === this.ROLL_UP_2_ROWS_) {\n        this.rollUpRows_ = 2;\n        this.setRollUp(packet.pts);\n      } else if (data === this.ROLL_UP_3_ROWS_) {\n        this.rollUpRows_ = 3;\n        this.setRollUp(packet.pts);\n      } else if (data === this.ROLL_UP_4_ROWS_) {\n        this.rollUpRows_ = 4;\n        this.setRollUp(packet.pts);\n      } else if (data === this.CARRIAGE_RETURN_) {\n        this.clearFormatting(packet.pts);\n        this.flushDisplayed(packet.pts);\n        this.shiftRowsUp_();\n        this.startPts_ = packet.pts;\n      } else if (data === this.BACKSPACE_) {\n        if (this.mode_ === 'popOn') {\n          this.nonDisplayed_[this.row_] = this.nonDisplayed_[this.row_].slice(0, -1);\n        } else {\n          this.displayed_[this.row_] = this.displayed_[this.row_].slice(0, -1);\n        }\n      } else if (data === this.ERASE_DISPLAYED_MEMORY_) {\n        this.flushDisplayed(packet.pts);\n        this.displayed_ = createDisplayBuffer();\n      } else if (data === this.ERASE_NON_DISPLAYED_MEMORY_) {\n        this.nonDisplayed_ = createDisplayBuffer();\n      } else if (data === this.RESUME_DIRECT_CAPTIONING_) {\n        if (this.mode_ !== 'paintOn') {\n          // NOTE: This should be removed when proper caption positioning is\n          // implemented\n          this.flushDisplayed(packet.pts);\n          this.displayed_ = createDisplayBuffer();\n        }\n\n        this.mode_ = 'paintOn';\n        this.startPts_ = packet.pts; // Append special characters to caption text\n      } else if (this.isSpecialCharacter(char0, char1)) {\n        // Bitmask char0 so that we can apply character transformations\n        // regardless of field and data channel.\n        // Then byte-shift to the left and OR with char1 so we can pass the\n        // entire character code to `getCharFromCode`.\n        char0 = (char0 & 0x03) << 8;\n        text = getCharFromCode(char0 | char1);\n        this[this.mode_](packet.pts, text);\n        this.column_++; // Append extended characters to caption text\n      } else if (this.isExtCharacter(char0, char1)) {\n        // Extended characters always follow their \"non-extended\" equivalents.\n        // IE if a \"è\" is desired, you'll always receive \"eè\"; non-compliant\n        // decoders are supposed to drop the \"è\", while compliant decoders\n        // backspace the \"e\" and insert \"è\".\n        // Delete the previous character\n        if (this.mode_ === 'popOn') {\n          this.nonDisplayed_[this.row_] = this.nonDisplayed_[this.row_].slice(0, -1);\n        } else {\n          this.displayed_[this.row_] = this.displayed_[this.row_].slice(0, -1);\n        } // Bitmask char0 so that we can apply character transformations\n        // regardless of field and data channel.\n        // Then byte-shift to the left and OR with char1 so we can pass the\n        // entire character code to `getCharFromCode`.\n\n\n        char0 = (char0 & 0x03) << 8;\n        text = getCharFromCode(char0 | char1);\n        this[this.mode_](packet.pts, text);\n        this.column_++; // Process mid-row codes\n      } else if (this.isMidRowCode(char0, char1)) {\n        // Attributes are not additive, so clear all formatting\n        this.clearFormatting(packet.pts); // According to the standard, mid-row codes\n        // should be replaced with spaces, so add one now\n\n        this[this.mode_](packet.pts, ' ');\n        this.column_++;\n\n        if ((char1 & 0xe) === 0xe) {\n          this.addFormatting(packet.pts, ['i']);\n        }\n\n        if ((char1 & 0x1) === 0x1) {\n          this.addFormatting(packet.pts, ['u']);\n        } // Detect offset control codes and adjust cursor\n\n      } else if (this.isOffsetControlCode(char0, char1)) {\n        // Cursor position is set by indent PAC (see below) in 4-column\n        // increments, with an additional offset code of 1-3 to reach any\n        // of the 32 columns specified by CEA-608. So all we need to do\n        // here is increment the column cursor by the given offset.\n        this.column_ += char1 & 0x03; // Detect PACs (Preamble Address Codes)\n      } else if (this.isPAC(char0, char1)) {\n        // There's no logic for PAC -> row mapping, so we have to just\n        // find the row code in an array and use its index :(\n        var row = ROWS.indexOf(data & 0x1f20); // Configure the caption window if we're in roll-up mode\n\n        if (this.mode_ === 'rollUp') {\n          // This implies that the base row is incorrectly set.\n          // As per the recommendation in CEA-608(Base Row Implementation), defer to the number\n          // of roll-up rows set.\n          if (row - this.rollUpRows_ + 1 < 0) {\n            row = this.rollUpRows_ - 1;\n          }\n\n          this.setRollUp(packet.pts, row);\n        }\n\n        if (row !== this.row_) {\n          // formatting is only persistent for current row\n          this.clearFormatting(packet.pts);\n          this.row_ = row;\n        } // All PACs can apply underline, so detect and apply\n        // (All odd-numbered second bytes set underline)\n\n\n        if (char1 & 0x1 && this.formatting_.indexOf('u') === -1) {\n          this.addFormatting(packet.pts, ['u']);\n        }\n\n        if ((data & 0x10) === 0x10) {\n          // We've got an indent level code. Each successive even number\n          // increments the column cursor by 4, so we can get the desired\n          // column position by bit-shifting to the right (to get n/2)\n          // and multiplying by 4.\n          this.column_ = ((data & 0xe) >> 1) * 4;\n        }\n\n        if (this.isColorPAC(char1)) {\n          // it's a color code, though we only support white, which\n          // can be either normal or italicized. white italics can be\n          // either 0x4e or 0x6e depending on the row, so we just\n          // bitwise-and with 0xe to see if italics should be turned on\n          if ((char1 & 0xe) === 0xe) {\n            this.addFormatting(packet.pts, ['i']);\n          }\n        } // We have a normal character in char0, and possibly one in char1\n\n      } else if (this.isNormalChar(char0)) {\n        if (char1 === 0x00) {\n          char1 = null;\n        }\n\n        text = getCharFromCode(char0);\n        text += getCharFromCode(char1);\n        this[this.mode_](packet.pts, text);\n        this.column_ += text.length;\n      } // finish data processing\n\n    };\n  };\n\n  Cea608Stream.prototype = new stream(); // Trigger a cue point that captures the current state of the\n  // display buffer\n\n  Cea608Stream.prototype.flushDisplayed = function (pts) {\n    var content = this.displayed_ // remove spaces from the start and end of the string\n    .map(function (row, index) {\n      try {\n        return row.trim();\n      } catch (e) {\n        // Ordinarily, this shouldn't happen. However, caption\n        // parsing errors should not throw exceptions and\n        // break playback.\n        this.trigger('log', {\n          level: 'warn',\n          message: 'Skipping a malformed 608 caption at index ' + index + '.'\n        });\n        return '';\n      }\n    }, this) // combine all text rows to display in one cue\n    .join('\\n') // and remove blank rows from the start and end, but not the middle\n    .replace(/^\\n+|\\n+$/g, '');\n\n    if (content.length) {\n      this.trigger('data', {\n        startPts: this.startPts_,\n        endPts: pts,\n        text: content,\n        stream: this.name_\n      });\n    }\n  };\n  /**\n   * Zero out the data, used for startup and on seek\n   */\n\n\n  Cea608Stream.prototype.reset = function () {\n    this.mode_ = 'popOn'; // When in roll-up mode, the index of the last row that will\n    // actually display captions. If a caption is shifted to a row\n    // with a lower index than this, it is cleared from the display\n    // buffer\n\n    this.topRow_ = 0;\n    this.startPts_ = 0;\n    this.displayed_ = createDisplayBuffer();\n    this.nonDisplayed_ = createDisplayBuffer();\n    this.lastControlCode_ = null; // Track row and column for proper line-breaking and spacing\n\n    this.column_ = 0;\n    this.row_ = BOTTOM_ROW;\n    this.rollUpRows_ = 2; // This variable holds currently-applied formatting\n\n    this.formatting_ = [];\n  };\n  /**\n   * Sets up control code and related constants for this instance\n   */\n\n\n  Cea608Stream.prototype.setConstants = function () {\n    // The following attributes have these uses:\n    // ext_ :    char0 for mid-row codes, and the base for extended\n    //           chars (ext_+0, ext_+1, and ext_+2 are char0s for\n    //           extended codes)\n    // control_: char0 for control codes, except byte-shifted to the\n    //           left so that we can do this.control_ | CONTROL_CODE\n    // offset_:  char0 for tab offset codes\n    //\n    // It's also worth noting that control codes, and _only_ control codes,\n    // differ between field 1 and field2. Field 2 control codes are always\n    // their field 1 value plus 1. That's why there's the \"| field\" on the\n    // control value.\n    if (this.dataChannel_ === 0) {\n      this.BASE_ = 0x10;\n      this.EXT_ = 0x11;\n      this.CONTROL_ = (0x14 | this.field_) << 8;\n      this.OFFSET_ = 0x17;\n    } else if (this.dataChannel_ === 1) {\n      this.BASE_ = 0x18;\n      this.EXT_ = 0x19;\n      this.CONTROL_ = (0x1c | this.field_) << 8;\n      this.OFFSET_ = 0x1f;\n    } // Constants for the LSByte command codes recognized by Cea608Stream. This\n    // list is not exhaustive. For a more comprehensive listing and semantics see\n    // http://www.gpo.gov/fdsys/pkg/CFR-2010-title47-vol1/pdf/CFR-2010-title47-vol1-sec15-119.pdf\n    // Padding\n\n\n    this.PADDING_ = 0x0000; // Pop-on Mode\n\n    this.RESUME_CAPTION_LOADING_ = this.CONTROL_ | 0x20;\n    this.END_OF_CAPTION_ = this.CONTROL_ | 0x2f; // Roll-up Mode\n\n    this.ROLL_UP_2_ROWS_ = this.CONTROL_ | 0x25;\n    this.ROLL_UP_3_ROWS_ = this.CONTROL_ | 0x26;\n    this.ROLL_UP_4_ROWS_ = this.CONTROL_ | 0x27;\n    this.CARRIAGE_RETURN_ = this.CONTROL_ | 0x2d; // paint-on mode\n\n    this.RESUME_DIRECT_CAPTIONING_ = this.CONTROL_ | 0x29; // Erasure\n\n    this.BACKSPACE_ = this.CONTROL_ | 0x21;\n    this.ERASE_DISPLAYED_MEMORY_ = this.CONTROL_ | 0x2c;\n    this.ERASE_NON_DISPLAYED_MEMORY_ = this.CONTROL_ | 0x2e;\n  };\n  /**\n   * Detects if the 2-byte packet data is a special character\n   *\n   * Special characters have a second byte in the range 0x30 to 0x3f,\n   * with the first byte being 0x11 (for data channel 1) or 0x19 (for\n   * data channel 2).\n   *\n   * @param  {Integer} char0 The first byte\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the 2 bytes are an special character\n   */\n\n\n  Cea608Stream.prototype.isSpecialCharacter = function (char0, char1) {\n    return char0 === this.EXT_ && char1 >= 0x30 && char1 <= 0x3f;\n  };\n  /**\n   * Detects if the 2-byte packet data is an extended character\n   *\n   * Extended characters have a second byte in the range 0x20 to 0x3f,\n   * with the first byte being 0x12 or 0x13 (for data channel 1) or\n   * 0x1a or 0x1b (for data channel 2).\n   *\n   * @param  {Integer} char0 The first byte\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the 2 bytes are an extended character\n   */\n\n\n  Cea608Stream.prototype.isExtCharacter = function (char0, char1) {\n    return (char0 === this.EXT_ + 1 || char0 === this.EXT_ + 2) && char1 >= 0x20 && char1 <= 0x3f;\n  };\n  /**\n   * Detects if the 2-byte packet is a mid-row code\n   *\n   * Mid-row codes have a second byte in the range 0x20 to 0x2f, with\n   * the first byte being 0x11 (for data channel 1) or 0x19 (for data\n   * channel 2).\n   *\n   * @param  {Integer} char0 The first byte\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the 2 bytes are a mid-row code\n   */\n\n\n  Cea608Stream.prototype.isMidRowCode = function (char0, char1) {\n    return char0 === this.EXT_ && char1 >= 0x20 && char1 <= 0x2f;\n  };\n  /**\n   * Detects if the 2-byte packet is an offset control code\n   *\n   * Offset control codes have a second byte in the range 0x21 to 0x23,\n   * with the first byte being 0x17 (for data channel 1) or 0x1f (for\n   * data channel 2).\n   *\n   * @param  {Integer} char0 The first byte\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the 2 bytes are an offset control code\n   */\n\n\n  Cea608Stream.prototype.isOffsetControlCode = function (char0, char1) {\n    return char0 === this.OFFSET_ && char1 >= 0x21 && char1 <= 0x23;\n  };\n  /**\n   * Detects if the 2-byte packet is a Preamble Address Code\n   *\n   * PACs have a first byte in the range 0x10 to 0x17 (for data channel 1)\n   * or 0x18 to 0x1f (for data channel 2), with the second byte in the\n   * range 0x40 to 0x7f.\n   *\n   * @param  {Integer} char0 The first byte\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the 2 bytes are a PAC\n   */\n\n\n  Cea608Stream.prototype.isPAC = function (char0, char1) {\n    return char0 >= this.BASE_ && char0 < this.BASE_ + 8 && char1 >= 0x40 && char1 <= 0x7f;\n  };\n  /**\n   * Detects if a packet's second byte is in the range of a PAC color code\n   *\n   * PAC color codes have the second byte be in the range 0x40 to 0x4f, or\n   * 0x60 to 0x6f.\n   *\n   * @param  {Integer} char1 The second byte\n   * @return {Boolean}       Whether the byte is a color PAC\n   */\n\n\n  Cea608Stream.prototype.isColorPAC = function (char1) {\n    return char1 >= 0x40 && char1 <= 0x4f || char1 >= 0x60 && char1 <= 0x7f;\n  };\n  /**\n   * Detects if a single byte is in the range of a normal character\n   *\n   * Normal text bytes are in the range 0x20 to 0x7f.\n   *\n   * @param  {Integer} char  The byte\n   * @return {Boolean}       Whether the byte is a normal character\n   */\n\n\n  Cea608Stream.prototype.isNormalChar = function (char) {\n    return char >= 0x20 && char <= 0x7f;\n  };\n  /**\n   * Configures roll-up\n   *\n   * @param  {Integer} pts         Current PTS\n   * @param  {Integer} newBaseRow  Used by PACs to slide the current window to\n   *                               a new position\n   */\n\n\n  Cea608Stream.prototype.setRollUp = function (pts, newBaseRow) {\n    // Reset the base row to the bottom row when switching modes\n    if (this.mode_ !== 'rollUp') {\n      this.row_ = BOTTOM_ROW;\n      this.mode_ = 'rollUp'; // Spec says to wipe memories when switching to roll-up\n\n      this.flushDisplayed(pts);\n      this.nonDisplayed_ = createDisplayBuffer();\n      this.displayed_ = createDisplayBuffer();\n    }\n\n    if (newBaseRow !== undefined && newBaseRow !== this.row_) {\n      // move currently displayed captions (up or down) to the new base row\n      for (var i = 0; i < this.rollUpRows_; i++) {\n        this.displayed_[newBaseRow - i] = this.displayed_[this.row_ - i];\n        this.displayed_[this.row_ - i] = '';\n      }\n    }\n\n    if (newBaseRow === undefined) {\n      newBaseRow = this.row_;\n    }\n\n    this.topRow_ = newBaseRow - this.rollUpRows_ + 1;\n  }; // Adds the opening HTML tag for the passed character to the caption text,\n  // and keeps track of it for later closing\n\n\n  Cea608Stream.prototype.addFormatting = function (pts, format) {\n    this.formatting_ = this.formatting_.concat(format);\n    var text = format.reduce(function (text, format) {\n      return text + '<' + format + '>';\n    }, '');\n    this[this.mode_](pts, text);\n  }; // Adds HTML closing tags for current formatting to caption text and\n  // clears remembered formatting\n\n\n  Cea608Stream.prototype.clearFormatting = function (pts) {\n    if (!this.formatting_.length) {\n      return;\n    }\n\n    var text = this.formatting_.reverse().reduce(function (text, format) {\n      return text + '</' + format + '>';\n    }, '');\n    this.formatting_ = [];\n    this[this.mode_](pts, text);\n  }; // Mode Implementations\n\n\n  Cea608Stream.prototype.popOn = function (pts, text) {\n    var baseRow = this.nonDisplayed_[this.row_]; // buffer characters\n\n    baseRow += text;\n    this.nonDisplayed_[this.row_] = baseRow;\n  };\n\n  Cea608Stream.prototype.rollUp = function (pts, text) {\n    var baseRow = this.displayed_[this.row_];\n    baseRow += text;\n    this.displayed_[this.row_] = baseRow;\n  };\n\n  Cea608Stream.prototype.shiftRowsUp_ = function () {\n    var i; // clear out inactive rows\n\n    for (i = 0; i < this.topRow_; i++) {\n      this.displayed_[i] = '';\n    }\n\n    for (i = this.row_ + 1; i < BOTTOM_ROW + 1; i++) {\n      this.displayed_[i] = '';\n    } // shift displayed rows up\n\n\n    for (i = this.topRow_; i < this.row_; i++) {\n      this.displayed_[i] = this.displayed_[i + 1];\n    } // clear out the bottom row\n\n\n    this.displayed_[this.row_] = '';\n  };\n\n  Cea608Stream.prototype.paintOn = function (pts, text) {\n    var baseRow = this.displayed_[this.row_];\n    baseRow += text;\n    this.displayed_[this.row_] = baseRow;\n  }; // exports\n\n\n  var captionStream = {\n    CaptionStream: CaptionStream$1,\n    Cea608Stream: Cea608Stream,\n    Cea708Stream: Cea708Stream\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var streamTypes = {\n    H264_STREAM_TYPE: 0x1B,\n    ADTS_STREAM_TYPE: 0x0F,\n    METADATA_STREAM_TYPE: 0x15\n  };\n\n  var MAX_TS = 8589934592;\n  var RO_THRESH = 4294967296;\n  var TYPE_SHARED = 'shared';\n\n  var handleRollover$1 = function handleRollover(value, reference) {\n    var direction = 1;\n\n    if (value > reference) {\n      // If the current timestamp value is greater than our reference timestamp and we detect a\n      // timestamp rollover, this means the roll over is happening in the opposite direction.\n      // Example scenario: Enter a long stream/video just after a rollover occurred. The reference\n      // point will be set to a small number, e.g. 1. The user then seeks backwards over the\n      // rollover point. In loading this segment, the timestamp values will be very large,\n      // e.g. 2^33 - 1. Since this comes before the data we loaded previously, we want to adjust\n      // the time stamp to be `value - 2^33`.\n      direction = -1;\n    } // Note: A seek forwards or back that is greater than the RO_THRESH (2^32, ~13 hours) will\n    // cause an incorrect adjustment.\n\n\n    while (Math.abs(reference - value) > RO_THRESH) {\n      value += direction * MAX_TS;\n    }\n\n    return value;\n  };\n\n  var TimestampRolloverStream$1 = function TimestampRolloverStream(type) {\n    var lastDTS, referenceDTS;\n    TimestampRolloverStream.prototype.init.call(this); // The \"shared\" type is used in cases where a stream will contain muxed\n    // video and audio. We could use `undefined` here, but having a string\n    // makes debugging a little clearer.\n\n    this.type_ = type || TYPE_SHARED;\n\n    this.push = function (data) {\n      // Any \"shared\" rollover streams will accept _all_ data. Otherwise,\n      // streams will only accept data that matches their type.\n      if (this.type_ !== TYPE_SHARED && data.type !== this.type_) {\n        return;\n      }\n\n      if (referenceDTS === undefined) {\n        referenceDTS = data.dts;\n      }\n\n      data.dts = handleRollover$1(data.dts, referenceDTS);\n      data.pts = handleRollover$1(data.pts, referenceDTS);\n      lastDTS = data.dts;\n      this.trigger('data', data);\n    };\n\n    this.flush = function () {\n      referenceDTS = lastDTS;\n      this.trigger('done');\n    };\n\n    this.endTimeline = function () {\n      this.flush();\n      this.trigger('endedtimeline');\n    };\n\n    this.discontinuity = function () {\n      referenceDTS = void 0;\n      lastDTS = void 0;\n    };\n\n    this.reset = function () {\n      this.discontinuity();\n      this.trigger('reset');\n    };\n  };\n\n  TimestampRolloverStream$1.prototype = new stream();\n  var timestampRolloverStream = {\n    TimestampRolloverStream: TimestampRolloverStream$1,\n    handleRollover: handleRollover$1\n  };\n\n  var percentEncode$1 = function percentEncode(bytes, start, end) {\n    var i,\n        result = '';\n\n    for (i = start; i < end; i++) {\n      result += '%' + ('00' + bytes[i].toString(16)).slice(-2);\n    }\n\n    return result;\n  },\n      // return the string representation of the specified byte range,\n  // interpreted as UTf-8.\n  parseUtf8 = function parseUtf8(bytes, start, end) {\n    return decodeURIComponent(percentEncode$1(bytes, start, end));\n  },\n      // return the string representation of the specified byte range,\n  // interpreted as ISO-8859-1.\n  parseIso88591$1 = function parseIso88591(bytes, start, end) {\n    return unescape(percentEncode$1(bytes, start, end)); // jshint ignore:line\n  },\n      parseSyncSafeInteger$1 = function parseSyncSafeInteger(data) {\n    return data[0] << 21 | data[1] << 14 | data[2] << 7 | data[3];\n  },\n      tagParsers = {\n    TXXX: function TXXX(tag) {\n      var i;\n\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the text fields\n          tag.description = parseUtf8(tag.data, 1, i); // do not include the null terminator in the tag value\n\n          tag.value = parseUtf8(tag.data, i + 1, tag.data.length).replace(/\\0*$/, '');\n          break;\n        }\n      }\n\n      tag.data = tag.value;\n    },\n    WXXX: function WXXX(tag) {\n      var i;\n\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.description = parseUtf8(tag.data, 1, i);\n          tag.url = parseUtf8(tag.data, i + 1, tag.data.length);\n          break;\n        }\n      }\n    },\n    PRIV: function PRIV(tag) {\n      var i;\n\n      for (i = 0; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.owner = parseIso88591$1(tag.data, 0, i);\n          break;\n        }\n      }\n\n      tag.privateData = tag.data.subarray(i + 1);\n      tag.data = tag.privateData;\n    }\n  },\n      _MetadataStream;\n\n  _MetadataStream = function MetadataStream(options) {\n    var settings = {\n      // the bytes of the program-level descriptor field in MP2T\n      // see ISO/IEC 13818-1:2013 (E), section 2.6 \"Program and\n      // program element descriptors\"\n      descriptor: options && options.descriptor\n    },\n        // the total size in bytes of the ID3 tag being parsed\n    tagSize = 0,\n        // tag data that is not complete enough to be parsed\n    buffer = [],\n        // the total number of bytes currently in the buffer\n    bufferSize = 0,\n        i;\n\n    _MetadataStream.prototype.init.call(this); // calculate the text track in-band metadata track dispatch type\n    // https://html.spec.whatwg.org/multipage/embedded-content.html#steps-to-expose-a-media-resource-specific-text-track\n\n\n    this.dispatchType = streamTypes.METADATA_STREAM_TYPE.toString(16);\n\n    if (settings.descriptor) {\n      for (i = 0; i < settings.descriptor.length; i++) {\n        this.dispatchType += ('00' + settings.descriptor[i].toString(16)).slice(-2);\n      }\n    }\n\n    this.push = function (chunk) {\n      var tag, frameStart, frameSize, frame, i, frameHeader;\n\n      if (chunk.type !== 'timed-metadata') {\n        return;\n      } // if data_alignment_indicator is set in the PES header,\n      // we must have the start of a new ID3 tag. Assume anything\n      // remaining in the buffer was malformed and throw it out\n\n\n      if (chunk.dataAlignmentIndicator) {\n        bufferSize = 0;\n        buffer.length = 0;\n      } // ignore events that don't look like ID3 data\n\n\n      if (buffer.length === 0 && (chunk.data.length < 10 || chunk.data[0] !== 'I'.charCodeAt(0) || chunk.data[1] !== 'D'.charCodeAt(0) || chunk.data[2] !== '3'.charCodeAt(0))) {\n        this.trigger('log', {\n          level: 'warn',\n          message: 'Skipping unrecognized metadata packet'\n        });\n        return;\n      } // add this chunk to the data we've collected so far\n\n\n      buffer.push(chunk);\n      bufferSize += chunk.data.byteLength; // grab the size of the entire frame from the ID3 header\n\n      if (buffer.length === 1) {\n        // the frame size is transmitted as a 28-bit integer in the\n        // last four bytes of the ID3 header.\n        // The most significant bit of each byte is dropped and the\n        // results concatenated to recover the actual value.\n        tagSize = parseSyncSafeInteger$1(chunk.data.subarray(6, 10)); // ID3 reports the tag size excluding the header but it's more\n        // convenient for our comparisons to include it\n\n        tagSize += 10;\n      } // if the entire frame has not arrived, wait for more data\n\n\n      if (bufferSize < tagSize) {\n        return;\n      } // collect the entire frame so it can be parsed\n\n\n      tag = {\n        data: new Uint8Array(tagSize),\n        frames: [],\n        pts: buffer[0].pts,\n        dts: buffer[0].dts\n      };\n\n      for (i = 0; i < tagSize;) {\n        tag.data.set(buffer[0].data.subarray(0, tagSize - i), i);\n        i += buffer[0].data.byteLength;\n        bufferSize -= buffer[0].data.byteLength;\n        buffer.shift();\n      } // find the start of the first frame and the end of the tag\n\n\n      frameStart = 10;\n\n      if (tag.data[5] & 0x40) {\n        // advance the frame start past the extended header\n        frameStart += 4; // header size field\n\n        frameStart += parseSyncSafeInteger$1(tag.data.subarray(10, 14)); // clip any padding off the end\n\n        tagSize -= parseSyncSafeInteger$1(tag.data.subarray(16, 20));\n      } // parse one or more ID3 frames\n      // http://id3.org/id3v2.3.0#ID3v2_frame_overview\n\n\n      do {\n        // determine the number of bytes in this frame\n        frameSize = parseSyncSafeInteger$1(tag.data.subarray(frameStart + 4, frameStart + 8));\n\n        if (frameSize < 1) {\n          this.trigger('log', {\n            level: 'warn',\n            message: 'Malformed ID3 frame encountered. Skipping remaining metadata parsing.'\n          }); // If the frame is malformed, don't parse any further frames but allow previous valid parsed frames\n          // to be sent along.\n\n          break;\n        }\n\n        frameHeader = String.fromCharCode(tag.data[frameStart], tag.data[frameStart + 1], tag.data[frameStart + 2], tag.data[frameStart + 3]);\n        frame = {\n          id: frameHeader,\n          data: tag.data.subarray(frameStart + 10, frameStart + frameSize + 10)\n        };\n        frame.key = frame.id;\n\n        if (tagParsers[frame.id]) {\n          tagParsers[frame.id](frame); // handle the special PRIV frame used to indicate the start\n          // time for raw AAC data\n\n          if (frame.owner === 'com.apple.streaming.transportStreamTimestamp') {\n            var d = frame.data,\n                size = (d[3] & 0x01) << 30 | d[4] << 22 | d[5] << 14 | d[6] << 6 | d[7] >>> 2;\n            size *= 4;\n            size += d[7] & 0x03;\n            frame.timeStamp = size; // in raw AAC, all subsequent data will be timestamped based\n            // on the value of this frame\n            // we couldn't have known the appropriate pts and dts before\n            // parsing this ID3 tag so set those values now\n\n            if (tag.pts === undefined && tag.dts === undefined) {\n              tag.pts = frame.timeStamp;\n              tag.dts = frame.timeStamp;\n            }\n\n            this.trigger('timestamp', frame);\n          }\n        }\n\n        tag.frames.push(frame);\n        frameStart += 10; // advance past the frame header\n\n        frameStart += frameSize; // advance past the frame body\n      } while (frameStart < tagSize);\n\n      this.trigger('data', tag);\n    };\n  };\n\n  _MetadataStream.prototype = new stream();\n  var metadataStream = _MetadataStream;\n\n  var TimestampRolloverStream = timestampRolloverStream.TimestampRolloverStream; // object types\n\n  var _TransportPacketStream, _TransportParseStream, _ElementaryStream; // constants\n\n\n  var MP2T_PACKET_LENGTH$1 = 188,\n      // bytes\n  SYNC_BYTE$1 = 0x47;\n  /**\n   * Splits an incoming stream of binary data into MPEG-2 Transport\n   * Stream packets.\n   */\n\n  _TransportPacketStream = function TransportPacketStream() {\n    var buffer = new Uint8Array(MP2T_PACKET_LENGTH$1),\n        bytesInBuffer = 0;\n\n    _TransportPacketStream.prototype.init.call(this); // Deliver new bytes to the stream.\n\n    /**\n     * Split a stream of data into M2TS packets\n    **/\n\n\n    this.push = function (bytes) {\n      var startIndex = 0,\n          endIndex = MP2T_PACKET_LENGTH$1,\n          everything; // If there are bytes remaining from the last segment, prepend them to the\n      // bytes that were pushed in\n\n      if (bytesInBuffer) {\n        everything = new Uint8Array(bytes.byteLength + bytesInBuffer);\n        everything.set(buffer.subarray(0, bytesInBuffer));\n        everything.set(bytes, bytesInBuffer);\n        bytesInBuffer = 0;\n      } else {\n        everything = bytes;\n      } // While we have enough data for a packet\n\n\n      while (endIndex < everything.byteLength) {\n        // Look for a pair of start and end sync bytes in the data..\n        if (everything[startIndex] === SYNC_BYTE$1 && everything[endIndex] === SYNC_BYTE$1) {\n          // We found a packet so emit it and jump one whole packet forward in\n          // the stream\n          this.trigger('data', everything.subarray(startIndex, endIndex));\n          startIndex += MP2T_PACKET_LENGTH$1;\n          endIndex += MP2T_PACKET_LENGTH$1;\n          continue;\n        } // If we get here, we have somehow become de-synchronized and we need to step\n        // forward one byte at a time until we find a pair of sync bytes that denote\n        // a packet\n\n\n        startIndex++;\n        endIndex++;\n      } // If there was some data left over at the end of the segment that couldn't\n      // possibly be a whole packet, keep it because it might be the start of a packet\n      // that continues in the next segment\n\n\n      if (startIndex < everything.byteLength) {\n        buffer.set(everything.subarray(startIndex), 0);\n        bytesInBuffer = everything.byteLength - startIndex;\n      }\n    };\n    /**\n     * Passes identified M2TS packets to the TransportParseStream to be parsed\n    **/\n\n\n    this.flush = function () {\n      // If the buffer contains a whole packet when we are being flushed, emit it\n      // and empty the buffer. Otherwise hold onto the data because it may be\n      // important for decoding the next segment\n      if (bytesInBuffer === MP2T_PACKET_LENGTH$1 && buffer[0] === SYNC_BYTE$1) {\n        this.trigger('data', buffer);\n        bytesInBuffer = 0;\n      }\n\n      this.trigger('done');\n    };\n\n    this.endTimeline = function () {\n      this.flush();\n      this.trigger('endedtimeline');\n    };\n\n    this.reset = function () {\n      bytesInBuffer = 0;\n      this.trigger('reset');\n    };\n  };\n\n  _TransportPacketStream.prototype = new stream();\n  /**\n   * Accepts an MP2T TransportPacketStream and emits data events with parsed\n   * forms of the individual transport stream packets.\n   */\n\n  _TransportParseStream = function TransportParseStream() {\n    var parsePsi, parsePat, parsePmt, self;\n\n    _TransportParseStream.prototype.init.call(this);\n\n    self = this;\n    this.packetsWaitingForPmt = [];\n    this.programMapTable = undefined;\n\n    parsePsi = function parsePsi(payload, psi) {\n      var offset = 0; // PSI packets may be split into multiple sections and those\n      // sections may be split into multiple packets. If a PSI\n      // section starts in this packet, the payload_unit_start_indicator\n      // will be true and the first byte of the payload will indicate\n      // the offset from the current position to the start of the\n      // section.\n\n      if (psi.payloadUnitStartIndicator) {\n        offset += payload[offset] + 1;\n      }\n\n      if (psi.type === 'pat') {\n        parsePat(payload.subarray(offset), psi);\n      } else {\n        parsePmt(payload.subarray(offset), psi);\n      }\n    };\n\n    parsePat = function parsePat(payload, pat) {\n      pat.section_number = payload[7]; // eslint-disable-line camelcase\n\n      pat.last_section_number = payload[8]; // eslint-disable-line camelcase\n      // skip the PSI header and parse the first PMT entry\n\n      self.pmtPid = (payload[10] & 0x1F) << 8 | payload[11];\n      pat.pmtPid = self.pmtPid;\n    };\n    /**\n     * Parse out the relevant fields of a Program Map Table (PMT).\n     * @param payload {Uint8Array} the PMT-specific portion of an MP2T\n     * packet. The first byte in this array should be the table_id\n     * field.\n     * @param pmt {object} the object that should be decorated with\n     * fields parsed from the PMT.\n     */\n\n\n    parsePmt = function parsePmt(payload, pmt) {\n      var sectionLength, tableEnd, programInfoLength, offset; // PMTs can be sent ahead of the time when they should actually\n      // take effect. We don't believe this should ever be the case\n      // for HLS but we'll ignore \"forward\" PMT declarations if we see\n      // them. Future PMT declarations have the current_next_indicator\n      // set to zero.\n\n      if (!(payload[5] & 0x01)) {\n        return;\n      } // overwrite any existing program map table\n\n\n      self.programMapTable = {\n        video: null,\n        audio: null,\n        'timed-metadata': {}\n      }; // the mapping table ends at the end of the current section\n\n      sectionLength = (payload[1] & 0x0f) << 8 | payload[2];\n      tableEnd = 3 + sectionLength - 4; // to determine where the table is, we have to figure out how\n      // long the program info descriptors are\n\n      programInfoLength = (payload[10] & 0x0f) << 8 | payload[11]; // advance the offset to the first entry in the mapping table\n\n      offset = 12 + programInfoLength;\n\n      while (offset < tableEnd) {\n        var streamType = payload[offset];\n        var pid = (payload[offset + 1] & 0x1F) << 8 | payload[offset + 2]; // only map a single elementary_pid for audio and video stream types\n        // TODO: should this be done for metadata too? for now maintain behavior of\n        //       multiple metadata streams\n\n        if (streamType === streamTypes.H264_STREAM_TYPE && self.programMapTable.video === null) {\n          self.programMapTable.video = pid;\n        } else if (streamType === streamTypes.ADTS_STREAM_TYPE && self.programMapTable.audio === null) {\n          self.programMapTable.audio = pid;\n        } else if (streamType === streamTypes.METADATA_STREAM_TYPE) {\n          // map pid to stream type for metadata streams\n          self.programMapTable['timed-metadata'][pid] = streamType;\n        } // move to the next table entry\n        // skip past the elementary stream descriptors, if present\n\n\n        offset += ((payload[offset + 3] & 0x0F) << 8 | payload[offset + 4]) + 5;\n      } // record the map on the packet as well\n\n\n      pmt.programMapTable = self.programMapTable;\n    };\n    /**\n     * Deliver a new MP2T packet to the next stream in the pipeline.\n     */\n\n\n    this.push = function (packet) {\n      var result = {},\n          offset = 4;\n      result.payloadUnitStartIndicator = !!(packet[1] & 0x40); // pid is a 13-bit field starting at the last bit of packet[1]\n\n      result.pid = packet[1] & 0x1f;\n      result.pid <<= 8;\n      result.pid |= packet[2]; // if an adaption field is present, its length is specified by the\n      // fifth byte of the TS packet header. The adaptation field is\n      // used to add stuffing to PES packets that don't fill a complete\n      // TS packet, and to specify some forms of timing and control data\n      // that we do not currently use.\n\n      if ((packet[3] & 0x30) >>> 4 > 0x01) {\n        offset += packet[offset] + 1;\n      } // parse the rest of the packet based on the type\n\n\n      if (result.pid === 0) {\n        result.type = 'pat';\n        parsePsi(packet.subarray(offset), result);\n        this.trigger('data', result);\n      } else if (result.pid === this.pmtPid) {\n        result.type = 'pmt';\n        parsePsi(packet.subarray(offset), result);\n        this.trigger('data', result); // if there are any packets waiting for a PMT to be found, process them now\n\n        while (this.packetsWaitingForPmt.length) {\n          this.processPes_.apply(this, this.packetsWaitingForPmt.shift());\n        }\n      } else if (this.programMapTable === undefined) {\n        // When we have not seen a PMT yet, defer further processing of\n        // PES packets until one has been parsed\n        this.packetsWaitingForPmt.push([packet, offset, result]);\n      } else {\n        this.processPes_(packet, offset, result);\n      }\n    };\n\n    this.processPes_ = function (packet, offset, result) {\n      // set the appropriate stream type\n      if (result.pid === this.programMapTable.video) {\n        result.streamType = streamTypes.H264_STREAM_TYPE;\n      } else if (result.pid === this.programMapTable.audio) {\n        result.streamType = streamTypes.ADTS_STREAM_TYPE;\n      } else {\n        // if not video or audio, it is timed-metadata or unknown\n        // if unknown, streamType will be undefined\n        result.streamType = this.programMapTable['timed-metadata'][result.pid];\n      }\n\n      result.type = 'pes';\n      result.data = packet.subarray(offset);\n      this.trigger('data', result);\n    };\n  };\n\n  _TransportParseStream.prototype = new stream();\n  _TransportParseStream.STREAM_TYPES = {\n    h264: 0x1b,\n    adts: 0x0f\n  };\n  /**\n   * Reconsistutes program elementary stream (PES) packets from parsed\n   * transport stream packets. That is, if you pipe an\n   * mp2t.TransportParseStream into a mp2t.ElementaryStream, the output\n   * events will be events which capture the bytes for individual PES\n   * packets plus relevant metadata that has been extracted from the\n   * container.\n   */\n\n  _ElementaryStream = function ElementaryStream() {\n    var self = this,\n        segmentHadPmt = false,\n        // PES packet fragments\n    video = {\n      data: [],\n      size: 0\n    },\n        audio = {\n      data: [],\n      size: 0\n    },\n        timedMetadata = {\n      data: [],\n      size: 0\n    },\n        programMapTable,\n        parsePes = function parsePes(payload, pes) {\n      var ptsDtsFlags;\n      var startPrefix = payload[0] << 16 | payload[1] << 8 | payload[2]; // default to an empty array\n\n      pes.data = new Uint8Array(); // In certain live streams, the start of a TS fragment has ts packets\n      // that are frame data that is continuing from the previous fragment. This\n      // is to check that the pes data is the start of a new pes payload\n\n      if (startPrefix !== 1) {\n        return;\n      } // get the packet length, this will be 0 for video\n\n\n      pes.packetLength = 6 + (payload[4] << 8 | payload[5]); // find out if this packets starts a new keyframe\n\n      pes.dataAlignmentIndicator = (payload[6] & 0x04) !== 0; // PES packets may be annotated with a PTS value, or a PTS value\n      // and a DTS value. Determine what combination of values is\n      // available to work with.\n\n      ptsDtsFlags = payload[7]; // PTS and DTS are normally stored as a 33-bit number.  Javascript\n      // performs all bitwise operations on 32-bit integers but javascript\n      // supports a much greater range (52-bits) of integer using standard\n      // mathematical operations.\n      // We construct a 31-bit value using bitwise operators over the 31\n      // most significant bits and then multiply by 4 (equal to a left-shift\n      // of 2) before we add the final 2 least significant bits of the\n      // timestamp (equal to an OR.)\n\n      if (ptsDtsFlags & 0xC0) {\n        // the PTS and DTS are not written out directly. For information\n        // on how they are encoded, see\n        // http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n        pes.pts = (payload[9] & 0x0E) << 27 | (payload[10] & 0xFF) << 20 | (payload[11] & 0xFE) << 12 | (payload[12] & 0xFF) << 5 | (payload[13] & 0xFE) >>> 3;\n        pes.pts *= 4; // Left shift by 2\n\n        pes.pts += (payload[13] & 0x06) >>> 1; // OR by the two LSBs\n\n        pes.dts = pes.pts;\n\n        if (ptsDtsFlags & 0x40) {\n          pes.dts = (payload[14] & 0x0E) << 27 | (payload[15] & 0xFF) << 20 | (payload[16] & 0xFE) << 12 | (payload[17] & 0xFF) << 5 | (payload[18] & 0xFE) >>> 3;\n          pes.dts *= 4; // Left shift by 2\n\n          pes.dts += (payload[18] & 0x06) >>> 1; // OR by the two LSBs\n        }\n      } // the data section starts immediately after the PES header.\n      // pes_header_data_length specifies the number of header bytes\n      // that follow the last byte of the field.\n\n\n      pes.data = payload.subarray(9 + payload[8]);\n    },\n\n    /**\n      * Pass completely parsed PES packets to the next stream in the pipeline\n     **/\n    flushStream = function flushStream(stream, type, forceFlush) {\n      var packetData = new Uint8Array(stream.size),\n          event = {\n        type: type\n      },\n          i = 0,\n          offset = 0,\n          packetFlushable = false,\n          fragment; // do nothing if there is not enough buffered data for a complete\n      // PES header\n\n      if (!stream.data.length || stream.size < 9) {\n        return;\n      }\n\n      event.trackId = stream.data[0].pid; // reassemble the packet\n\n      for (i = 0; i < stream.data.length; i++) {\n        fragment = stream.data[i];\n        packetData.set(fragment.data, offset);\n        offset += fragment.data.byteLength;\n      } // parse assembled packet's PES header\n\n\n      parsePes(packetData, event); // non-video PES packets MUST have a non-zero PES_packet_length\n      // check that there is enough stream data to fill the packet\n\n      packetFlushable = type === 'video' || event.packetLength <= stream.size; // flush pending packets if the conditions are right\n\n      if (forceFlush || packetFlushable) {\n        stream.size = 0;\n        stream.data.length = 0;\n      } // only emit packets that are complete. this is to avoid assembling\n      // incomplete PES packets due to poor segmentation\n\n\n      if (packetFlushable) {\n        self.trigger('data', event);\n      }\n    };\n\n    _ElementaryStream.prototype.init.call(this);\n    /**\n     * Identifies M2TS packet types and parses PES packets using metadata\n     * parsed from the PMT\n     **/\n\n\n    this.push = function (data) {\n      ({\n        pat: function pat() {// we have to wait for the PMT to arrive as well before we\n          // have any meaningful metadata\n        },\n        pes: function pes() {\n          var stream, streamType;\n\n          switch (data.streamType) {\n            case streamTypes.H264_STREAM_TYPE:\n              stream = video;\n              streamType = 'video';\n              break;\n\n            case streamTypes.ADTS_STREAM_TYPE:\n              stream = audio;\n              streamType = 'audio';\n              break;\n\n            case streamTypes.METADATA_STREAM_TYPE:\n              stream = timedMetadata;\n              streamType = 'timed-metadata';\n              break;\n\n            default:\n              // ignore unknown stream types\n              return;\n          } // if a new packet is starting, we can flush the completed\n          // packet\n\n\n          if (data.payloadUnitStartIndicator) {\n            flushStream(stream, streamType, true);\n          } // buffer this fragment until we are sure we've received the\n          // complete payload\n\n\n          stream.data.push(data);\n          stream.size += data.data.byteLength;\n        },\n        pmt: function pmt() {\n          var event = {\n            type: 'metadata',\n            tracks: []\n          };\n          programMapTable = data.programMapTable; // translate audio and video streams to tracks\n\n          if (programMapTable.video !== null) {\n            event.tracks.push({\n              timelineStartInfo: {\n                baseMediaDecodeTime: 0\n              },\n              id: +programMapTable.video,\n              codec: 'avc',\n              type: 'video'\n            });\n          }\n\n          if (programMapTable.audio !== null) {\n            event.tracks.push({\n              timelineStartInfo: {\n                baseMediaDecodeTime: 0\n              },\n              id: +programMapTable.audio,\n              codec: 'adts',\n              type: 'audio'\n            });\n          }\n\n          segmentHadPmt = true;\n          self.trigger('data', event);\n        }\n      })[data.type]();\n    };\n\n    this.reset = function () {\n      video.size = 0;\n      video.data.length = 0;\n      audio.size = 0;\n      audio.data.length = 0;\n      this.trigger('reset');\n    };\n    /**\n     * Flush any remaining input. Video PES packets may be of variable\n     * length. Normally, the start of a new video packet can trigger the\n     * finalization of the previous packet. That is not possible if no\n     * more video is forthcoming, however. In that case, some other\n     * mechanism (like the end of the file) has to be employed. When it is\n     * clear that no additional data is forthcoming, calling this method\n     * will flush the buffered packets.\n     */\n\n\n    this.flushStreams_ = function () {\n      // !!THIS ORDER IS IMPORTANT!!\n      // video first then audio\n      flushStream(video, 'video');\n      flushStream(audio, 'audio');\n      flushStream(timedMetadata, 'timed-metadata');\n    };\n\n    this.flush = function () {\n      // if on flush we haven't had a pmt emitted\n      // and we have a pmt to emit. emit the pmt\n      // so that we trigger a trackinfo downstream.\n      if (!segmentHadPmt && programMapTable) {\n        var pmt = {\n          type: 'metadata',\n          tracks: []\n        }; // translate audio and video streams to tracks\n\n        if (programMapTable.video !== null) {\n          pmt.tracks.push({\n            timelineStartInfo: {\n              baseMediaDecodeTime: 0\n            },\n            id: +programMapTable.video,\n            codec: 'avc',\n            type: 'video'\n          });\n        }\n\n        if (programMapTable.audio !== null) {\n          pmt.tracks.push({\n            timelineStartInfo: {\n              baseMediaDecodeTime: 0\n            },\n            id: +programMapTable.audio,\n            codec: 'adts',\n            type: 'audio'\n          });\n        }\n\n        self.trigger('data', pmt);\n      }\n\n      segmentHadPmt = false;\n      this.flushStreams_();\n      this.trigger('done');\n    };\n  };\n\n  _ElementaryStream.prototype = new stream();\n  var m2ts$1 = {\n    PAT_PID: 0x0000,\n    MP2T_PACKET_LENGTH: MP2T_PACKET_LENGTH$1,\n    TransportPacketStream: _TransportPacketStream,\n    TransportParseStream: _TransportParseStream,\n    ElementaryStream: _ElementaryStream,\n    TimestampRolloverStream: TimestampRolloverStream,\n    CaptionStream: captionStream.CaptionStream,\n    Cea608Stream: captionStream.Cea608Stream,\n    Cea708Stream: captionStream.Cea708Stream,\n    MetadataStream: metadataStream\n  };\n\n  for (var type in streamTypes) {\n    if (streamTypes.hasOwnProperty(type)) {\n      m2ts$1[type] = streamTypes[type];\n    }\n  }\n\n  var m2ts_1 = m2ts$1;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   *\n   * Utilities to detect basic properties and metadata about Aac data.\n   */\n\n  var ADTS_SAMPLING_FREQUENCIES = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n\n  var parseId3TagSize = function parseId3TagSize(header, byteIndex) {\n    var returnSize = header[byteIndex + 6] << 21 | header[byteIndex + 7] << 14 | header[byteIndex + 8] << 7 | header[byteIndex + 9],\n        flags = header[byteIndex + 5],\n        footerPresent = (flags & 16) >> 4; // if we get a negative returnSize clamp it to 0\n\n    returnSize = returnSize >= 0 ? returnSize : 0;\n\n    if (footerPresent) {\n      return returnSize + 20;\n    }\n\n    return returnSize + 10;\n  };\n\n  var getId3Offset = function getId3Offset(data, offset) {\n    if (data.length - offset < 10 || data[offset] !== 'I'.charCodeAt(0) || data[offset + 1] !== 'D'.charCodeAt(0) || data[offset + 2] !== '3'.charCodeAt(0)) {\n      return offset;\n    }\n\n    offset += parseId3TagSize(data, offset);\n    return getId3Offset(data, offset);\n  }; // TODO: use vhs-utils\n\n\n  var isLikelyAacData$2 = function isLikelyAacData(data) {\n    var offset = getId3Offset(data, 0);\n    return data.length >= offset + 2 && (data[offset] & 0xFF) === 0xFF && (data[offset + 1] & 0xF0) === 0xF0 && // verify that the 2 layer bits are 0, aka this\n    // is not mp3 data but aac data.\n    (data[offset + 1] & 0x16) === 0x10;\n  };\n\n  var parseSyncSafeInteger = function parseSyncSafeInteger(data) {\n    return data[0] << 21 | data[1] << 14 | data[2] << 7 | data[3];\n  }; // return a percent-encoded representation of the specified byte range\n  // @see http://en.wikipedia.org/wiki/Percent-encoding\n\n\n  var percentEncode = function percentEncode(bytes, start, end) {\n    var i,\n        result = '';\n\n    for (i = start; i < end; i++) {\n      result += '%' + ('00' + bytes[i].toString(16)).slice(-2);\n    }\n\n    return result;\n  }; // return the string representation of the specified byte range,\n  // interpreted as ISO-8859-1.\n\n\n  var parseIso88591 = function parseIso88591(bytes, start, end) {\n    return unescape(percentEncode(bytes, start, end)); // jshint ignore:line\n  };\n\n  var parseAdtsSize = function parseAdtsSize(header, byteIndex) {\n    var lowThree = (header[byteIndex + 5] & 0xE0) >> 5,\n        middle = header[byteIndex + 4] << 3,\n        highTwo = header[byteIndex + 3] & 0x3 << 11;\n    return highTwo | middle | lowThree;\n  };\n\n  var parseType$1 = function parseType(header, byteIndex) {\n    if (header[byteIndex] === 'I'.charCodeAt(0) && header[byteIndex + 1] === 'D'.charCodeAt(0) && header[byteIndex + 2] === '3'.charCodeAt(0)) {\n      return 'timed-metadata';\n    } else if (header[byteIndex] & 0xff === 0xff && (header[byteIndex + 1] & 0xf0) === 0xf0) {\n      return 'audio';\n    }\n\n    return null;\n  };\n\n  var parseSampleRate = function parseSampleRate(packet) {\n    var i = 0;\n\n    while (i + 5 < packet.length) {\n      if (packet[i] !== 0xFF || (packet[i + 1] & 0xF6) !== 0xF0) {\n        // If a valid header was not found,  jump one forward and attempt to\n        // find a valid ADTS header starting at the next byte\n        i++;\n        continue;\n      }\n\n      return ADTS_SAMPLING_FREQUENCIES[(packet[i + 2] & 0x3c) >>> 2];\n    }\n\n    return null;\n  };\n\n  var parseAacTimestamp = function parseAacTimestamp(packet) {\n    var frameStart, frameSize, frame, frameHeader; // find the start of the first frame and the end of the tag\n\n    frameStart = 10;\n\n    if (packet[5] & 0x40) {\n      // advance the frame start past the extended header\n      frameStart += 4; // header size field\n\n      frameStart += parseSyncSafeInteger(packet.subarray(10, 14));\n    } // parse one or more ID3 frames\n    // http://id3.org/id3v2.3.0#ID3v2_frame_overview\n\n\n    do {\n      // determine the number of bytes in this frame\n      frameSize = parseSyncSafeInteger(packet.subarray(frameStart + 4, frameStart + 8));\n\n      if (frameSize < 1) {\n        return null;\n      }\n\n      frameHeader = String.fromCharCode(packet[frameStart], packet[frameStart + 1], packet[frameStart + 2], packet[frameStart + 3]);\n\n      if (frameHeader === 'PRIV') {\n        frame = packet.subarray(frameStart + 10, frameStart + frameSize + 10);\n\n        for (var i = 0; i < frame.byteLength; i++) {\n          if (frame[i] === 0) {\n            var owner = parseIso88591(frame, 0, i);\n\n            if (owner === 'com.apple.streaming.transportStreamTimestamp') {\n              var d = frame.subarray(i + 1);\n              var size = (d[3] & 0x01) << 30 | d[4] << 22 | d[5] << 14 | d[6] << 6 | d[7] >>> 2;\n              size *= 4;\n              size += d[7] & 0x03;\n              return size;\n            }\n\n            break;\n          }\n        }\n      }\n\n      frameStart += 10; // advance past the frame header\n\n      frameStart += frameSize; // advance past the frame body\n    } while (frameStart < packet.byteLength);\n\n    return null;\n  };\n\n  var utils = {\n    isLikelyAacData: isLikelyAacData$2,\n    parseId3TagSize: parseId3TagSize,\n    parseAdtsSize: parseAdtsSize,\n    parseType: parseType$1,\n    parseSampleRate: parseSampleRate,\n    parseAacTimestamp: parseAacTimestamp\n  };\n\n  var _AacStream;\n  /**\n   * Splits an incoming stream of binary data into ADTS and ID3 Frames.\n   */\n\n\n  _AacStream = function AacStream() {\n    var everything = new Uint8Array(),\n        timeStamp = 0;\n\n    _AacStream.prototype.init.call(this);\n\n    this.setTimestamp = function (timestamp) {\n      timeStamp = timestamp;\n    };\n\n    this.push = function (bytes) {\n      var frameSize = 0,\n          byteIndex = 0,\n          bytesLeft,\n          chunk,\n          packet,\n          tempLength; // If there are bytes remaining from the last segment, prepend them to the\n      // bytes that were pushed in\n\n      if (everything.length) {\n        tempLength = everything.length;\n        everything = new Uint8Array(bytes.byteLength + tempLength);\n        everything.set(everything.subarray(0, tempLength));\n        everything.set(bytes, tempLength);\n      } else {\n        everything = bytes;\n      }\n\n      while (everything.length - byteIndex >= 3) {\n        if (everything[byteIndex] === 'I'.charCodeAt(0) && everything[byteIndex + 1] === 'D'.charCodeAt(0) && everything[byteIndex + 2] === '3'.charCodeAt(0)) {\n          // Exit early because we don't have enough to parse\n          // the ID3 tag header\n          if (everything.length - byteIndex < 10) {\n            break;\n          } // check framesize\n\n\n          frameSize = utils.parseId3TagSize(everything, byteIndex); // Exit early if we don't have enough in the buffer\n          // to emit a full packet\n          // Add to byteIndex to support multiple ID3 tags in sequence\n\n          if (byteIndex + frameSize > everything.length) {\n            break;\n          }\n\n          chunk = {\n            type: 'timed-metadata',\n            data: everything.subarray(byteIndex, byteIndex + frameSize)\n          };\n          this.trigger('data', chunk);\n          byteIndex += frameSize;\n          continue;\n        } else if ((everything[byteIndex] & 0xff) === 0xff && (everything[byteIndex + 1] & 0xf0) === 0xf0) {\n          // Exit early because we don't have enough to parse\n          // the ADTS frame header\n          if (everything.length - byteIndex < 7) {\n            break;\n          }\n\n          frameSize = utils.parseAdtsSize(everything, byteIndex); // Exit early if we don't have enough in the buffer\n          // to emit a full packet\n\n          if (byteIndex + frameSize > everything.length) {\n            break;\n          }\n\n          packet = {\n            type: 'audio',\n            data: everything.subarray(byteIndex, byteIndex + frameSize),\n            pts: timeStamp,\n            dts: timeStamp\n          };\n          this.trigger('data', packet);\n          byteIndex += frameSize;\n          continue;\n        }\n\n        byteIndex++;\n      }\n\n      bytesLeft = everything.length - byteIndex;\n\n      if (bytesLeft > 0) {\n        everything = everything.subarray(byteIndex);\n      } else {\n        everything = new Uint8Array();\n      }\n    };\n\n    this.reset = function () {\n      everything = new Uint8Array();\n      this.trigger('reset');\n    };\n\n    this.endTimeline = function () {\n      everything = new Uint8Array();\n      this.trigger('endedtimeline');\n    };\n  };\n\n  _AacStream.prototype = new stream();\n  var aac = _AacStream;\n\n  // constants\n  var AUDIO_PROPERTIES = ['audioobjecttype', 'channelcount', 'samplerate', 'samplingfrequencyindex', 'samplesize'];\n  var audioProperties = AUDIO_PROPERTIES;\n\n  var VIDEO_PROPERTIES = ['width', 'height', 'profileIdc', 'levelIdc', 'profileCompatibility', 'sarRatio'];\n  var videoProperties = VIDEO_PROPERTIES;\n\n  var H264Stream$1 = h264.H264Stream;\n  var isLikelyAacData$1 = utils.isLikelyAacData;\n  var ONE_SECOND_IN_TS$2 = clock.ONE_SECOND_IN_TS; // object types\n\n  var _VideoSegmentStream$1, _AudioSegmentStream$1, _Transmuxer$1, _CoalesceStream;\n\n  var retriggerForStream = function retriggerForStream(key, event) {\n    event.stream = key;\n    this.trigger('log', event);\n  };\n\n  var addPipelineLogRetriggers = function addPipelineLogRetriggers(transmuxer, pipeline) {\n    var keys = Object.keys(pipeline);\n\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]; // skip non-stream keys and headOfPipeline\n      // which is just a duplicate\n\n      if (key === 'headOfPipeline' || !pipeline[key].on) {\n        continue;\n      }\n\n      pipeline[key].on('log', retriggerForStream.bind(transmuxer, key));\n    }\n  };\n  /**\n   * Compare two arrays (even typed) for same-ness\n   */\n\n\n  var arrayEquals = function arrayEquals(a, b) {\n    var i;\n\n    if (a.length !== b.length) {\n      return false;\n    } // compare the value of each element in the array\n\n\n    for (i = 0; i < a.length; i++) {\n      if (a[i] !== b[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  var generateSegmentTimingInfo = function generateSegmentTimingInfo(baseMediaDecodeTime, startDts, startPts, endDts, endPts, prependedContentDuration) {\n    var ptsOffsetFromDts = startPts - startDts,\n        decodeDuration = endDts - startDts,\n        presentationDuration = endPts - startPts; // The PTS and DTS values are based on the actual stream times from the segment,\n    // however, the player time values will reflect a start from the baseMediaDecodeTime.\n    // In order to provide relevant values for the player times, base timing info on the\n    // baseMediaDecodeTime and the DTS and PTS durations of the segment.\n\n    return {\n      start: {\n        dts: baseMediaDecodeTime,\n        pts: baseMediaDecodeTime + ptsOffsetFromDts\n      },\n      end: {\n        dts: baseMediaDecodeTime + decodeDuration,\n        pts: baseMediaDecodeTime + presentationDuration\n      },\n      prependedContentDuration: prependedContentDuration,\n      baseMediaDecodeTime: baseMediaDecodeTime\n    };\n  };\n  /**\n   * Constructs a single-track, ISO BMFF media segment from AAC data\n   * events. The output of this stream can be fed to a SourceBuffer\n   * configured with a suitable initialization segment.\n   * @param track {object} track metadata configuration\n   * @param options {object} transmuxer options object\n   * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n   *        in the source; false to adjust the first segment to start at 0.\n   */\n\n\n  _AudioSegmentStream$1 = function AudioSegmentStream(track, options) {\n    var adtsFrames = [],\n        sequenceNumber,\n        earliestAllowedDts = 0,\n        audioAppendStartTs = 0,\n        videoBaseMediaDecodeTime = Infinity;\n    options = options || {};\n    sequenceNumber = options.firstSequenceNumber || 0;\n\n    _AudioSegmentStream$1.prototype.init.call(this);\n\n    this.push = function (data) {\n      trackDecodeInfo.collectDtsInfo(track, data);\n\n      if (track) {\n        audioProperties.forEach(function (prop) {\n          track[prop] = data[prop];\n        });\n      } // buffer audio data until end() is called\n\n\n      adtsFrames.push(data);\n    };\n\n    this.setEarliestDts = function (earliestDts) {\n      earliestAllowedDts = earliestDts;\n    };\n\n    this.setVideoBaseMediaDecodeTime = function (baseMediaDecodeTime) {\n      videoBaseMediaDecodeTime = baseMediaDecodeTime;\n    };\n\n    this.setAudioAppendStart = function (timestamp) {\n      audioAppendStartTs = timestamp;\n    };\n\n    this.flush = function () {\n      var frames, moof, mdat, boxes, frameDuration, segmentDuration, videoClockCyclesOfSilencePrefixed; // return early if no audio data has been observed\n\n      if (adtsFrames.length === 0) {\n        this.trigger('done', 'AudioSegmentStream');\n        return;\n      }\n\n      frames = audioFrameUtils.trimAdtsFramesByEarliestDts(adtsFrames, track, earliestAllowedDts);\n      track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(track, options.keepOriginalTimestamps); // amount of audio filled but the value is in video clock rather than audio clock\n\n      videoClockCyclesOfSilencePrefixed = audioFrameUtils.prefixWithSilence(track, frames, audioAppendStartTs, videoBaseMediaDecodeTime); // we have to build the index from byte locations to\n      // samples (that is, adts frames) in the audio data\n\n      track.samples = audioFrameUtils.generateSampleTable(frames); // concatenate the audio data to constuct the mdat\n\n      mdat = mp4Generator.mdat(audioFrameUtils.concatenateFrameData(frames));\n      adtsFrames = [];\n      moof = mp4Generator.moof(sequenceNumber, [track]);\n      boxes = new Uint8Array(moof.byteLength + mdat.byteLength); // bump the sequence number for next time\n\n      sequenceNumber++;\n      boxes.set(moof);\n      boxes.set(mdat, moof.byteLength);\n      trackDecodeInfo.clearDtsInfo(track);\n      frameDuration = Math.ceil(ONE_SECOND_IN_TS$2 * 1024 / track.samplerate); // TODO this check was added to maintain backwards compatibility (particularly with\n      // tests) on adding the timingInfo event. However, it seems unlikely that there's a\n      // valid use-case where an init segment/data should be triggered without associated\n      // frames. Leaving for now, but should be looked into.\n\n      if (frames.length) {\n        segmentDuration = frames.length * frameDuration;\n        this.trigger('segmentTimingInfo', generateSegmentTimingInfo( // The audio track's baseMediaDecodeTime is in audio clock cycles, but the\n        // frame info is in video clock cycles. Convert to match expectation of\n        // listeners (that all timestamps will be based on video clock cycles).\n        clock.audioTsToVideoTs(track.baseMediaDecodeTime, track.samplerate), // frame times are already in video clock, as is segment duration\n        frames[0].dts, frames[0].pts, frames[0].dts + segmentDuration, frames[0].pts + segmentDuration, videoClockCyclesOfSilencePrefixed || 0));\n        this.trigger('timingInfo', {\n          start: frames[0].pts,\n          end: frames[0].pts + segmentDuration\n        });\n      }\n\n      this.trigger('data', {\n        track: track,\n        boxes: boxes\n      });\n      this.trigger('done', 'AudioSegmentStream');\n    };\n\n    this.reset = function () {\n      trackDecodeInfo.clearDtsInfo(track);\n      adtsFrames = [];\n      this.trigger('reset');\n    };\n  };\n\n  _AudioSegmentStream$1.prototype = new stream();\n  /**\n   * Constructs a single-track, ISO BMFF media segment from H264 data\n   * events. The output of this stream can be fed to a SourceBuffer\n   * configured with a suitable initialization segment.\n   * @param track {object} track metadata configuration\n   * @param options {object} transmuxer options object\n   * @param options.alignGopsAtEnd {boolean} If true, start from the end of the\n   *        gopsToAlignWith list when attempting to align gop pts\n   * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n   *        in the source; false to adjust the first segment to start at 0.\n   */\n\n  _VideoSegmentStream$1 = function VideoSegmentStream(track, options) {\n    var sequenceNumber,\n        nalUnits = [],\n        gopsToAlignWith = [],\n        config,\n        pps;\n    options = options || {};\n    sequenceNumber = options.firstSequenceNumber || 0;\n\n    _VideoSegmentStream$1.prototype.init.call(this);\n\n    delete track.minPTS;\n    this.gopCache_ = [];\n    /**\n      * Constructs a ISO BMFF segment given H264 nalUnits\n      * @param {Object} nalUnit A data event representing a nalUnit\n      * @param {String} nalUnit.nalUnitType\n      * @param {Object} nalUnit.config Properties for a mp4 track\n      * @param {Uint8Array} nalUnit.data The nalUnit bytes\n      * @see lib/codecs/h264.js\n     **/\n\n    this.push = function (nalUnit) {\n      trackDecodeInfo.collectDtsInfo(track, nalUnit); // record the track config\n\n      if (nalUnit.nalUnitType === 'seq_parameter_set_rbsp' && !config) {\n        config = nalUnit.config;\n        track.sps = [nalUnit.data];\n        videoProperties.forEach(function (prop) {\n          track[prop] = config[prop];\n        }, this);\n      }\n\n      if (nalUnit.nalUnitType === 'pic_parameter_set_rbsp' && !pps) {\n        pps = nalUnit.data;\n        track.pps = [nalUnit.data];\n      } // buffer video until flush() is called\n\n\n      nalUnits.push(nalUnit);\n    };\n    /**\n      * Pass constructed ISO BMFF track and boxes on to the\n      * next stream in the pipeline\n     **/\n\n\n    this.flush = function () {\n      var frames,\n          gopForFusion,\n          gops,\n          moof,\n          mdat,\n          boxes,\n          prependedContentDuration = 0,\n          firstGop,\n          lastGop; // Throw away nalUnits at the start of the byte stream until\n      // we find the first AUD\n\n      while (nalUnits.length) {\n        if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n          break;\n        }\n\n        nalUnits.shift();\n      } // Return early if no video data has been observed\n\n\n      if (nalUnits.length === 0) {\n        this.resetStream_();\n        this.trigger('done', 'VideoSegmentStream');\n        return;\n      } // Organize the raw nal-units into arrays that represent\n      // higher-level constructs such as frames and gops\n      // (group-of-pictures)\n\n\n      frames = frameUtils.groupNalsIntoFrames(nalUnits);\n      gops = frameUtils.groupFramesIntoGops(frames); // If the first frame of this fragment is not a keyframe we have\n      // a problem since MSE (on Chrome) requires a leading keyframe.\n      //\n      // We have two approaches to repairing this situation:\n      // 1) GOP-FUSION:\n      //    This is where we keep track of the GOPS (group-of-pictures)\n      //    from previous fragments and attempt to find one that we can\n      //    prepend to the current fragment in order to create a valid\n      //    fragment.\n      // 2) KEYFRAME-PULLING:\n      //    Here we search for the first keyframe in the fragment and\n      //    throw away all the frames between the start of the fragment\n      //    and that keyframe. We then extend the duration and pull the\n      //    PTS of the keyframe forward so that it covers the time range\n      //    of the frames that were disposed of.\n      //\n      // #1 is far prefereable over #2 which can cause \"stuttering\" but\n      // requires more things to be just right.\n\n      if (!gops[0][0].keyFrame) {\n        // Search for a gop for fusion from our gopCache\n        gopForFusion = this.getGopForFusion_(nalUnits[0], track);\n\n        if (gopForFusion) {\n          // in order to provide more accurate timing information about the segment, save\n          // the number of seconds prepended to the original segment due to GOP fusion\n          prependedContentDuration = gopForFusion.duration;\n          gops.unshift(gopForFusion); // Adjust Gops' metadata to account for the inclusion of the\n          // new gop at the beginning\n\n          gops.byteLength += gopForFusion.byteLength;\n          gops.nalCount += gopForFusion.nalCount;\n          gops.pts = gopForFusion.pts;\n          gops.dts = gopForFusion.dts;\n          gops.duration += gopForFusion.duration;\n        } else {\n          // If we didn't find a candidate gop fall back to keyframe-pulling\n          gops = frameUtils.extendFirstKeyFrame(gops);\n        }\n      } // Trim gops to align with gopsToAlignWith\n\n\n      if (gopsToAlignWith.length) {\n        var alignedGops;\n\n        if (options.alignGopsAtEnd) {\n          alignedGops = this.alignGopsAtEnd_(gops);\n        } else {\n          alignedGops = this.alignGopsAtStart_(gops);\n        }\n\n        if (!alignedGops) {\n          // save all the nals in the last GOP into the gop cache\n          this.gopCache_.unshift({\n            gop: gops.pop(),\n            pps: track.pps,\n            sps: track.sps\n          }); // Keep a maximum of 6 GOPs in the cache\n\n          this.gopCache_.length = Math.min(6, this.gopCache_.length); // Clear nalUnits\n\n          nalUnits = []; // return early no gops can be aligned with desired gopsToAlignWith\n\n          this.resetStream_();\n          this.trigger('done', 'VideoSegmentStream');\n          return;\n        } // Some gops were trimmed. clear dts info so minSegmentDts and pts are correct\n        // when recalculated before sending off to CoalesceStream\n\n\n        trackDecodeInfo.clearDtsInfo(track);\n        gops = alignedGops;\n      }\n\n      trackDecodeInfo.collectDtsInfo(track, gops); // First, we have to build the index from byte locations to\n      // samples (that is, frames) in the video data\n\n      track.samples = frameUtils.generateSampleTable(gops); // Concatenate the video data and construct the mdat\n\n      mdat = mp4Generator.mdat(frameUtils.concatenateNalData(gops));\n      track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(track, options.keepOriginalTimestamps);\n      this.trigger('processedGopsInfo', gops.map(function (gop) {\n        return {\n          pts: gop.pts,\n          dts: gop.dts,\n          byteLength: gop.byteLength\n        };\n      }));\n      firstGop = gops[0];\n      lastGop = gops[gops.length - 1];\n      this.trigger('segmentTimingInfo', generateSegmentTimingInfo(track.baseMediaDecodeTime, firstGop.dts, firstGop.pts, lastGop.dts + lastGop.duration, lastGop.pts + lastGop.duration, prependedContentDuration));\n      this.trigger('timingInfo', {\n        start: gops[0].pts,\n        end: gops[gops.length - 1].pts + gops[gops.length - 1].duration\n      }); // save all the nals in the last GOP into the gop cache\n\n      this.gopCache_.unshift({\n        gop: gops.pop(),\n        pps: track.pps,\n        sps: track.sps\n      }); // Keep a maximum of 6 GOPs in the cache\n\n      this.gopCache_.length = Math.min(6, this.gopCache_.length); // Clear nalUnits\n\n      nalUnits = [];\n      this.trigger('baseMediaDecodeTime', track.baseMediaDecodeTime);\n      this.trigger('timelineStartInfo', track.timelineStartInfo);\n      moof = mp4Generator.moof(sequenceNumber, [track]); // it would be great to allocate this array up front instead of\n      // throwing away hundreds of media segment fragments\n\n      boxes = new Uint8Array(moof.byteLength + mdat.byteLength); // Bump the sequence number for next time\n\n      sequenceNumber++;\n      boxes.set(moof);\n      boxes.set(mdat, moof.byteLength);\n      this.trigger('data', {\n        track: track,\n        boxes: boxes\n      });\n      this.resetStream_(); // Continue with the flush process now\n\n      this.trigger('done', 'VideoSegmentStream');\n    };\n\n    this.reset = function () {\n      this.resetStream_();\n      nalUnits = [];\n      this.gopCache_.length = 0;\n      gopsToAlignWith.length = 0;\n      this.trigger('reset');\n    };\n\n    this.resetStream_ = function () {\n      trackDecodeInfo.clearDtsInfo(track); // reset config and pps because they may differ across segments\n      // for instance, when we are rendition switching\n\n      config = undefined;\n      pps = undefined;\n    }; // Search for a candidate Gop for gop-fusion from the gop cache and\n    // return it or return null if no good candidate was found\n\n\n    this.getGopForFusion_ = function (nalUnit) {\n      var halfSecond = 45000,\n          // Half-a-second in a 90khz clock\n      allowableOverlap = 10000,\n          // About 3 frames @ 30fps\n      nearestDistance = Infinity,\n          dtsDistance,\n          nearestGopObj,\n          currentGop,\n          currentGopObj,\n          i; // Search for the GOP nearest to the beginning of this nal unit\n\n      for (i = 0; i < this.gopCache_.length; i++) {\n        currentGopObj = this.gopCache_[i];\n        currentGop = currentGopObj.gop; // Reject Gops with different SPS or PPS\n\n        if (!(track.pps && arrayEquals(track.pps[0], currentGopObj.pps[0])) || !(track.sps && arrayEquals(track.sps[0], currentGopObj.sps[0]))) {\n          continue;\n        } // Reject Gops that would require a negative baseMediaDecodeTime\n\n\n        if (currentGop.dts < track.timelineStartInfo.dts) {\n          continue;\n        } // The distance between the end of the gop and the start of the nalUnit\n\n\n        dtsDistance = nalUnit.dts - currentGop.dts - currentGop.duration; // Only consider GOPS that start before the nal unit and end within\n        // a half-second of the nal unit\n\n        if (dtsDistance >= -allowableOverlap && dtsDistance <= halfSecond) {\n          // Always use the closest GOP we found if there is more than\n          // one candidate\n          if (!nearestGopObj || nearestDistance > dtsDistance) {\n            nearestGopObj = currentGopObj;\n            nearestDistance = dtsDistance;\n          }\n        }\n      }\n\n      if (nearestGopObj) {\n        return nearestGopObj.gop;\n      }\n\n      return null;\n    }; // trim gop list to the first gop found that has a matching pts with a gop in the list\n    // of gopsToAlignWith starting from the START of the list\n\n\n    this.alignGopsAtStart_ = function (gops) {\n      var alignIndex, gopIndex, align, gop, byteLength, nalCount, duration, alignedGops;\n      byteLength = gops.byteLength;\n      nalCount = gops.nalCount;\n      duration = gops.duration;\n      alignIndex = gopIndex = 0;\n\n      while (alignIndex < gopsToAlignWith.length && gopIndex < gops.length) {\n        align = gopsToAlignWith[alignIndex];\n        gop = gops[gopIndex];\n\n        if (align.pts === gop.pts) {\n          break;\n        }\n\n        if (gop.pts > align.pts) {\n          // this current gop starts after the current gop we want to align on, so increment\n          // align index\n          alignIndex++;\n          continue;\n        } // current gop starts before the current gop we want to align on. so increment gop\n        // index\n\n\n        gopIndex++;\n        byteLength -= gop.byteLength;\n        nalCount -= gop.nalCount;\n        duration -= gop.duration;\n      }\n\n      if (gopIndex === 0) {\n        // no gops to trim\n        return gops;\n      }\n\n      if (gopIndex === gops.length) {\n        // all gops trimmed, skip appending all gops\n        return null;\n      }\n\n      alignedGops = gops.slice(gopIndex);\n      alignedGops.byteLength = byteLength;\n      alignedGops.duration = duration;\n      alignedGops.nalCount = nalCount;\n      alignedGops.pts = alignedGops[0].pts;\n      alignedGops.dts = alignedGops[0].dts;\n      return alignedGops;\n    }; // trim gop list to the first gop found that has a matching pts with a gop in the list\n    // of gopsToAlignWith starting from the END of the list\n\n\n    this.alignGopsAtEnd_ = function (gops) {\n      var alignIndex, gopIndex, align, gop, alignEndIndex, matchFound;\n      alignIndex = gopsToAlignWith.length - 1;\n      gopIndex = gops.length - 1;\n      alignEndIndex = null;\n      matchFound = false;\n\n      while (alignIndex >= 0 && gopIndex >= 0) {\n        align = gopsToAlignWith[alignIndex];\n        gop = gops[gopIndex];\n\n        if (align.pts === gop.pts) {\n          matchFound = true;\n          break;\n        }\n\n        if (align.pts > gop.pts) {\n          alignIndex--;\n          continue;\n        }\n\n        if (alignIndex === gopsToAlignWith.length - 1) {\n          // gop.pts is greater than the last alignment candidate. If no match is found\n          // by the end of this loop, we still want to append gops that come after this\n          // point\n          alignEndIndex = gopIndex;\n        }\n\n        gopIndex--;\n      }\n\n      if (!matchFound && alignEndIndex === null) {\n        return null;\n      }\n\n      var trimIndex;\n\n      if (matchFound) {\n        trimIndex = gopIndex;\n      } else {\n        trimIndex = alignEndIndex;\n      }\n\n      if (trimIndex === 0) {\n        return gops;\n      }\n\n      var alignedGops = gops.slice(trimIndex);\n      var metadata = alignedGops.reduce(function (total, gop) {\n        total.byteLength += gop.byteLength;\n        total.duration += gop.duration;\n        total.nalCount += gop.nalCount;\n        return total;\n      }, {\n        byteLength: 0,\n        duration: 0,\n        nalCount: 0\n      });\n      alignedGops.byteLength = metadata.byteLength;\n      alignedGops.duration = metadata.duration;\n      alignedGops.nalCount = metadata.nalCount;\n      alignedGops.pts = alignedGops[0].pts;\n      alignedGops.dts = alignedGops[0].dts;\n      return alignedGops;\n    };\n\n    this.alignGopsWith = function (newGopsToAlignWith) {\n      gopsToAlignWith = newGopsToAlignWith;\n    };\n  };\n\n  _VideoSegmentStream$1.prototype = new stream();\n  /**\n   * A Stream that can combine multiple streams (ie. audio & video)\n   * into a single output segment for MSE. Also supports audio-only\n   * and video-only streams.\n   * @param options {object} transmuxer options object\n   * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n   *        in the source; false to adjust the first segment to start at media timeline start.\n   */\n\n  _CoalesceStream = function CoalesceStream(options, metadataStream) {\n    // Number of Tracks per output segment\n    // If greater than 1, we combine multiple\n    // tracks into a single segment\n    this.numberOfTracks = 0;\n    this.metadataStream = metadataStream;\n    options = options || {};\n\n    if (typeof options.remux !== 'undefined') {\n      this.remuxTracks = !!options.remux;\n    } else {\n      this.remuxTracks = true;\n    }\n\n    if (typeof options.keepOriginalTimestamps === 'boolean') {\n      this.keepOriginalTimestamps = options.keepOriginalTimestamps;\n    } else {\n      this.keepOriginalTimestamps = false;\n    }\n\n    this.pendingTracks = [];\n    this.videoTrack = null;\n    this.pendingBoxes = [];\n    this.pendingCaptions = [];\n    this.pendingMetadata = [];\n    this.pendingBytes = 0;\n    this.emittedTracks = 0;\n\n    _CoalesceStream.prototype.init.call(this); // Take output from multiple\n\n\n    this.push = function (output) {\n      // buffer incoming captions until the associated video segment\n      // finishes\n      if (output.text) {\n        return this.pendingCaptions.push(output);\n      } // buffer incoming id3 tags until the final flush\n\n\n      if (output.frames) {\n        return this.pendingMetadata.push(output);\n      } // Add this track to the list of pending tracks and store\n      // important information required for the construction of\n      // the final segment\n\n\n      this.pendingTracks.push(output.track);\n      this.pendingBytes += output.boxes.byteLength; // TODO: is there an issue for this against chrome?\n      // We unshift audio and push video because\n      // as of Chrome 75 when switching from\n      // one init segment to another if the video\n      // mdat does not appear after the audio mdat\n      // only audio will play for the duration of our transmux.\n\n      if (output.track.type === 'video') {\n        this.videoTrack = output.track;\n        this.pendingBoxes.push(output.boxes);\n      }\n\n      if (output.track.type === 'audio') {\n        this.audioTrack = output.track;\n        this.pendingBoxes.unshift(output.boxes);\n      }\n    };\n  };\n\n  _CoalesceStream.prototype = new stream();\n\n  _CoalesceStream.prototype.flush = function (flushSource) {\n    var offset = 0,\n        event = {\n      captions: [],\n      captionStreams: {},\n      metadata: [],\n      info: {}\n    },\n        caption,\n        id3,\n        initSegment,\n        timelineStartPts = 0,\n        i;\n\n    if (this.pendingTracks.length < this.numberOfTracks) {\n      if (flushSource !== 'VideoSegmentStream' && flushSource !== 'AudioSegmentStream') {\n        // Return because we haven't received a flush from a data-generating\n        // portion of the segment (meaning that we have only recieved meta-data\n        // or captions.)\n        return;\n      } else if (this.remuxTracks) {\n        // Return until we have enough tracks from the pipeline to remux (if we\n        // are remuxing audio and video into a single MP4)\n        return;\n      } else if (this.pendingTracks.length === 0) {\n        // In the case where we receive a flush without any data having been\n        // received we consider it an emitted track for the purposes of coalescing\n        // `done` events.\n        // We do this for the case where there is an audio and video track in the\n        // segment but no audio data. (seen in several playlists with alternate\n        // audio tracks and no audio present in the main TS segments.)\n        this.emittedTracks++;\n\n        if (this.emittedTracks >= this.numberOfTracks) {\n          this.trigger('done');\n          this.emittedTracks = 0;\n        }\n\n        return;\n      }\n    }\n\n    if (this.videoTrack) {\n      timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n      videoProperties.forEach(function (prop) {\n        event.info[prop] = this.videoTrack[prop];\n      }, this);\n    } else if (this.audioTrack) {\n      timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n      audioProperties.forEach(function (prop) {\n        event.info[prop] = this.audioTrack[prop];\n      }, this);\n    }\n\n    if (this.videoTrack || this.audioTrack) {\n      if (this.pendingTracks.length === 1) {\n        event.type = this.pendingTracks[0].type;\n      } else {\n        event.type = 'combined';\n      }\n\n      this.emittedTracks += this.pendingTracks.length;\n      initSegment = mp4Generator.initSegment(this.pendingTracks); // Create a new typed array to hold the init segment\n\n      event.initSegment = new Uint8Array(initSegment.byteLength); // Create an init segment containing a moov\n      // and track definitions\n\n      event.initSegment.set(initSegment); // Create a new typed array to hold the moof+mdats\n\n      event.data = new Uint8Array(this.pendingBytes); // Append each moof+mdat (one per track) together\n\n      for (i = 0; i < this.pendingBoxes.length; i++) {\n        event.data.set(this.pendingBoxes[i], offset);\n        offset += this.pendingBoxes[i].byteLength;\n      } // Translate caption PTS times into second offsets to match the\n      // video timeline for the segment, and add track info\n\n\n      for (i = 0; i < this.pendingCaptions.length; i++) {\n        caption = this.pendingCaptions[i];\n        caption.startTime = clock.metadataTsToSeconds(caption.startPts, timelineStartPts, this.keepOriginalTimestamps);\n        caption.endTime = clock.metadataTsToSeconds(caption.endPts, timelineStartPts, this.keepOriginalTimestamps);\n        event.captionStreams[caption.stream] = true;\n        event.captions.push(caption);\n      } // Translate ID3 frame PTS times into second offsets to match the\n      // video timeline for the segment\n\n\n      for (i = 0; i < this.pendingMetadata.length; i++) {\n        id3 = this.pendingMetadata[i];\n        id3.cueTime = clock.metadataTsToSeconds(id3.pts, timelineStartPts, this.keepOriginalTimestamps);\n        event.metadata.push(id3);\n      } // We add this to every single emitted segment even though we only need\n      // it for the first\n\n\n      event.metadata.dispatchType = this.metadataStream.dispatchType; // Reset stream state\n\n      this.pendingTracks.length = 0;\n      this.videoTrack = null;\n      this.pendingBoxes.length = 0;\n      this.pendingCaptions.length = 0;\n      this.pendingBytes = 0;\n      this.pendingMetadata.length = 0; // Emit the built segment\n      // We include captions and ID3 tags for backwards compatibility,\n      // ideally we should send only video and audio in the data event\n\n      this.trigger('data', event); // Emit each caption to the outside world\n      // Ideally, this would happen immediately on parsing captions,\n      // but we need to ensure that video data is sent back first\n      // so that caption timing can be adjusted to match video timing\n\n      for (i = 0; i < event.captions.length; i++) {\n        caption = event.captions[i];\n        this.trigger('caption', caption);\n      } // Emit each id3 tag to the outside world\n      // Ideally, this would happen immediately on parsing the tag,\n      // but we need to ensure that video data is sent back first\n      // so that ID3 frame timing can be adjusted to match video timing\n\n\n      for (i = 0; i < event.metadata.length; i++) {\n        id3 = event.metadata[i];\n        this.trigger('id3Frame', id3);\n      }\n    } // Only emit `done` if all tracks have been flushed and emitted\n\n\n    if (this.emittedTracks >= this.numberOfTracks) {\n      this.trigger('done');\n      this.emittedTracks = 0;\n    }\n  };\n\n  _CoalesceStream.prototype.setRemux = function (val) {\n    this.remuxTracks = val;\n  };\n  /**\n   * A Stream that expects MP2T binary data as input and produces\n   * corresponding media segments, suitable for use with Media Source\n   * Extension (MSE) implementations that support the ISO BMFF byte\n   * stream format, like Chrome.\n   */\n\n\n  _Transmuxer$1 = function Transmuxer(options) {\n    var self = this,\n        hasFlushed = true,\n        videoTrack,\n        audioTrack;\n\n    _Transmuxer$1.prototype.init.call(this);\n\n    options = options || {};\n    this.baseMediaDecodeTime = options.baseMediaDecodeTime || 0;\n    this.transmuxPipeline_ = {};\n\n    this.setupAacPipeline = function () {\n      var pipeline = {};\n      this.transmuxPipeline_ = pipeline;\n      pipeline.type = 'aac';\n      pipeline.metadataStream = new m2ts_1.MetadataStream(); // set up the parsing pipeline\n\n      pipeline.aacStream = new aac();\n      pipeline.audioTimestampRolloverStream = new m2ts_1.TimestampRolloverStream('audio');\n      pipeline.timedMetadataTimestampRolloverStream = new m2ts_1.TimestampRolloverStream('timed-metadata');\n      pipeline.adtsStream = new adts();\n      pipeline.coalesceStream = new _CoalesceStream(options, pipeline.metadataStream);\n      pipeline.headOfPipeline = pipeline.aacStream;\n      pipeline.aacStream.pipe(pipeline.audioTimestampRolloverStream).pipe(pipeline.adtsStream);\n      pipeline.aacStream.pipe(pipeline.timedMetadataTimestampRolloverStream).pipe(pipeline.metadataStream).pipe(pipeline.coalesceStream);\n      pipeline.metadataStream.on('timestamp', function (frame) {\n        pipeline.aacStream.setTimestamp(frame.timeStamp);\n      });\n      pipeline.aacStream.on('data', function (data) {\n        if (data.type !== 'timed-metadata' && data.type !== 'audio' || pipeline.audioSegmentStream) {\n          return;\n        }\n\n        audioTrack = audioTrack || {\n          timelineStartInfo: {\n            baseMediaDecodeTime: self.baseMediaDecodeTime\n          },\n          codec: 'adts',\n          type: 'audio'\n        }; // hook up the audio segment stream to the first track with aac data\n\n        pipeline.coalesceStream.numberOfTracks++;\n        pipeline.audioSegmentStream = new _AudioSegmentStream$1(audioTrack, options);\n        pipeline.audioSegmentStream.on('log', self.getLogTrigger_('audioSegmentStream'));\n        pipeline.audioSegmentStream.on('timingInfo', self.trigger.bind(self, 'audioTimingInfo')); // Set up the final part of the audio pipeline\n\n        pipeline.adtsStream.pipe(pipeline.audioSegmentStream).pipe(pipeline.coalesceStream); // emit pmt info\n\n        self.trigger('trackinfo', {\n          hasAudio: !!audioTrack,\n          hasVideo: !!videoTrack\n        });\n      }); // Re-emit any data coming from the coalesce stream to the outside world\n\n      pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data')); // Let the consumer know we have finished flushing the entire pipeline\n\n      pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n      addPipelineLogRetriggers(this, pipeline);\n    };\n\n    this.setupTsPipeline = function () {\n      var pipeline = {};\n      this.transmuxPipeline_ = pipeline;\n      pipeline.type = 'ts';\n      pipeline.metadataStream = new m2ts_1.MetadataStream(); // set up the parsing pipeline\n\n      pipeline.packetStream = new m2ts_1.TransportPacketStream();\n      pipeline.parseStream = new m2ts_1.TransportParseStream();\n      pipeline.elementaryStream = new m2ts_1.ElementaryStream();\n      pipeline.timestampRolloverStream = new m2ts_1.TimestampRolloverStream();\n      pipeline.adtsStream = new adts();\n      pipeline.h264Stream = new H264Stream$1();\n      pipeline.captionStream = new m2ts_1.CaptionStream(options);\n      pipeline.coalesceStream = new _CoalesceStream(options, pipeline.metadataStream);\n      pipeline.headOfPipeline = pipeline.packetStream; // disassemble MPEG2-TS packets into elementary streams\n\n      pipeline.packetStream.pipe(pipeline.parseStream).pipe(pipeline.elementaryStream).pipe(pipeline.timestampRolloverStream); // !!THIS ORDER IS IMPORTANT!!\n      // demux the streams\n\n      pipeline.timestampRolloverStream.pipe(pipeline.h264Stream);\n      pipeline.timestampRolloverStream.pipe(pipeline.adtsStream);\n      pipeline.timestampRolloverStream.pipe(pipeline.metadataStream).pipe(pipeline.coalesceStream); // Hook up CEA-608/708 caption stream\n\n      pipeline.h264Stream.pipe(pipeline.captionStream).pipe(pipeline.coalesceStream);\n      pipeline.elementaryStream.on('data', function (data) {\n        var i;\n\n        if (data.type === 'metadata') {\n          i = data.tracks.length; // scan the tracks listed in the metadata\n\n          while (i--) {\n            if (!videoTrack && data.tracks[i].type === 'video') {\n              videoTrack = data.tracks[i];\n              videoTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n            } else if (!audioTrack && data.tracks[i].type === 'audio') {\n              audioTrack = data.tracks[i];\n              audioTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n            }\n          } // hook up the video segment stream to the first track with h264 data\n\n\n          if (videoTrack && !pipeline.videoSegmentStream) {\n            pipeline.coalesceStream.numberOfTracks++;\n            pipeline.videoSegmentStream = new _VideoSegmentStream$1(videoTrack, options);\n            pipeline.videoSegmentStream.on('log', self.getLogTrigger_('videoSegmentStream'));\n            pipeline.videoSegmentStream.on('timelineStartInfo', function (timelineStartInfo) {\n              // When video emits timelineStartInfo data after a flush, we forward that\n              // info to the AudioSegmentStream, if it exists, because video timeline\n              // data takes precedence.  Do not do this if keepOriginalTimestamps is set,\n              // because this is a particularly subtle form of timestamp alteration.\n              if (audioTrack && !options.keepOriginalTimestamps) {\n                audioTrack.timelineStartInfo = timelineStartInfo; // On the first segment we trim AAC frames that exist before the\n                // very earliest DTS we have seen in video because Chrome will\n                // interpret any video track with a baseMediaDecodeTime that is\n                // non-zero as a gap.\n\n                pipeline.audioSegmentStream.setEarliestDts(timelineStartInfo.dts - self.baseMediaDecodeTime);\n              }\n            });\n            pipeline.videoSegmentStream.on('processedGopsInfo', self.trigger.bind(self, 'gopInfo'));\n            pipeline.videoSegmentStream.on('segmentTimingInfo', self.trigger.bind(self, 'videoSegmentTimingInfo'));\n            pipeline.videoSegmentStream.on('baseMediaDecodeTime', function (baseMediaDecodeTime) {\n              if (audioTrack) {\n                pipeline.audioSegmentStream.setVideoBaseMediaDecodeTime(baseMediaDecodeTime);\n              }\n            });\n            pipeline.videoSegmentStream.on('timingInfo', self.trigger.bind(self, 'videoTimingInfo')); // Set up the final part of the video pipeline\n\n            pipeline.h264Stream.pipe(pipeline.videoSegmentStream).pipe(pipeline.coalesceStream);\n          }\n\n          if (audioTrack && !pipeline.audioSegmentStream) {\n            // hook up the audio segment stream to the first track with aac data\n            pipeline.coalesceStream.numberOfTracks++;\n            pipeline.audioSegmentStream = new _AudioSegmentStream$1(audioTrack, options);\n            pipeline.audioSegmentStream.on('log', self.getLogTrigger_('audioSegmentStream'));\n            pipeline.audioSegmentStream.on('timingInfo', self.trigger.bind(self, 'audioTimingInfo'));\n            pipeline.audioSegmentStream.on('segmentTimingInfo', self.trigger.bind(self, 'audioSegmentTimingInfo')); // Set up the final part of the audio pipeline\n\n            pipeline.adtsStream.pipe(pipeline.audioSegmentStream).pipe(pipeline.coalesceStream);\n          } // emit pmt info\n\n\n          self.trigger('trackinfo', {\n            hasAudio: !!audioTrack,\n            hasVideo: !!videoTrack\n          });\n        }\n      }); // Re-emit any data coming from the coalesce stream to the outside world\n\n      pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data'));\n      pipeline.coalesceStream.on('id3Frame', function (id3Frame) {\n        id3Frame.dispatchType = pipeline.metadataStream.dispatchType;\n        self.trigger('id3Frame', id3Frame);\n      });\n      pipeline.coalesceStream.on('caption', this.trigger.bind(this, 'caption')); // Let the consumer know we have finished flushing the entire pipeline\n\n      pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n      addPipelineLogRetriggers(this, pipeline);\n    }; // hook up the segment streams once track metadata is delivered\n\n\n    this.setBaseMediaDecodeTime = function (baseMediaDecodeTime) {\n      var pipeline = this.transmuxPipeline_;\n\n      if (!options.keepOriginalTimestamps) {\n        this.baseMediaDecodeTime = baseMediaDecodeTime;\n      }\n\n      if (audioTrack) {\n        audioTrack.timelineStartInfo.dts = undefined;\n        audioTrack.timelineStartInfo.pts = undefined;\n        trackDecodeInfo.clearDtsInfo(audioTrack);\n\n        if (pipeline.audioTimestampRolloverStream) {\n          pipeline.audioTimestampRolloverStream.discontinuity();\n        }\n      }\n\n      if (videoTrack) {\n        if (pipeline.videoSegmentStream) {\n          pipeline.videoSegmentStream.gopCache_ = [];\n        }\n\n        videoTrack.timelineStartInfo.dts = undefined;\n        videoTrack.timelineStartInfo.pts = undefined;\n        trackDecodeInfo.clearDtsInfo(videoTrack);\n        pipeline.captionStream.reset();\n      }\n\n      if (pipeline.timestampRolloverStream) {\n        pipeline.timestampRolloverStream.discontinuity();\n      }\n    };\n\n    this.setAudioAppendStart = function (timestamp) {\n      if (audioTrack) {\n        this.transmuxPipeline_.audioSegmentStream.setAudioAppendStart(timestamp);\n      }\n    };\n\n    this.setRemux = function (val) {\n      var pipeline = this.transmuxPipeline_;\n      options.remux = val;\n\n      if (pipeline && pipeline.coalesceStream) {\n        pipeline.coalesceStream.setRemux(val);\n      }\n    };\n\n    this.alignGopsWith = function (gopsToAlignWith) {\n      if (videoTrack && this.transmuxPipeline_.videoSegmentStream) {\n        this.transmuxPipeline_.videoSegmentStream.alignGopsWith(gopsToAlignWith);\n      }\n    };\n\n    this.getLogTrigger_ = function (key) {\n      var self = this;\n      return function (event) {\n        event.stream = key;\n        self.trigger('log', event);\n      };\n    }; // feed incoming data to the front of the parsing pipeline\n\n\n    this.push = function (data) {\n      if (hasFlushed) {\n        var isAac = isLikelyAacData$1(data);\n\n        if (isAac && this.transmuxPipeline_.type !== 'aac') {\n          this.setupAacPipeline();\n        } else if (!isAac && this.transmuxPipeline_.type !== 'ts') {\n          this.setupTsPipeline();\n        }\n\n        hasFlushed = false;\n      }\n\n      this.transmuxPipeline_.headOfPipeline.push(data);\n    }; // flush any buffered data\n\n\n    this.flush = function () {\n      hasFlushed = true; // Start at the top of the pipeline and flush all pending work\n\n      this.transmuxPipeline_.headOfPipeline.flush();\n    };\n\n    this.endTimeline = function () {\n      this.transmuxPipeline_.headOfPipeline.endTimeline();\n    };\n\n    this.reset = function () {\n      if (this.transmuxPipeline_.headOfPipeline) {\n        this.transmuxPipeline_.headOfPipeline.reset();\n      }\n    }; // Caption data has to be reset when seeking outside buffered range\n\n\n    this.resetCaptions = function () {\n      if (this.transmuxPipeline_.captionStream) {\n        this.transmuxPipeline_.captionStream.reset();\n      }\n    };\n  };\n\n  _Transmuxer$1.prototype = new stream();\n  var transmuxer$2 = {\n    Transmuxer: _Transmuxer$1,\n    VideoSegmentStream: _VideoSegmentStream$1,\n    AudioSegmentStream: _AudioSegmentStream$1,\n    AUDIO_PROPERTIES: audioProperties,\n    VIDEO_PROPERTIES: videoProperties,\n    // exported for testing\n    generateSegmentTimingInfo: generateSegmentTimingInfo\n  };\n\n  var discardEmulationPreventionBytes = captionPacketParser.discardEmulationPreventionBytes;\n  var CaptionStream = captionStream.CaptionStream;\n  /**\n    * Maps an offset in the mdat to a sample based on the the size of the samples.\n    * Assumes that `parseSamples` has been called first.\n    *\n    * @param {Number} offset - The offset into the mdat\n    * @param {Object[]} samples - An array of samples, parsed using `parseSamples`\n    * @return {?Object} The matching sample, or null if no match was found.\n    *\n    * @see ISO-BMFF-12/2015, Section 8.8.8\n   **/\n\n  var mapToSample = function mapToSample(offset, samples) {\n    var approximateOffset = offset;\n\n    for (var i = 0; i < samples.length; i++) {\n      var sample = samples[i];\n\n      if (approximateOffset < sample.size) {\n        return sample;\n      }\n\n      approximateOffset -= sample.size;\n    }\n\n    return null;\n  };\n  /**\n    * Finds SEI nal units contained in a Media Data Box.\n    * Assumes that `parseSamples` has been called first.\n    *\n    * @param {Uint8Array} avcStream - The bytes of the mdat\n    * @param {Object[]} samples - The samples parsed out by `parseSamples`\n    * @param {Number} trackId - The trackId of this video track\n    * @return {Object[]} seiNals - the parsed SEI NALUs found.\n    *   The contents of the seiNal should match what is expected by\n    *   CaptionStream.push (nalUnitType, size, data, escapedRBSP, pts, dts)\n    *\n    * @see ISO-BMFF-12/2015, Section 8.1.1\n    * @see Rec. ITU-T H.264, 7.3.2.3.1\n   **/\n\n\n  var findSeiNals = function findSeiNals(avcStream, samples, trackId) {\n    var avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n        result = {\n      logs: [],\n      seiNals: []\n    },\n        seiNal,\n        i,\n        length,\n        lastMatchedSample;\n\n    for (i = 0; i + 4 < avcStream.length; i += length) {\n      length = avcView.getUint32(i);\n      i += 4; // Bail if this doesn't appear to be an H264 stream\n\n      if (length <= 0) {\n        continue;\n      }\n\n      switch (avcStream[i] & 0x1F) {\n        case 0x06:\n          var data = avcStream.subarray(i + 1, i + 1 + length);\n          var matchingSample = mapToSample(i, samples);\n          seiNal = {\n            nalUnitType: 'sei_rbsp',\n            size: length,\n            data: data,\n            escapedRBSP: discardEmulationPreventionBytes(data),\n            trackId: trackId\n          };\n\n          if (matchingSample) {\n            seiNal.pts = matchingSample.pts;\n            seiNal.dts = matchingSample.dts;\n            lastMatchedSample = matchingSample;\n          } else if (lastMatchedSample) {\n            // If a matching sample cannot be found, use the last\n            // sample's values as they should be as close as possible\n            seiNal.pts = lastMatchedSample.pts;\n            seiNal.dts = lastMatchedSample.dts;\n          } else {\n            result.logs.push({\n              level: 'warn',\n              message: 'We\\'ve encountered a nal unit without data at ' + i + ' for trackId ' + trackId + '. See mux.js#223.'\n            });\n            break;\n          }\n\n          result.seiNals.push(seiNal);\n          break;\n      }\n    }\n\n    return result;\n  };\n  /**\n    * Parses sample information out of Track Run Boxes and calculates\n    * the absolute presentation and decode timestamps of each sample.\n    *\n    * @param {Array<Uint8Array>} truns - The Trun Run boxes to be parsed\n    * @param {Number|BigInt} baseMediaDecodeTime - base media decode time from tfdt\n        @see ISO-BMFF-12/2015, Section 8.8.12\n    * @param {Object} tfhd - The parsed Track Fragment Header\n    *   @see inspect.parseTfhd\n    * @return {Object[]} the parsed samples\n    *\n    * @see ISO-BMFF-12/2015, Section 8.8.8\n   **/\n\n\n  var parseSamples = function parseSamples(truns, baseMediaDecodeTime, tfhd) {\n    var currentDts = baseMediaDecodeTime;\n    var defaultSampleDuration = tfhd.defaultSampleDuration || 0;\n    var defaultSampleSize = tfhd.defaultSampleSize || 0;\n    var trackId = tfhd.trackId;\n    var allSamples = [];\n    truns.forEach(function (trun) {\n      // Note: We currently do not parse the sample table as well\n      // as the trun. It's possible some sources will require this.\n      // moov > trak > mdia > minf > stbl\n      var trackRun = parseTrun(trun);\n      var samples = trackRun.samples;\n      samples.forEach(function (sample) {\n        if (sample.duration === undefined) {\n          sample.duration = defaultSampleDuration;\n        }\n\n        if (sample.size === undefined) {\n          sample.size = defaultSampleSize;\n        }\n\n        sample.trackId = trackId;\n        sample.dts = currentDts;\n\n        if (sample.compositionTimeOffset === undefined) {\n          sample.compositionTimeOffset = 0;\n        }\n\n        if (typeof currentDts === 'bigint') {\n          sample.pts = currentDts + window__default['default'].BigInt(sample.compositionTimeOffset);\n          currentDts += window__default['default'].BigInt(sample.duration);\n        } else {\n          sample.pts = currentDts + sample.compositionTimeOffset;\n          currentDts += sample.duration;\n        }\n      });\n      allSamples = allSamples.concat(samples);\n    });\n    return allSamples;\n  };\n  /**\n    * Parses out caption nals from an FMP4 segment's video tracks.\n    *\n    * @param {Uint8Array} segment - The bytes of a single segment\n    * @param {Number} videoTrackId - The trackId of a video track in the segment\n    * @return {Object.<Number, Object[]>} A mapping of video trackId to\n    *   a list of seiNals found in that track\n   **/\n\n\n  var parseCaptionNals = function parseCaptionNals(segment, videoTrackId) {\n    // To get the samples\n    var trafs = findBox_1(segment, ['moof', 'traf']); // To get SEI NAL units\n\n    var mdats = findBox_1(segment, ['mdat']);\n    var captionNals = {};\n    var mdatTrafPairs = []; // Pair up each traf with a mdat as moofs and mdats are in pairs\n\n    mdats.forEach(function (mdat, index) {\n      var matchingTraf = trafs[index];\n      mdatTrafPairs.push({\n        mdat: mdat,\n        traf: matchingTraf\n      });\n    });\n    mdatTrafPairs.forEach(function (pair) {\n      var mdat = pair.mdat;\n      var traf = pair.traf;\n      var tfhd = findBox_1(traf, ['tfhd']); // Exactly 1 tfhd per traf\n\n      var headerInfo = parseTfhd(tfhd[0]);\n      var trackId = headerInfo.trackId;\n      var tfdt = findBox_1(traf, ['tfdt']); // Either 0 or 1 tfdt per traf\n\n      var baseMediaDecodeTime = tfdt.length > 0 ? parseTfdt(tfdt[0]).baseMediaDecodeTime : 0;\n      var truns = findBox_1(traf, ['trun']);\n      var samples;\n      var result; // Only parse video data for the chosen video track\n\n      if (videoTrackId === trackId && truns.length > 0) {\n        samples = parseSamples(truns, baseMediaDecodeTime, headerInfo);\n        result = findSeiNals(mdat, samples, trackId);\n\n        if (!captionNals[trackId]) {\n          captionNals[trackId] = {\n            seiNals: [],\n            logs: []\n          };\n        }\n\n        captionNals[trackId].seiNals = captionNals[trackId].seiNals.concat(result.seiNals);\n        captionNals[trackId].logs = captionNals[trackId].logs.concat(result.logs);\n      }\n    });\n    return captionNals;\n  };\n  /**\n    * Parses out inband captions from an MP4 container and returns\n    * caption objects that can be used by WebVTT and the TextTrack API.\n    * @see https://developer.mozilla.org/en-US/docs/Web/API/VTTCue\n    * @see https://developer.mozilla.org/en-US/docs/Web/API/TextTrack\n    * Assumes that `probe.getVideoTrackIds` and `probe.timescale` have been called first\n    *\n    * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n    * @param {Number} trackId - The id of the video track to parse\n    * @param {Number} timescale - The timescale for the video track from the init segment\n    *\n    * @return {?Object[]} parsedCaptions - A list of captions or null if no video tracks\n    * @return {Number} parsedCaptions[].startTime - The time to show the caption in seconds\n    * @return {Number} parsedCaptions[].endTime - The time to stop showing the caption in seconds\n    * @return {String} parsedCaptions[].text - The visible content of the caption\n   **/\n\n\n  var parseEmbeddedCaptions = function parseEmbeddedCaptions(segment, trackId, timescale) {\n    var captionNals; // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n\n    if (trackId === null) {\n      return null;\n    }\n\n    captionNals = parseCaptionNals(segment, trackId);\n    var trackNals = captionNals[trackId] || {};\n    return {\n      seiNals: trackNals.seiNals,\n      logs: trackNals.logs,\n      timescale: timescale\n    };\n  };\n  /**\n    * Converts SEI NALUs into captions that can be used by video.js\n   **/\n\n\n  var CaptionParser = function CaptionParser() {\n    var isInitialized = false;\n    var captionStream; // Stores segments seen before trackId and timescale are set\n\n    var segmentCache; // Stores video track ID of the track being parsed\n\n    var trackId; // Stores the timescale of the track being parsed\n\n    var timescale; // Stores captions parsed so far\n\n    var parsedCaptions; // Stores whether we are receiving partial data or not\n\n    var parsingPartial;\n    /**\n      * A method to indicate whether a CaptionParser has been initalized\n      * @returns {Boolean}\n     **/\n\n    this.isInitialized = function () {\n      return isInitialized;\n    };\n    /**\n      * Initializes the underlying CaptionStream, SEI NAL parsing\n      * and management, and caption collection\n     **/\n\n\n    this.init = function (options) {\n      captionStream = new CaptionStream();\n      isInitialized = true;\n      parsingPartial = options ? options.isPartial : false; // Collect dispatched captions\n\n      captionStream.on('data', function (event) {\n        // Convert to seconds in the source's timescale\n        event.startTime = event.startPts / timescale;\n        event.endTime = event.endPts / timescale;\n        parsedCaptions.captions.push(event);\n        parsedCaptions.captionStreams[event.stream] = true;\n      });\n      captionStream.on('log', function (log) {\n        parsedCaptions.logs.push(log);\n      });\n    };\n    /**\n      * Determines if a new video track will be selected\n      * or if the timescale changed\n      * @return {Boolean}\n     **/\n\n\n    this.isNewInit = function (videoTrackIds, timescales) {\n      if (videoTrackIds && videoTrackIds.length === 0 || timescales && typeof timescales === 'object' && Object.keys(timescales).length === 0) {\n        return false;\n      }\n\n      return trackId !== videoTrackIds[0] || timescale !== timescales[trackId];\n    };\n    /**\n      * Parses out SEI captions and interacts with underlying\n      * CaptionStream to return dispatched captions\n      *\n      * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n      * @param {Number[]} videoTrackIds - A list of video tracks found in the init segment\n      * @param {Object.<Number, Number>} timescales - The timescales found in the init segment\n      * @see parseEmbeddedCaptions\n      * @see m2ts/caption-stream.js\n     **/\n\n\n    this.parse = function (segment, videoTrackIds, timescales) {\n      var parsedData;\n\n      if (!this.isInitialized()) {\n        return null; // This is not likely to be a video segment\n      } else if (!videoTrackIds || !timescales) {\n        return null;\n      } else if (this.isNewInit(videoTrackIds, timescales)) {\n        // Use the first video track only as there is no\n        // mechanism to switch to other video tracks\n        trackId = videoTrackIds[0];\n        timescale = timescales[trackId]; // If an init segment has not been seen yet, hold onto segment\n        // data until we have one.\n        // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n      } else if (trackId === null || !timescale) {\n        segmentCache.push(segment);\n        return null;\n      } // Now that a timescale and trackId is set, parse cached segments\n\n\n      while (segmentCache.length > 0) {\n        var cachedSegment = segmentCache.shift();\n        this.parse(cachedSegment, videoTrackIds, timescales);\n      }\n\n      parsedData = parseEmbeddedCaptions(segment, trackId, timescale);\n\n      if (parsedData && parsedData.logs) {\n        parsedCaptions.logs = parsedCaptions.logs.concat(parsedData.logs);\n      }\n\n      if (parsedData === null || !parsedData.seiNals) {\n        if (parsedCaptions.logs.length) {\n          return {\n            logs: parsedCaptions.logs,\n            captions: [],\n            captionStreams: []\n          };\n        }\n\n        return null;\n      }\n\n      this.pushNals(parsedData.seiNals); // Force the parsed captions to be dispatched\n\n      this.flushStream();\n      return parsedCaptions;\n    };\n    /**\n      * Pushes SEI NALUs onto CaptionStream\n      * @param {Object[]} nals - A list of SEI nals parsed using `parseCaptionNals`\n      * Assumes that `parseCaptionNals` has been called first\n      * @see m2ts/caption-stream.js\n      **/\n\n\n    this.pushNals = function (nals) {\n      if (!this.isInitialized() || !nals || nals.length === 0) {\n        return null;\n      }\n\n      nals.forEach(function (nal) {\n        captionStream.push(nal);\n      });\n    };\n    /**\n      * Flushes underlying CaptionStream to dispatch processed, displayable captions\n      * @see m2ts/caption-stream.js\n     **/\n\n\n    this.flushStream = function () {\n      if (!this.isInitialized()) {\n        return null;\n      }\n\n      if (!parsingPartial) {\n        captionStream.flush();\n      } else {\n        captionStream.partialFlush();\n      }\n    };\n    /**\n      * Reset caption buckets for new data\n     **/\n\n\n    this.clearParsedCaptions = function () {\n      parsedCaptions.captions = [];\n      parsedCaptions.captionStreams = {};\n      parsedCaptions.logs = [];\n    };\n    /**\n      * Resets underlying CaptionStream\n      * @see m2ts/caption-stream.js\n     **/\n\n\n    this.resetCaptionStream = function () {\n      if (!this.isInitialized()) {\n        return null;\n      }\n\n      captionStream.reset();\n    };\n    /**\n      * Convenience method to clear all captions flushed from the\n      * CaptionStream and still being parsed\n      * @see m2ts/caption-stream.js\n     **/\n\n\n    this.clearAllCaptions = function () {\n      this.clearParsedCaptions();\n      this.resetCaptionStream();\n    };\n    /**\n      * Reset caption parser\n     **/\n\n\n    this.reset = function () {\n      segmentCache = [];\n      trackId = null;\n      timescale = null;\n\n      if (!parsedCaptions) {\n        parsedCaptions = {\n          captions: [],\n          // CC1, CC2, CC3, CC4\n          captionStreams: {},\n          logs: []\n        };\n      } else {\n        this.clearParsedCaptions();\n      }\n\n      this.resetCaptionStream();\n    };\n\n    this.reset();\n  };\n\n  var captionParser = CaptionParser;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var mp4 = {\n    generator: mp4Generator,\n    probe: probe$2,\n    Transmuxer: transmuxer$2.Transmuxer,\n    AudioSegmentStream: transmuxer$2.AudioSegmentStream,\n    VideoSegmentStream: transmuxer$2.VideoSegmentStream,\n    CaptionParser: captionParser\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   *\n   * An object that stores the bytes of an FLV tag and methods for\n   * querying and manipulating that data.\n   * @see http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf\n   */\n\n  var _FlvTag; // (type:uint, extraData:Boolean = false) extends ByteArray\n\n\n  _FlvTag = function FlvTag(type, extraData) {\n    var // Counter if this is a metadata tag, nal start marker if this is a video\n    // tag. unused if this is an audio tag\n    adHoc = 0,\n        // :uint\n    // The default size is 16kb but this is not enough to hold iframe\n    // data and the resizing algorithm costs a bit so we create a larger\n    // starting buffer for video tags\n    bufferStartSize = 16384,\n        // checks whether the FLV tag has enough capacity to accept the proposed\n    // write and re-allocates the internal buffers if necessary\n    prepareWrite = function prepareWrite(flv, count) {\n      var bytes,\n          minLength = flv.position + count;\n\n      if (minLength < flv.bytes.byteLength) {\n        // there's enough capacity so do nothing\n        return;\n      } // allocate a new buffer and copy over the data that will not be modified\n\n\n      bytes = new Uint8Array(minLength * 2);\n      bytes.set(flv.bytes.subarray(0, flv.position), 0);\n      flv.bytes = bytes;\n      flv.view = new DataView(flv.bytes.buffer);\n    },\n        // commonly used metadata properties\n    widthBytes = _FlvTag.widthBytes || new Uint8Array('width'.length),\n        heightBytes = _FlvTag.heightBytes || new Uint8Array('height'.length),\n        videocodecidBytes = _FlvTag.videocodecidBytes || new Uint8Array('videocodecid'.length),\n        i;\n\n    if (!_FlvTag.widthBytes) {\n      // calculating the bytes of common metadata names ahead of time makes the\n      // corresponding writes faster because we don't have to loop over the\n      // characters\n      // re-test with test/perf.html if you're planning on changing this\n      for (i = 0; i < 'width'.length; i++) {\n        widthBytes[i] = 'width'.charCodeAt(i);\n      }\n\n      for (i = 0; i < 'height'.length; i++) {\n        heightBytes[i] = 'height'.charCodeAt(i);\n      }\n\n      for (i = 0; i < 'videocodecid'.length; i++) {\n        videocodecidBytes[i] = 'videocodecid'.charCodeAt(i);\n      }\n\n      _FlvTag.widthBytes = widthBytes;\n      _FlvTag.heightBytes = heightBytes;\n      _FlvTag.videocodecidBytes = videocodecidBytes;\n    }\n\n    this.keyFrame = false; // :Boolean\n\n    switch (type) {\n      case _FlvTag.VIDEO_TAG:\n        this.length = 16; // Start the buffer at 256k\n\n        bufferStartSize *= 6;\n        break;\n\n      case _FlvTag.AUDIO_TAG:\n        this.length = 13;\n        this.keyFrame = true;\n        break;\n\n      case _FlvTag.METADATA_TAG:\n        this.length = 29;\n        this.keyFrame = true;\n        break;\n\n      default:\n        throw new Error('Unknown FLV tag type');\n    }\n\n    this.bytes = new Uint8Array(bufferStartSize);\n    this.view = new DataView(this.bytes.buffer);\n    this.bytes[0] = type;\n    this.position = this.length;\n    this.keyFrame = extraData; // Defaults to false\n    // presentation timestamp\n\n    this.pts = 0; // decoder timestamp\n\n    this.dts = 0; // ByteArray#writeBytes(bytes:ByteArray, offset:uint = 0, length:uint = 0)\n\n    this.writeBytes = function (bytes, offset, length) {\n      var start = offset || 0,\n          end;\n      length = length || bytes.byteLength;\n      end = start + length;\n      prepareWrite(this, length);\n      this.bytes.set(bytes.subarray(start, end), this.position);\n      this.position += length;\n      this.length = Math.max(this.length, this.position);\n    }; // ByteArray#writeByte(value:int):void\n\n\n    this.writeByte = function (byte) {\n      prepareWrite(this, 1);\n      this.bytes[this.position] = byte;\n      this.position++;\n      this.length = Math.max(this.length, this.position);\n    }; // ByteArray#writeShort(value:int):void\n\n\n    this.writeShort = function (short) {\n      prepareWrite(this, 2);\n      this.view.setUint16(this.position, short);\n      this.position += 2;\n      this.length = Math.max(this.length, this.position);\n    }; // Negative index into array\n    // (pos:uint):int\n\n\n    this.negIndex = function (pos) {\n      return this.bytes[this.length - pos];\n    }; // The functions below ONLY work when this[0] == VIDEO_TAG.\n    // We are not going to check for that because we dont want the overhead\n    // (nal:ByteArray = null):int\n\n\n    this.nalUnitSize = function () {\n      if (adHoc === 0) {\n        return 0;\n      }\n\n      return this.length - (adHoc + 4);\n    };\n\n    this.startNalUnit = function () {\n      // remember position and add 4 bytes\n      if (adHoc > 0) {\n        throw new Error('Attempted to create new NAL wihout closing the old one');\n      } // reserve 4 bytes for nal unit size\n\n\n      adHoc = this.length;\n      this.length += 4;\n      this.position = this.length;\n    }; // (nal:ByteArray = null):void\n\n\n    this.endNalUnit = function (nalContainer) {\n      var nalStart, // :uint\n      nalLength; // :uint\n      // Rewind to the marker and write the size\n\n      if (this.length === adHoc + 4) {\n        // we started a nal unit, but didnt write one, so roll back the 4 byte size value\n        this.length -= 4;\n      } else if (adHoc > 0) {\n        nalStart = adHoc + 4;\n        nalLength = this.length - nalStart;\n        this.position = adHoc;\n        this.view.setUint32(this.position, nalLength);\n        this.position = this.length;\n\n        if (nalContainer) {\n          // Add the tag to the NAL unit\n          nalContainer.push(this.bytes.subarray(nalStart, nalStart + nalLength));\n        }\n      }\n\n      adHoc = 0;\n    };\n    /**\n     * Write out a 64-bit floating point valued metadata property. This method is\n     * called frequently during a typical parse and needs to be fast.\n     */\n    // (key:String, val:Number):void\n\n\n    this.writeMetaDataDouble = function (key, val) {\n      var i;\n      prepareWrite(this, 2 + key.length + 9); // write size of property name\n\n      this.view.setUint16(this.position, key.length);\n      this.position += 2; // this next part looks terrible but it improves parser throughput by\n      // 10kB/s in my testing\n      // write property name\n\n      if (key === 'width') {\n        this.bytes.set(widthBytes, this.position);\n        this.position += 5;\n      } else if (key === 'height') {\n        this.bytes.set(heightBytes, this.position);\n        this.position += 6;\n      } else if (key === 'videocodecid') {\n        this.bytes.set(videocodecidBytes, this.position);\n        this.position += 12;\n      } else {\n        for (i = 0; i < key.length; i++) {\n          this.bytes[this.position] = key.charCodeAt(i);\n          this.position++;\n        }\n      } // skip null byte\n\n\n      this.position++; // write property value\n\n      this.view.setFloat64(this.position, val);\n      this.position += 8; // update flv tag length\n\n      this.length = Math.max(this.length, this.position);\n      ++adHoc;\n    }; // (key:String, val:Boolean):void\n\n\n    this.writeMetaDataBoolean = function (key, val) {\n      var i;\n      prepareWrite(this, 2);\n      this.view.setUint16(this.position, key.length);\n      this.position += 2;\n\n      for (i = 0; i < key.length; i++) {\n        // if key.charCodeAt(i) >= 255, handle error\n        prepareWrite(this, 1);\n        this.bytes[this.position] = key.charCodeAt(i);\n        this.position++;\n      }\n\n      prepareWrite(this, 2);\n      this.view.setUint8(this.position, 0x01);\n      this.position++;\n      this.view.setUint8(this.position, val ? 0x01 : 0x00);\n      this.position++;\n      this.length = Math.max(this.length, this.position);\n      ++adHoc;\n    }; // ():ByteArray\n\n\n    this.finalize = function () {\n      var dtsDelta, // :int\n      len; // :int\n\n      switch (this.bytes[0]) {\n        // Video Data\n        case _FlvTag.VIDEO_TAG:\n          // We only support AVC, 1 = key frame (for AVC, a seekable\n          // frame), 2 = inter frame (for AVC, a non-seekable frame)\n          this.bytes[11] = (this.keyFrame || extraData ? 0x10 : 0x20) | 0x07;\n          this.bytes[12] = extraData ? 0x00 : 0x01;\n          dtsDelta = this.pts - this.dts;\n          this.bytes[13] = (dtsDelta & 0x00FF0000) >>> 16;\n          this.bytes[14] = (dtsDelta & 0x0000FF00) >>> 8;\n          this.bytes[15] = (dtsDelta & 0x000000FF) >>> 0;\n          break;\n\n        case _FlvTag.AUDIO_TAG:\n          this.bytes[11] = 0xAF; // 44 kHz, 16-bit stereo\n\n          this.bytes[12] = extraData ? 0x00 : 0x01;\n          break;\n\n        case _FlvTag.METADATA_TAG:\n          this.position = 11;\n          this.view.setUint8(this.position, 0x02); // String type\n\n          this.position++;\n          this.view.setUint16(this.position, 0x0A); // 10 Bytes\n\n          this.position += 2; // set \"onMetaData\"\n\n          this.bytes.set([0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x61, 0x44, 0x61, 0x74, 0x61], this.position);\n          this.position += 10;\n          this.bytes[this.position] = 0x08; // Array type\n\n          this.position++;\n          this.view.setUint32(this.position, adHoc);\n          this.position = this.length;\n          this.bytes.set([0, 0, 9], this.position);\n          this.position += 3; // End Data Tag\n\n          this.length = this.position;\n          break;\n      }\n\n      len = this.length - 11; // write the DataSize field\n\n      this.bytes[1] = (len & 0x00FF0000) >>> 16;\n      this.bytes[2] = (len & 0x0000FF00) >>> 8;\n      this.bytes[3] = (len & 0x000000FF) >>> 0; // write the Timestamp\n\n      this.bytes[4] = (this.dts & 0x00FF0000) >>> 16;\n      this.bytes[5] = (this.dts & 0x0000FF00) >>> 8;\n      this.bytes[6] = (this.dts & 0x000000FF) >>> 0;\n      this.bytes[7] = (this.dts & 0xFF000000) >>> 24; // write the StreamID\n\n      this.bytes[8] = 0;\n      this.bytes[9] = 0;\n      this.bytes[10] = 0; // Sometimes we're at the end of the view and have one slot to write a\n      // uint32, so, prepareWrite of count 4, since, view is uint8\n\n      prepareWrite(this, 4);\n      this.view.setUint32(this.length, this.length);\n      this.length += 4;\n      this.position += 4; // trim down the byte buffer to what is actually being used\n\n      this.bytes = this.bytes.subarray(0, this.length);\n      this.frameTime = _FlvTag.frameTime(this.bytes); // if bytes.bytelength isn't equal to this.length, handle error\n\n      return this;\n    };\n  };\n\n  _FlvTag.AUDIO_TAG = 0x08; // == 8, :uint\n\n  _FlvTag.VIDEO_TAG = 0x09; // == 9, :uint\n\n  _FlvTag.METADATA_TAG = 0x12; // == 18, :uint\n  // (tag:ByteArray):Boolean {\n\n  _FlvTag.isAudioFrame = function (tag) {\n    return _FlvTag.AUDIO_TAG === tag[0];\n  }; // (tag:ByteArray):Boolean {\n\n\n  _FlvTag.isVideoFrame = function (tag) {\n    return _FlvTag.VIDEO_TAG === tag[0];\n  }; // (tag:ByteArray):Boolean {\n\n\n  _FlvTag.isMetaData = function (tag) {\n    return _FlvTag.METADATA_TAG === tag[0];\n  }; // (tag:ByteArray):Boolean {\n\n\n  _FlvTag.isKeyFrame = function (tag) {\n    if (_FlvTag.isVideoFrame(tag)) {\n      return tag[11] === 0x17;\n    }\n\n    if (_FlvTag.isAudioFrame(tag)) {\n      return true;\n    }\n\n    if (_FlvTag.isMetaData(tag)) {\n      return true;\n    }\n\n    return false;\n  }; // (tag:ByteArray):uint {\n\n\n  _FlvTag.frameTime = function (tag) {\n    var pts = tag[4] << 16; // :uint\n\n    pts |= tag[5] << 8;\n    pts |= tag[6] << 0;\n    pts |= tag[7] << 24;\n    return pts;\n  };\n\n  var flvTag = _FlvTag;\n\n  /**\n   * The final stage of the transmuxer that emits the flv tags\n   * for audio, video, and metadata. Also tranlates in time and\n   * outputs caption data and id3 cues.\n   */\n\n\n  var CoalesceStream = function CoalesceStream(options) {\n    // Number of Tracks per output segment\n    // If greater than 1, we combine multiple\n    // tracks into a single segment\n    this.numberOfTracks = 0;\n    this.metadataStream = options.metadataStream;\n    this.videoTags = [];\n    this.audioTags = [];\n    this.videoTrack = null;\n    this.audioTrack = null;\n    this.pendingCaptions = [];\n    this.pendingMetadata = [];\n    this.pendingTracks = 0;\n    this.processedTracks = 0;\n    CoalesceStream.prototype.init.call(this); // Take output from multiple\n\n    this.push = function (output) {\n      // buffer incoming captions until the associated video segment\n      // finishes\n      if (output.text) {\n        return this.pendingCaptions.push(output);\n      } // buffer incoming id3 tags until the final flush\n\n\n      if (output.frames) {\n        return this.pendingMetadata.push(output);\n      }\n\n      if (output.track.type === 'video') {\n        this.videoTrack = output.track;\n        this.videoTags = output.tags;\n        this.pendingTracks++;\n      }\n\n      if (output.track.type === 'audio') {\n        this.audioTrack = output.track;\n        this.audioTags = output.tags;\n        this.pendingTracks++;\n      }\n    };\n  };\n\n  CoalesceStream.prototype = new stream();\n\n  CoalesceStream.prototype.flush = function (flushSource) {\n    var id3,\n        caption,\n        i,\n        timelineStartPts,\n        event = {\n      tags: {},\n      captions: [],\n      captionStreams: {},\n      metadata: []\n    };\n\n    if (this.pendingTracks < this.numberOfTracks) {\n      if (flushSource !== 'VideoSegmentStream' && flushSource !== 'AudioSegmentStream') {\n        // Return because we haven't received a flush from a data-generating\n        // portion of the segment (meaning that we have only recieved meta-data\n        // or captions.)\n        return;\n      } else if (this.pendingTracks === 0) {\n        // In the case where we receive a flush without any data having been\n        // received we consider it an emitted track for the purposes of coalescing\n        // `done` events.\n        // We do this for the case where there is an audio and video track in the\n        // segment but no audio data. (seen in several playlists with alternate\n        // audio tracks and no audio present in the main TS segments.)\n        this.processedTracks++;\n\n        if (this.processedTracks < this.numberOfTracks) {\n          return;\n        }\n      }\n    }\n\n    this.processedTracks += this.pendingTracks;\n    this.pendingTracks = 0;\n\n    if (this.processedTracks < this.numberOfTracks) {\n      return;\n    }\n\n    if (this.videoTrack) {\n      timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n    } else if (this.audioTrack) {\n      timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n    }\n\n    event.tags.videoTags = this.videoTags;\n    event.tags.audioTags = this.audioTags; // Translate caption PTS times into second offsets into the\n    // video timeline for the segment, and add track info\n\n    for (i = 0; i < this.pendingCaptions.length; i++) {\n      caption = this.pendingCaptions[i];\n      caption.startTime = caption.startPts - timelineStartPts;\n      caption.startTime /= 90e3;\n      caption.endTime = caption.endPts - timelineStartPts;\n      caption.endTime /= 90e3;\n      event.captionStreams[caption.stream] = true;\n      event.captions.push(caption);\n    } // Translate ID3 frame PTS times into second offsets into the\n    // video timeline for the segment\n\n\n    for (i = 0; i < this.pendingMetadata.length; i++) {\n      id3 = this.pendingMetadata[i];\n      id3.cueTime = id3.pts - timelineStartPts;\n      id3.cueTime /= 90e3;\n      event.metadata.push(id3);\n    } // We add this to every single emitted segment even though we only need\n    // it for the first\n\n\n    event.metadata.dispatchType = this.metadataStream.dispatchType; // Reset stream state\n\n    this.videoTrack = null;\n    this.audioTrack = null;\n    this.videoTags = [];\n    this.audioTags = [];\n    this.pendingCaptions.length = 0;\n    this.pendingMetadata.length = 0;\n    this.pendingTracks = 0;\n    this.processedTracks = 0; // Emit the final segment\n\n    this.trigger('data', event);\n    this.trigger('done');\n  };\n\n  var coalesceStream = CoalesceStream;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var TagList = function TagList() {\n    var self = this;\n    this.list = [];\n\n    this.push = function (tag) {\n      this.list.push({\n        bytes: tag.bytes,\n        dts: tag.dts,\n        pts: tag.pts,\n        keyFrame: tag.keyFrame,\n        metaDataTag: tag.metaDataTag\n      });\n    };\n\n    Object.defineProperty(this, 'length', {\n      get: function get() {\n        return self.list.length;\n      }\n    });\n  };\n\n  var tagList = TagList;\n\n  var H264Stream = h264.H264Stream;\n\n  var _Transmuxer, _VideoSegmentStream, _AudioSegmentStream, collectTimelineInfo, metaDataTag, extraDataTag;\n  /**\n   * Store information about the start and end of the tracka and the\n   * duration for each frame/sample we process in order to calculate\n   * the baseMediaDecodeTime\n   */\n\n\n  collectTimelineInfo = function collectTimelineInfo(track, data) {\n    if (typeof data.pts === 'number') {\n      if (track.timelineStartInfo.pts === undefined) {\n        track.timelineStartInfo.pts = data.pts;\n      } else {\n        track.timelineStartInfo.pts = Math.min(track.timelineStartInfo.pts, data.pts);\n      }\n    }\n\n    if (typeof data.dts === 'number') {\n      if (track.timelineStartInfo.dts === undefined) {\n        track.timelineStartInfo.dts = data.dts;\n      } else {\n        track.timelineStartInfo.dts = Math.min(track.timelineStartInfo.dts, data.dts);\n      }\n    }\n  };\n\n  metaDataTag = function metaDataTag(track, pts) {\n    var tag = new flvTag(flvTag.METADATA_TAG); // :FlvTag\n\n    tag.dts = pts;\n    tag.pts = pts;\n    tag.writeMetaDataDouble('videocodecid', 7);\n    tag.writeMetaDataDouble('width', track.width);\n    tag.writeMetaDataDouble('height', track.height);\n    return tag;\n  };\n\n  extraDataTag = function extraDataTag(track, pts) {\n    var i,\n        tag = new flvTag(flvTag.VIDEO_TAG, true);\n    tag.dts = pts;\n    tag.pts = pts;\n    tag.writeByte(0x01); // version\n\n    tag.writeByte(track.profileIdc); // profile\n\n    tag.writeByte(track.profileCompatibility); // compatibility\n\n    tag.writeByte(track.levelIdc); // level\n\n    tag.writeByte(0xFC | 0x03); // reserved (6 bits), NULA length size - 1 (2 bits)\n\n    tag.writeByte(0xE0 | 0x01); // reserved (3 bits), num of SPS (5 bits)\n\n    tag.writeShort(track.sps[0].length); // data of SPS\n\n    tag.writeBytes(track.sps[0]); // SPS\n\n    tag.writeByte(track.pps.length); // num of PPS (will there ever be more that 1 PPS?)\n\n    for (i = 0; i < track.pps.length; ++i) {\n      tag.writeShort(track.pps[i].length); // 2 bytes for length of PPS\n\n      tag.writeBytes(track.pps[i]); // data of PPS\n    }\n\n    return tag;\n  };\n  /**\n   * Constructs a single-track, media segment from AAC data\n   * events. The output of this stream can be fed to flash.\n   */\n\n\n  _AudioSegmentStream = function AudioSegmentStream(track) {\n    var adtsFrames = [],\n        videoKeyFrames = [],\n        oldExtraData;\n\n    _AudioSegmentStream.prototype.init.call(this);\n\n    this.push = function (data) {\n      collectTimelineInfo(track, data);\n\n      if (track) {\n        track.audioobjecttype = data.audioobjecttype;\n        track.channelcount = data.channelcount;\n        track.samplerate = data.samplerate;\n        track.samplingfrequencyindex = data.samplingfrequencyindex;\n        track.samplesize = data.samplesize;\n        track.extraData = track.audioobjecttype << 11 | track.samplingfrequencyindex << 7 | track.channelcount << 3;\n      }\n\n      data.pts = Math.round(data.pts / 90);\n      data.dts = Math.round(data.dts / 90); // buffer audio data until end() is called\n\n      adtsFrames.push(data);\n    };\n\n    this.flush = function () {\n      var currentFrame,\n          adtsFrame,\n          lastMetaPts,\n          tags = new tagList(); // return early if no audio data has been observed\n\n      if (adtsFrames.length === 0) {\n        this.trigger('done', 'AudioSegmentStream');\n        return;\n      }\n\n      lastMetaPts = -Infinity;\n\n      while (adtsFrames.length) {\n        currentFrame = adtsFrames.shift(); // write out a metadata frame at every video key frame\n\n        if (videoKeyFrames.length && currentFrame.pts >= videoKeyFrames[0]) {\n          lastMetaPts = videoKeyFrames.shift();\n          this.writeMetaDataTags(tags, lastMetaPts);\n        } // also write out metadata tags every 1 second so that the decoder\n        // is re-initialized quickly after seeking into a different\n        // audio configuration.\n\n\n        if (track.extraData !== oldExtraData || currentFrame.pts - lastMetaPts >= 1000) {\n          this.writeMetaDataTags(tags, currentFrame.pts);\n          oldExtraData = track.extraData;\n          lastMetaPts = currentFrame.pts;\n        }\n\n        adtsFrame = new flvTag(flvTag.AUDIO_TAG);\n        adtsFrame.pts = currentFrame.pts;\n        adtsFrame.dts = currentFrame.dts;\n        adtsFrame.writeBytes(currentFrame.data);\n        tags.push(adtsFrame.finalize());\n      }\n\n      videoKeyFrames.length = 0;\n      oldExtraData = null;\n      this.trigger('data', {\n        track: track,\n        tags: tags.list\n      });\n      this.trigger('done', 'AudioSegmentStream');\n    };\n\n    this.writeMetaDataTags = function (tags, pts) {\n      var adtsFrame;\n      adtsFrame = new flvTag(flvTag.METADATA_TAG); // For audio, DTS is always the same as PTS. We want to set the DTS\n      // however so we can compare with video DTS to determine approximate\n      // packet order\n\n      adtsFrame.pts = pts;\n      adtsFrame.dts = pts; // AAC is always 10\n\n      adtsFrame.writeMetaDataDouble('audiocodecid', 10);\n      adtsFrame.writeMetaDataBoolean('stereo', track.channelcount === 2);\n      adtsFrame.writeMetaDataDouble('audiosamplerate', track.samplerate); // Is AAC always 16 bit?\n\n      adtsFrame.writeMetaDataDouble('audiosamplesize', 16);\n      tags.push(adtsFrame.finalize());\n      adtsFrame = new flvTag(flvTag.AUDIO_TAG, true); // For audio, DTS is always the same as PTS. We want to set the DTS\n      // however so we can compare with video DTS to determine approximate\n      // packet order\n\n      adtsFrame.pts = pts;\n      adtsFrame.dts = pts;\n      adtsFrame.view.setUint16(adtsFrame.position, track.extraData);\n      adtsFrame.position += 2;\n      adtsFrame.length = Math.max(adtsFrame.length, adtsFrame.position);\n      tags.push(adtsFrame.finalize());\n    };\n\n    this.onVideoKeyFrame = function (pts) {\n      videoKeyFrames.push(pts);\n    };\n  };\n\n  _AudioSegmentStream.prototype = new stream();\n  /**\n   * Store FlvTags for the h264 stream\n   * @param track {object} track metadata configuration\n   */\n\n  _VideoSegmentStream = function VideoSegmentStream(track) {\n    var nalUnits = [],\n        config,\n        h264Frame;\n\n    _VideoSegmentStream.prototype.init.call(this);\n\n    this.finishFrame = function (tags, frame) {\n      if (!frame) {\n        return;\n      } // Check if keyframe and the length of tags.\n      // This makes sure we write metadata on the first frame of a segment.\n\n\n      if (config && track && track.newMetadata && (frame.keyFrame || tags.length === 0)) {\n        // Push extra data on every IDR frame in case we did a stream change + seek\n        var metaTag = metaDataTag(config, frame.dts).finalize();\n        var extraTag = extraDataTag(track, frame.dts).finalize();\n        metaTag.metaDataTag = extraTag.metaDataTag = true;\n        tags.push(metaTag);\n        tags.push(extraTag);\n        track.newMetadata = false;\n        this.trigger('keyframe', frame.dts);\n      }\n\n      frame.endNalUnit();\n      tags.push(frame.finalize());\n      h264Frame = null;\n    };\n\n    this.push = function (data) {\n      collectTimelineInfo(track, data);\n      data.pts = Math.round(data.pts / 90);\n      data.dts = Math.round(data.dts / 90); // buffer video until flush() is called\n\n      nalUnits.push(data);\n    };\n\n    this.flush = function () {\n      var currentNal,\n          tags = new tagList(); // Throw away nalUnits at the start of the byte stream until we find\n      // the first AUD\n\n      while (nalUnits.length) {\n        if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n          break;\n        }\n\n        nalUnits.shift();\n      } // return early if no video data has been observed\n\n\n      if (nalUnits.length === 0) {\n        this.trigger('done', 'VideoSegmentStream');\n        return;\n      }\n\n      while (nalUnits.length) {\n        currentNal = nalUnits.shift(); // record the track config\n\n        if (currentNal.nalUnitType === 'seq_parameter_set_rbsp') {\n          track.newMetadata = true;\n          config = currentNal.config;\n          track.width = config.width;\n          track.height = config.height;\n          track.sps = [currentNal.data];\n          track.profileIdc = config.profileIdc;\n          track.levelIdc = config.levelIdc;\n          track.profileCompatibility = config.profileCompatibility;\n          h264Frame.endNalUnit();\n        } else if (currentNal.nalUnitType === 'pic_parameter_set_rbsp') {\n          track.newMetadata = true;\n          track.pps = [currentNal.data];\n          h264Frame.endNalUnit();\n        } else if (currentNal.nalUnitType === 'access_unit_delimiter_rbsp') {\n          if (h264Frame) {\n            this.finishFrame(tags, h264Frame);\n          }\n\n          h264Frame = new flvTag(flvTag.VIDEO_TAG);\n          h264Frame.pts = currentNal.pts;\n          h264Frame.dts = currentNal.dts;\n        } else {\n          if (currentNal.nalUnitType === 'slice_layer_without_partitioning_rbsp_idr') {\n            // the current sample is a key frame\n            h264Frame.keyFrame = true;\n          }\n\n          h264Frame.endNalUnit();\n        }\n\n        h264Frame.startNalUnit();\n        h264Frame.writeBytes(currentNal.data);\n      }\n\n      if (h264Frame) {\n        this.finishFrame(tags, h264Frame);\n      }\n\n      this.trigger('data', {\n        track: track,\n        tags: tags.list\n      }); // Continue with the flush process now\n\n      this.trigger('done', 'VideoSegmentStream');\n    };\n  };\n\n  _VideoSegmentStream.prototype = new stream();\n  /**\n   * An object that incrementally transmuxes MPEG2 Trasport Stream\n   * chunks into an FLV.\n   */\n\n  _Transmuxer = function Transmuxer(options) {\n    var self = this,\n        packetStream,\n        parseStream,\n        elementaryStream,\n        videoTimestampRolloverStream,\n        audioTimestampRolloverStream,\n        timedMetadataTimestampRolloverStream,\n        adtsStream,\n        h264Stream,\n        videoSegmentStream,\n        audioSegmentStream,\n        captionStream,\n        coalesceStream$1;\n\n    _Transmuxer.prototype.init.call(this);\n\n    options = options || {}; // expose the metadata stream\n\n    this.metadataStream = new m2ts_1.MetadataStream();\n    options.metadataStream = this.metadataStream; // set up the parsing pipeline\n\n    packetStream = new m2ts_1.TransportPacketStream();\n    parseStream = new m2ts_1.TransportParseStream();\n    elementaryStream = new m2ts_1.ElementaryStream();\n    videoTimestampRolloverStream = new m2ts_1.TimestampRolloverStream('video');\n    audioTimestampRolloverStream = new m2ts_1.TimestampRolloverStream('audio');\n    timedMetadataTimestampRolloverStream = new m2ts_1.TimestampRolloverStream('timed-metadata');\n    adtsStream = new adts();\n    h264Stream = new H264Stream();\n    coalesceStream$1 = new coalesceStream(options); // disassemble MPEG2-TS packets into elementary streams\n\n    packetStream.pipe(parseStream).pipe(elementaryStream); // !!THIS ORDER IS IMPORTANT!!\n    // demux the streams\n\n    elementaryStream.pipe(videoTimestampRolloverStream).pipe(h264Stream);\n    elementaryStream.pipe(audioTimestampRolloverStream).pipe(adtsStream);\n    elementaryStream.pipe(timedMetadataTimestampRolloverStream).pipe(this.metadataStream).pipe(coalesceStream$1); // if CEA-708 parsing is available, hook up a caption stream\n\n    captionStream = new m2ts_1.CaptionStream(options);\n    h264Stream.pipe(captionStream).pipe(coalesceStream$1); // hook up the segment streams once track metadata is delivered\n\n    elementaryStream.on('data', function (data) {\n      var i, videoTrack, audioTrack;\n\n      if (data.type === 'metadata') {\n        i = data.tracks.length; // scan the tracks listed in the metadata\n\n        while (i--) {\n          if (data.tracks[i].type === 'video') {\n            videoTrack = data.tracks[i];\n          } else if (data.tracks[i].type === 'audio') {\n            audioTrack = data.tracks[i];\n          }\n        } // hook up the video segment stream to the first track with h264 data\n\n\n        if (videoTrack && !videoSegmentStream) {\n          coalesceStream$1.numberOfTracks++;\n          videoSegmentStream = new _VideoSegmentStream(videoTrack); // Set up the final part of the video pipeline\n\n          h264Stream.pipe(videoSegmentStream).pipe(coalesceStream$1);\n        }\n\n        if (audioTrack && !audioSegmentStream) {\n          // hook up the audio segment stream to the first track with aac data\n          coalesceStream$1.numberOfTracks++;\n          audioSegmentStream = new _AudioSegmentStream(audioTrack); // Set up the final part of the audio pipeline\n\n          adtsStream.pipe(audioSegmentStream).pipe(coalesceStream$1);\n\n          if (videoSegmentStream) {\n            videoSegmentStream.on('keyframe', audioSegmentStream.onVideoKeyFrame);\n          }\n        }\n      }\n    }); // feed incoming data to the front of the parsing pipeline\n\n    this.push = function (data) {\n      packetStream.push(data);\n    }; // flush any buffered data\n\n\n    this.flush = function () {\n      // Start at the top of the pipeline and flush all pending work\n      packetStream.flush();\n    }; // Caption data has to be reset when seeking outside buffered range\n\n\n    this.resetCaptions = function () {\n      captionStream.reset();\n    }; // Re-emit any data coming from the coalesce stream to the outside world\n\n\n    coalesceStream$1.on('data', function (event) {\n      self.trigger('data', event);\n    }); // Let the consumer know we have finished flushing the entire pipeline\n\n    coalesceStream$1.on('done', function () {\n      self.trigger('done');\n    });\n  };\n\n  _Transmuxer.prototype = new stream(); // forward compatibility\n\n  var transmuxer$1 = _Transmuxer;\n\n  // http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf.\n  // Technically, this function returns the header and a metadata FLV tag\n  // if duration is greater than zero\n  // duration in seconds\n  // @return {object} the bytes of the FLV header as a Uint8Array\n\n\n  var getFlvHeader = function getFlvHeader(duration, audio, video) {\n    // :ByteArray {\n    var headBytes = new Uint8Array(3 + 1 + 1 + 4),\n        head = new DataView(headBytes.buffer),\n        metadata,\n        result,\n        metadataLength; // default arguments\n\n    duration = duration || 0;\n    audio = audio === undefined ? true : audio;\n    video = video === undefined ? true : video; // signature\n\n    head.setUint8(0, 0x46); // 'F'\n\n    head.setUint8(1, 0x4c); // 'L'\n\n    head.setUint8(2, 0x56); // 'V'\n    // version\n\n    head.setUint8(3, 0x01); // flags\n\n    head.setUint8(4, (audio ? 0x04 : 0x00) | (video ? 0x01 : 0x00)); // data offset, should be 9 for FLV v1\n\n    head.setUint32(5, headBytes.byteLength); // init the first FLV tag\n\n    if (duration <= 0) {\n      // no duration available so just write the first field of the first\n      // FLV tag\n      result = new Uint8Array(headBytes.byteLength + 4);\n      result.set(headBytes);\n      result.set([0, 0, 0, 0], headBytes.byteLength);\n      return result;\n    } // write out the duration metadata tag\n\n\n    metadata = new flvTag(flvTag.METADATA_TAG);\n    metadata.pts = metadata.dts = 0;\n    metadata.writeMetaDataDouble('duration', duration);\n    metadataLength = metadata.finalize().length;\n    result = new Uint8Array(headBytes.byteLength + metadataLength);\n    result.set(headBytes);\n    result.set(head.byteLength, metadataLength);\n    return result;\n  };\n\n  var flvHeader = getFlvHeader;\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var flv = {\n    tag: flvTag,\n    Transmuxer: transmuxer$1,\n    getFlvHeader: flvHeader\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var m2ts = m2ts_1;\n\n  var ONE_SECOND_IN_TS$1 = clock.ONE_SECOND_IN_TS;\n  /**\n   * Constructs a single-track, ISO BMFF media segment from AAC data\n   * events. The output of this stream can be fed to a SourceBuffer\n   * configured with a suitable initialization segment.\n   */\n\n  var AudioSegmentStream = function AudioSegmentStream(track, options) {\n    var adtsFrames = [],\n        sequenceNumber = 0,\n        earliestAllowedDts = 0,\n        audioAppendStartTs = 0,\n        videoBaseMediaDecodeTime = Infinity,\n        segmentStartPts = null,\n        segmentEndPts = null;\n    options = options || {};\n    AudioSegmentStream.prototype.init.call(this);\n\n    this.push = function (data) {\n      trackDecodeInfo.collectDtsInfo(track, data);\n\n      if (track) {\n        audioProperties.forEach(function (prop) {\n          track[prop] = data[prop];\n        });\n      } // buffer audio data until end() is called\n\n\n      adtsFrames.push(data);\n    };\n\n    this.setEarliestDts = function (earliestDts) {\n      earliestAllowedDts = earliestDts;\n    };\n\n    this.setVideoBaseMediaDecodeTime = function (baseMediaDecodeTime) {\n      videoBaseMediaDecodeTime = baseMediaDecodeTime;\n    };\n\n    this.setAudioAppendStart = function (timestamp) {\n      audioAppendStartTs = timestamp;\n    };\n\n    this.processFrames_ = function () {\n      var frames, moof, mdat, boxes, timingInfo; // return early if no audio data has been observed\n\n      if (adtsFrames.length === 0) {\n        return;\n      }\n\n      frames = audioFrameUtils.trimAdtsFramesByEarliestDts(adtsFrames, track, earliestAllowedDts);\n\n      if (frames.length === 0) {\n        // return early if the frames are all after the earliest allowed DTS\n        // TODO should we clear the adtsFrames?\n        return;\n      }\n\n      track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(track, options.keepOriginalTimestamps);\n      audioFrameUtils.prefixWithSilence(track, frames, audioAppendStartTs, videoBaseMediaDecodeTime); // we have to build the index from byte locations to\n      // samples (that is, adts frames) in the audio data\n\n      track.samples = audioFrameUtils.generateSampleTable(frames); // concatenate the audio data to constuct the mdat\n\n      mdat = mp4Generator.mdat(audioFrameUtils.concatenateFrameData(frames));\n      adtsFrames = [];\n      moof = mp4Generator.moof(sequenceNumber, [track]); // bump the sequence number for next time\n\n      sequenceNumber++;\n      track.initSegment = mp4Generator.initSegment([track]); // it would be great to allocate this array up front instead of\n      // throwing away hundreds of media segment fragments\n\n      boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n      boxes.set(moof);\n      boxes.set(mdat, moof.byteLength);\n      trackDecodeInfo.clearDtsInfo(track);\n\n      if (segmentStartPts === null) {\n        segmentEndPts = segmentStartPts = frames[0].pts;\n      }\n\n      segmentEndPts += frames.length * (ONE_SECOND_IN_TS$1 * 1024 / track.samplerate);\n      timingInfo = {\n        start: segmentStartPts\n      };\n      this.trigger('timingInfo', timingInfo);\n      this.trigger('data', {\n        track: track,\n        boxes: boxes\n      });\n    };\n\n    this.flush = function () {\n      this.processFrames_(); // trigger final timing info\n\n      this.trigger('timingInfo', {\n        start: segmentStartPts,\n        end: segmentEndPts\n      });\n      this.resetTiming_();\n      this.trigger('done', 'AudioSegmentStream');\n    };\n\n    this.partialFlush = function () {\n      this.processFrames_();\n      this.trigger('partialdone', 'AudioSegmentStream');\n    };\n\n    this.endTimeline = function () {\n      this.flush();\n      this.trigger('endedtimeline', 'AudioSegmentStream');\n    };\n\n    this.resetTiming_ = function () {\n      trackDecodeInfo.clearDtsInfo(track);\n      segmentStartPts = null;\n      segmentEndPts = null;\n    };\n\n    this.reset = function () {\n      this.resetTiming_();\n      adtsFrames = [];\n      this.trigger('reset');\n    };\n  };\n\n  AudioSegmentStream.prototype = new stream();\n  var audioSegmentStream = AudioSegmentStream;\n\n  var VideoSegmentStream = function VideoSegmentStream(track, options) {\n    var sequenceNumber = 0,\n        nalUnits = [],\n        frameCache = [],\n        // gopsToAlignWith = [],\n    config,\n        pps,\n        segmentStartPts = null,\n        segmentEndPts = null,\n        gops,\n        ensureNextFrameIsKeyFrame = true;\n    options = options || {};\n    VideoSegmentStream.prototype.init.call(this);\n\n    this.push = function (nalUnit) {\n      trackDecodeInfo.collectDtsInfo(track, nalUnit);\n\n      if (typeof track.timelineStartInfo.dts === 'undefined') {\n        track.timelineStartInfo.dts = nalUnit.dts;\n      } // record the track config\n\n\n      if (nalUnit.nalUnitType === 'seq_parameter_set_rbsp' && !config) {\n        config = nalUnit.config;\n        track.sps = [nalUnit.data];\n        videoProperties.forEach(function (prop) {\n          track[prop] = config[prop];\n        }, this);\n      }\n\n      if (nalUnit.nalUnitType === 'pic_parameter_set_rbsp' && !pps) {\n        pps = nalUnit.data;\n        track.pps = [nalUnit.data];\n      } // buffer video until flush() is called\n\n\n      nalUnits.push(nalUnit);\n    };\n\n    this.processNals_ = function (cacheLastFrame) {\n      var i;\n      nalUnits = frameCache.concat(nalUnits); // Throw away nalUnits at the start of the byte stream until\n      // we find the first AUD\n\n      while (nalUnits.length) {\n        if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n          break;\n        }\n\n        nalUnits.shift();\n      } // Return early if no video data has been observed\n\n\n      if (nalUnits.length === 0) {\n        return;\n      }\n\n      var frames = frameUtils.groupNalsIntoFrames(nalUnits);\n\n      if (!frames.length) {\n        return;\n      } // note that the frame cache may also protect us from cases where we haven't\n      // pushed data for the entire first or last frame yet\n\n\n      frameCache = frames[frames.length - 1];\n\n      if (cacheLastFrame) {\n        frames.pop();\n        frames.duration -= frameCache.duration;\n        frames.nalCount -= frameCache.length;\n        frames.byteLength -= frameCache.byteLength;\n      }\n\n      if (!frames.length) {\n        nalUnits = [];\n        return;\n      }\n\n      this.trigger('timelineStartInfo', track.timelineStartInfo);\n\n      if (ensureNextFrameIsKeyFrame) {\n        gops = frameUtils.groupFramesIntoGops(frames);\n\n        if (!gops[0][0].keyFrame) {\n          gops = frameUtils.extendFirstKeyFrame(gops);\n\n          if (!gops[0][0].keyFrame) {\n            // we haven't yet gotten a key frame, so reset nal units to wait for more nal\n            // units\n            nalUnits = [].concat.apply([], frames).concat(frameCache);\n            frameCache = [];\n            return;\n          }\n\n          frames = [].concat.apply([], gops);\n          frames.duration = gops.duration;\n        }\n\n        ensureNextFrameIsKeyFrame = false;\n      }\n\n      if (segmentStartPts === null) {\n        segmentStartPts = frames[0].pts;\n        segmentEndPts = segmentStartPts;\n      }\n\n      segmentEndPts += frames.duration;\n      this.trigger('timingInfo', {\n        start: segmentStartPts,\n        end: segmentEndPts\n      });\n\n      for (i = 0; i < frames.length; i++) {\n        var frame = frames[i];\n        track.samples = frameUtils.generateSampleTableForFrame(frame);\n        var mdat = mp4Generator.mdat(frameUtils.concatenateNalDataForFrame(frame));\n        trackDecodeInfo.clearDtsInfo(track);\n        trackDecodeInfo.collectDtsInfo(track, frame);\n        track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(track, options.keepOriginalTimestamps);\n        var moof = mp4Generator.moof(sequenceNumber, [track]);\n        sequenceNumber++;\n        track.initSegment = mp4Generator.initSegment([track]);\n        var boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n        boxes.set(moof);\n        boxes.set(mdat, moof.byteLength);\n        this.trigger('data', {\n          track: track,\n          boxes: boxes,\n          sequence: sequenceNumber,\n          videoFrameDts: frame.dts,\n          videoFramePts: frame.pts\n        });\n      }\n\n      nalUnits = [];\n    };\n\n    this.resetTimingAndConfig_ = function () {\n      config = undefined;\n      pps = undefined;\n      segmentStartPts = null;\n      segmentEndPts = null;\n    };\n\n    this.partialFlush = function () {\n      this.processNals_(true);\n      this.trigger('partialdone', 'VideoSegmentStream');\n    };\n\n    this.flush = function () {\n      this.processNals_(false); // reset config and pps because they may differ across segments\n      // for instance, when we are rendition switching\n\n      this.resetTimingAndConfig_();\n      this.trigger('done', 'VideoSegmentStream');\n    };\n\n    this.endTimeline = function () {\n      this.flush();\n      this.trigger('endedtimeline', 'VideoSegmentStream');\n    };\n\n    this.reset = function () {\n      this.resetTimingAndConfig_();\n      frameCache = [];\n      nalUnits = [];\n      ensureNextFrameIsKeyFrame = true;\n      this.trigger('reset');\n    };\n  };\n\n  VideoSegmentStream.prototype = new stream();\n  var videoSegmentStream = VideoSegmentStream;\n\n  var isLikelyAacData = utils.isLikelyAacData;\n\n  var createPipeline = function createPipeline(object) {\n    object.prototype = new stream();\n    object.prototype.init.call(object);\n    return object;\n  };\n\n  var tsPipeline = function tsPipeline(options) {\n    var pipeline = {\n      type: 'ts',\n      tracks: {\n        audio: null,\n        video: null\n      },\n      packet: new m2ts_1.TransportPacketStream(),\n      parse: new m2ts_1.TransportParseStream(),\n      elementary: new m2ts_1.ElementaryStream(),\n      timestampRollover: new m2ts_1.TimestampRolloverStream(),\n      adts: new codecs.Adts(),\n      h264: new codecs.h264.H264Stream(),\n      captionStream: new m2ts_1.CaptionStream(options),\n      metadataStream: new m2ts_1.MetadataStream()\n    };\n    pipeline.headOfPipeline = pipeline.packet; // Transport Stream\n\n    pipeline.packet.pipe(pipeline.parse).pipe(pipeline.elementary).pipe(pipeline.timestampRollover); // H264\n\n    pipeline.timestampRollover.pipe(pipeline.h264); // Hook up CEA-608/708 caption stream\n\n    pipeline.h264.pipe(pipeline.captionStream);\n    pipeline.timestampRollover.pipe(pipeline.metadataStream); // ADTS\n\n    pipeline.timestampRollover.pipe(pipeline.adts);\n    pipeline.elementary.on('data', function (data) {\n      if (data.type !== 'metadata') {\n        return;\n      }\n\n      for (var i = 0; i < data.tracks.length; i++) {\n        if (!pipeline.tracks[data.tracks[i].type]) {\n          pipeline.tracks[data.tracks[i].type] = data.tracks[i];\n          pipeline.tracks[data.tracks[i].type].timelineStartInfo.baseMediaDecodeTime = options.baseMediaDecodeTime;\n        }\n      }\n\n      if (pipeline.tracks.video && !pipeline.videoSegmentStream) {\n        pipeline.videoSegmentStream = new videoSegmentStream(pipeline.tracks.video, options);\n        pipeline.videoSegmentStream.on('timelineStartInfo', function (timelineStartInfo) {\n          if (pipeline.tracks.audio && !options.keepOriginalTimestamps) {\n            pipeline.audioSegmentStream.setEarliestDts(timelineStartInfo.dts - options.baseMediaDecodeTime);\n          }\n        });\n        pipeline.videoSegmentStream.on('timingInfo', pipeline.trigger.bind(pipeline, 'videoTimingInfo'));\n        pipeline.videoSegmentStream.on('data', function (data) {\n          pipeline.trigger('data', {\n            type: 'video',\n            data: data\n          });\n        });\n        pipeline.videoSegmentStream.on('done', pipeline.trigger.bind(pipeline, 'done'));\n        pipeline.videoSegmentStream.on('partialdone', pipeline.trigger.bind(pipeline, 'partialdone'));\n        pipeline.videoSegmentStream.on('endedtimeline', pipeline.trigger.bind(pipeline, 'endedtimeline'));\n        pipeline.h264.pipe(pipeline.videoSegmentStream);\n      }\n\n      if (pipeline.tracks.audio && !pipeline.audioSegmentStream) {\n        pipeline.audioSegmentStream = new audioSegmentStream(pipeline.tracks.audio, options);\n        pipeline.audioSegmentStream.on('data', function (data) {\n          pipeline.trigger('data', {\n            type: 'audio',\n            data: data\n          });\n        });\n        pipeline.audioSegmentStream.on('done', pipeline.trigger.bind(pipeline, 'done'));\n        pipeline.audioSegmentStream.on('partialdone', pipeline.trigger.bind(pipeline, 'partialdone'));\n        pipeline.audioSegmentStream.on('endedtimeline', pipeline.trigger.bind(pipeline, 'endedtimeline'));\n        pipeline.audioSegmentStream.on('timingInfo', pipeline.trigger.bind(pipeline, 'audioTimingInfo'));\n        pipeline.adts.pipe(pipeline.audioSegmentStream);\n      } // emit pmt info\n\n\n      pipeline.trigger('trackinfo', {\n        hasAudio: !!pipeline.tracks.audio,\n        hasVideo: !!pipeline.tracks.video\n      });\n    });\n    pipeline.captionStream.on('data', function (caption) {\n      var timelineStartPts;\n\n      if (pipeline.tracks.video) {\n        timelineStartPts = pipeline.tracks.video.timelineStartInfo.pts || 0;\n      } else {\n        // This will only happen if we encounter caption packets before\n        // video data in a segment. This is an unusual/unlikely scenario,\n        // so we assume the timeline starts at zero for now.\n        timelineStartPts = 0;\n      } // Translate caption PTS times into second offsets into the\n      // video timeline for the segment\n\n\n      caption.startTime = clock.metadataTsToSeconds(caption.startPts, timelineStartPts, options.keepOriginalTimestamps);\n      caption.endTime = clock.metadataTsToSeconds(caption.endPts, timelineStartPts, options.keepOriginalTimestamps);\n      pipeline.trigger('caption', caption);\n    });\n    pipeline = createPipeline(pipeline);\n    pipeline.metadataStream.on('data', pipeline.trigger.bind(pipeline, 'id3Frame'));\n    return pipeline;\n  };\n\n  var aacPipeline = function aacPipeline(options) {\n    var pipeline = {\n      type: 'aac',\n      tracks: {\n        audio: null\n      },\n      metadataStream: new m2ts_1.MetadataStream(),\n      aacStream: new aac(),\n      audioRollover: new m2ts_1.TimestampRolloverStream('audio'),\n      timedMetadataRollover: new m2ts_1.TimestampRolloverStream('timed-metadata'),\n      adtsStream: new adts(true)\n    }; // set up the parsing pipeline\n\n    pipeline.headOfPipeline = pipeline.aacStream;\n    pipeline.aacStream.pipe(pipeline.audioRollover).pipe(pipeline.adtsStream);\n    pipeline.aacStream.pipe(pipeline.timedMetadataRollover).pipe(pipeline.metadataStream);\n    pipeline.metadataStream.on('timestamp', function (frame) {\n      pipeline.aacStream.setTimestamp(frame.timeStamp);\n    });\n    pipeline.aacStream.on('data', function (data) {\n      if (data.type !== 'timed-metadata' && data.type !== 'audio' || pipeline.audioSegmentStream) {\n        return;\n      }\n\n      pipeline.tracks.audio = pipeline.tracks.audio || {\n        timelineStartInfo: {\n          baseMediaDecodeTime: options.baseMediaDecodeTime\n        },\n        codec: 'adts',\n        type: 'audio'\n      }; // hook up the audio segment stream to the first track with aac data\n\n      pipeline.audioSegmentStream = new audioSegmentStream(pipeline.tracks.audio, options);\n      pipeline.audioSegmentStream.on('data', function (data) {\n        pipeline.trigger('data', {\n          type: 'audio',\n          data: data\n        });\n      });\n      pipeline.audioSegmentStream.on('partialdone', pipeline.trigger.bind(pipeline, 'partialdone'));\n      pipeline.audioSegmentStream.on('done', pipeline.trigger.bind(pipeline, 'done'));\n      pipeline.audioSegmentStream.on('endedtimeline', pipeline.trigger.bind(pipeline, 'endedtimeline'));\n      pipeline.audioSegmentStream.on('timingInfo', pipeline.trigger.bind(pipeline, 'audioTimingInfo')); // Set up the final part of the audio pipeline\n\n      pipeline.adtsStream.pipe(pipeline.audioSegmentStream);\n      pipeline.trigger('trackinfo', {\n        hasAudio: !!pipeline.tracks.audio,\n        hasVideo: !!pipeline.tracks.video\n      });\n    }); // set the pipeline up as a stream before binding to get access to the trigger function\n\n    pipeline = createPipeline(pipeline);\n    pipeline.metadataStream.on('data', pipeline.trigger.bind(pipeline, 'id3Frame'));\n    return pipeline;\n  };\n\n  var setupPipelineListeners = function setupPipelineListeners(pipeline, transmuxer) {\n    pipeline.on('data', transmuxer.trigger.bind(transmuxer, 'data'));\n    pipeline.on('done', transmuxer.trigger.bind(transmuxer, 'done'));\n    pipeline.on('partialdone', transmuxer.trigger.bind(transmuxer, 'partialdone'));\n    pipeline.on('endedtimeline', transmuxer.trigger.bind(transmuxer, 'endedtimeline'));\n    pipeline.on('audioTimingInfo', transmuxer.trigger.bind(transmuxer, 'audioTimingInfo'));\n    pipeline.on('videoTimingInfo', transmuxer.trigger.bind(transmuxer, 'videoTimingInfo'));\n    pipeline.on('trackinfo', transmuxer.trigger.bind(transmuxer, 'trackinfo'));\n    pipeline.on('id3Frame', function (event) {\n      // add this to every single emitted segment even though it's only needed for the first\n      event.dispatchType = pipeline.metadataStream.dispatchType; // keep original time, can be adjusted if needed at a higher level\n\n      event.cueTime = clock.videoTsToSeconds(event.pts);\n      transmuxer.trigger('id3Frame', event);\n    });\n    pipeline.on('caption', function (event) {\n      transmuxer.trigger('caption', event);\n    });\n  };\n\n  var Transmuxer = function Transmuxer(options) {\n    var pipeline = null,\n        hasFlushed = true;\n    options = options || {};\n    Transmuxer.prototype.init.call(this);\n    options.baseMediaDecodeTime = options.baseMediaDecodeTime || 0;\n\n    this.push = function (bytes) {\n      if (hasFlushed) {\n        var isAac = isLikelyAacData(bytes);\n\n        if (isAac && (!pipeline || pipeline.type !== 'aac')) {\n          pipeline = aacPipeline(options);\n          setupPipelineListeners(pipeline, this);\n        } else if (!isAac && (!pipeline || pipeline.type !== 'ts')) {\n          pipeline = tsPipeline(options);\n          setupPipelineListeners(pipeline, this);\n        }\n\n        hasFlushed = false;\n      }\n\n      pipeline.headOfPipeline.push(bytes);\n    };\n\n    this.flush = function () {\n      if (!pipeline) {\n        return;\n      }\n\n      hasFlushed = true;\n      pipeline.headOfPipeline.flush();\n    };\n\n    this.partialFlush = function () {\n      if (!pipeline) {\n        return;\n      }\n\n      pipeline.headOfPipeline.partialFlush();\n    };\n\n    this.endTimeline = function () {\n      if (!pipeline) {\n        return;\n      }\n\n      pipeline.headOfPipeline.endTimeline();\n    };\n\n    this.reset = function () {\n      if (!pipeline) {\n        return;\n      }\n\n      pipeline.headOfPipeline.reset();\n    };\n\n    this.setBaseMediaDecodeTime = function (baseMediaDecodeTime) {\n      if (!options.keepOriginalTimestamps) {\n        options.baseMediaDecodeTime = baseMediaDecodeTime;\n      }\n\n      if (!pipeline) {\n        return;\n      }\n\n      if (pipeline.tracks.audio) {\n        pipeline.tracks.audio.timelineStartInfo.dts = undefined;\n        pipeline.tracks.audio.timelineStartInfo.pts = undefined;\n        trackDecodeInfo.clearDtsInfo(pipeline.tracks.audio);\n\n        if (pipeline.audioRollover) {\n          pipeline.audioRollover.discontinuity();\n        }\n      }\n\n      if (pipeline.tracks.video) {\n        if (pipeline.videoSegmentStream) {\n          pipeline.videoSegmentStream.gopCache_ = [];\n        }\n\n        pipeline.tracks.video.timelineStartInfo.dts = undefined;\n        pipeline.tracks.video.timelineStartInfo.pts = undefined;\n        trackDecodeInfo.clearDtsInfo(pipeline.tracks.video); // pipeline.captionStream.reset();\n      }\n\n      if (pipeline.timestampRollover) {\n        pipeline.timestampRollover.discontinuity();\n      }\n    };\n\n    this.setRemux = function (val) {\n      options.remux = val;\n\n      if (pipeline && pipeline.coalesceStream) {\n        pipeline.coalesceStream.setRemux(val);\n      }\n    };\n\n    this.setAudioAppendStart = function (audioAppendStart) {\n      if (!pipeline || !pipeline.tracks.audio || !pipeline.audioSegmentStream) {\n        return;\n      }\n\n      pipeline.audioSegmentStream.setAudioAppendStart(audioAppendStart);\n    }; // TODO GOP alignment support\n    // Support may be a bit trickier than with full segment appends, as GOPs may be split\n    // and processed in a more granular fashion\n\n\n    this.alignGopsWith = function (gopsToAlignWith) {\n      return;\n    };\n  };\n\n  Transmuxer.prototype = new stream();\n  var transmuxer = Transmuxer;\n\n  var partial = {\n    Transmuxer: transmuxer\n  };\n\n  var getUint64$1 = numbers.getUint64;\n\n  var parseSidx = function parseSidx(data) {\n    var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4)),\n      references: [],\n      referenceId: view.getUint32(4),\n      timescale: view.getUint32(8)\n    },\n        i = 12;\n\n    if (result.version === 0) {\n      result.earliestPresentationTime = view.getUint32(i);\n      result.firstOffset = view.getUint32(i + 4);\n      i += 8;\n    } else {\n      // read 64 bits\n      result.earliestPresentationTime = getUint64$1(data.subarray(i));\n      result.firstOffset = getUint64$1(data.subarray(i + 8));\n      i += 16;\n    }\n\n    i += 2; // reserved\n\n    var referenceCount = view.getUint16(i);\n    i += 2; // start of references\n\n    for (; referenceCount > 0; i += 12, referenceCount--) {\n      result.references.push({\n        referenceType: (data[i] & 0x80) >>> 7,\n        referencedSize: view.getUint32(i) & 0x7FFFFFFF,\n        subsegmentDuration: view.getUint32(i + 4),\n        startsWithSap: !!(data[i + 8] & 0x80),\n        sapType: (data[i + 8] & 0x70) >>> 4,\n        sapDeltaTime: view.getUint32(i + 8) & 0x0FFFFFFF\n      });\n    }\n\n    return result;\n  };\n\n  var parseSidx_1 = parseSidx;\n\n  var getUint64 = numbers.getUint64;\n\n  var inspectMp4,\n      _textifyMp,\n      parseMp4Date = function parseMp4Date(seconds) {\n    return new Date(seconds * 1000 - 2082844800000);\n  },\n      nalParse = function nalParse(avcStream) {\n    var avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n        result = [],\n        i,\n        length;\n\n    for (i = 0; i + 4 < avcStream.length; i += length) {\n      length = avcView.getUint32(i);\n      i += 4; // bail if this doesn't appear to be an H264 stream\n\n      if (length <= 0) {\n        result.push('<span style=\\'color:red;\\'>MALFORMED DATA</span>');\n        continue;\n      }\n\n      switch (avcStream[i] & 0x1F) {\n        case 0x01:\n          result.push('slice_layer_without_partitioning_rbsp');\n          break;\n\n        case 0x05:\n          result.push('slice_layer_without_partitioning_rbsp_idr');\n          break;\n\n        case 0x06:\n          result.push('sei_rbsp');\n          break;\n\n        case 0x07:\n          result.push('seq_parameter_set_rbsp');\n          break;\n\n        case 0x08:\n          result.push('pic_parameter_set_rbsp');\n          break;\n\n        case 0x09:\n          result.push('access_unit_delimiter_rbsp');\n          break;\n\n        default:\n          result.push('UNKNOWN NAL - ' + avcStream[i] & 0x1F);\n          break;\n      }\n    }\n\n    return result;\n  },\n      // registry of handlers for individual mp4 box types\n  parse = {\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    avc1: function avc1(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        dataReferenceIndex: view.getUint16(6),\n        width: view.getUint16(24),\n        height: view.getUint16(26),\n        horizresolution: view.getUint16(28) + view.getUint16(30) / 16,\n        vertresolution: view.getUint16(32) + view.getUint16(34) / 16,\n        frameCount: view.getUint16(40),\n        depth: view.getUint16(74),\n        config: inspectMp4(data.subarray(78, data.byteLength))\n      };\n    },\n    avcC: function avcC(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        configurationVersion: data[0],\n        avcProfileIndication: data[1],\n        profileCompatibility: data[2],\n        avcLevelIndication: data[3],\n        lengthSizeMinusOne: data[4] & 0x03,\n        sps: [],\n        pps: []\n      },\n          numOfSequenceParameterSets = data[5] & 0x1f,\n          numOfPictureParameterSets,\n          nalSize,\n          offset,\n          i; // iterate past any SPSs\n\n      offset = 6;\n\n      for (i = 0; i < numOfSequenceParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.sps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      } // iterate past any PPSs\n\n\n      numOfPictureParameterSets = data[offset];\n      offset++;\n\n      for (i = 0; i < numOfPictureParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.pps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      }\n\n      return result;\n    },\n    btrt: function btrt(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        bufferSizeDB: view.getUint32(0),\n        maxBitrate: view.getUint32(4),\n        avgBitrate: view.getUint32(8)\n      };\n    },\n    edts: function edts(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    elst: function elst(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        edits: []\n      },\n          entryCount = view.getUint32(4),\n          i;\n\n      for (i = 8; entryCount; entryCount--) {\n        if (result.version === 0) {\n          result.edits.push({\n            segmentDuration: view.getUint32(i),\n            mediaTime: view.getInt32(i + 4),\n            mediaRate: view.getUint16(i + 8) + view.getUint16(i + 10) / (256 * 256)\n          });\n          i += 12;\n        } else {\n          result.edits.push({\n            segmentDuration: getUint64(data.subarray(i)),\n            mediaTime: getUint64(data.subarray(i + 8)),\n            mediaRate: view.getUint16(i + 16) + view.getUint16(i + 18) / (256 * 256)\n          });\n          i += 20;\n        }\n      }\n\n      return result;\n    },\n    esds: function esds(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        esId: data[6] << 8 | data[7],\n        streamPriority: data[8] & 0x1f,\n        decoderConfig: {\n          objectProfileIndication: data[11],\n          streamType: data[12] >>> 2 & 0x3f,\n          bufferSize: data[13] << 16 | data[14] << 8 | data[15],\n          maxBitrate: data[16] << 24 | data[17] << 16 | data[18] << 8 | data[19],\n          avgBitrate: data[20] << 24 | data[21] << 16 | data[22] << 8 | data[23],\n          decoderConfigDescriptor: {\n            tag: data[24],\n            length: data[25],\n            audioObjectType: data[26] >>> 3 & 0x1f,\n            samplingFrequencyIndex: (data[26] & 0x07) << 1 | data[27] >>> 7 & 0x01,\n            channelConfiguration: data[27] >>> 3 & 0x0f\n          }\n        }\n      };\n    },\n    ftyp: function ftyp(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        majorBrand: parseType_1(data.subarray(0, 4)),\n        minorVersion: view.getUint32(4),\n        compatibleBrands: []\n      },\n          i = 8;\n\n      while (i < data.byteLength) {\n        result.compatibleBrands.push(parseType_1(data.subarray(i, i + 4)));\n        i += 4;\n      }\n\n      return result;\n    },\n    dinf: function dinf(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    dref: function dref(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        dataReferences: inspectMp4(data.subarray(8))\n      };\n    },\n    hdlr: function hdlr(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        handlerType: parseType_1(data.subarray(8, 12)),\n        name: ''\n      },\n          i = 8; // parse out the name field\n\n      for (i = 24; i < data.byteLength; i++) {\n        if (data[i] === 0x00) {\n          // the name field is null-terminated\n          i++;\n          break;\n        }\n\n        result.name += String.fromCharCode(data[i]);\n      } // decode UTF-8 to javascript's internal representation\n      // see http://ecmanaut.blogspot.com/2006/07/encoding-decoding-utf8-in-javascript.html\n\n\n      result.name = decodeURIComponent(escape(result.name));\n      return result;\n    },\n    mdat: function mdat(data) {\n      return {\n        byteLength: data.byteLength,\n        nals: nalParse(data)\n      };\n    },\n    mdhd: function mdhd(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          i = 4,\n          language,\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        language: ''\n      };\n\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n\n      i += 4; // language is stored as an ISO-639-2/T code in an array of three 5-bit fields\n      // each field is the packed difference between its ASCII value and 0x60\n\n      language = view.getUint16(i);\n      result.language += String.fromCharCode((language >> 10) + 0x60);\n      result.language += String.fromCharCode(((language & 0x03e0) >> 5) + 0x60);\n      result.language += String.fromCharCode((language & 0x1f) + 0x60);\n      return result;\n    },\n    mdia: function mdia(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mfhd: function mfhd(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sequenceNumber: data[4] << 24 | data[5] << 16 | data[6] << 8 | data[7]\n      };\n    },\n    minf: function minf(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    mp4a: function mp4a(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        // 6 bytes reserved\n        dataReferenceIndex: view.getUint16(6),\n        // 4 + 4 bytes reserved\n        channelcount: view.getUint16(16),\n        samplesize: view.getUint16(18),\n        // 2 bytes pre_defined\n        // 2 bytes reserved\n        samplerate: view.getUint16(24) + view.getUint16(26) / 65536\n      }; // if there are more bytes to process, assume this is an ISO/IEC\n      // 14496-14 MP4AudioSampleEntry and parse the ESDBox\n\n      if (data.byteLength > 28) {\n        result.streamDescriptor = inspectMp4(data.subarray(28))[0];\n      }\n\n      return result;\n    },\n    moof: function moof(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    moov: function moov(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvex: function mvex(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvhd: function mvhd(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          i = 4,\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4))\n      };\n\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n\n      i += 4; // convert fixed-point, base 16 back to a number\n\n      result.rate = view.getUint16(i) + view.getUint16(i + 2) / 16;\n      i += 4;\n      result.volume = view.getUint8(i) + view.getUint8(i + 1) / 8;\n      i += 2;\n      i += 2;\n      i += 2 * 4;\n      result.matrix = new Uint32Array(data.subarray(i, i + 9 * 4));\n      i += 9 * 4;\n      i += 6 * 4;\n      result.nextTrackId = view.getUint32(i);\n      return result;\n    },\n    pdin: function pdin(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        rate: view.getUint32(4),\n        initialDelay: view.getUint32(8)\n      };\n    },\n    sdtp: function sdtp(data) {\n      var result = {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        samples: []\n      },\n          i;\n\n      for (i = 4; i < data.byteLength; i++) {\n        result.samples.push({\n          dependsOn: (data[i] & 0x30) >> 4,\n          isDependedOn: (data[i] & 0x0c) >> 2,\n          hasRedundancy: data[i] & 0x03\n        });\n      }\n\n      return result;\n    },\n    sidx: parseSidx_1,\n    smhd: function smhd(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        balance: data[4] + data[5] / 256\n      };\n    },\n    stbl: function stbl(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    ctts: function ctts(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        compositionOffsets: []\n      },\n          entryCount = view.getUint32(4),\n          i;\n\n      for (i = 8; entryCount; i += 8, entryCount--) {\n        result.compositionOffsets.push({\n          sampleCount: view.getUint32(i),\n          sampleOffset: view[result.version === 0 ? 'getUint32' : 'getInt32'](i + 4)\n        });\n      }\n\n      return result;\n    },\n    stss: function stss(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        syncSamples: []\n      },\n          entryCount = view.getUint32(4),\n          i;\n\n      for (i = 8; entryCount; i += 4, entryCount--) {\n        result.syncSamples.push(view.getUint32(i));\n      }\n\n      return result;\n    },\n    stco: function stco(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        chunkOffsets: []\n      },\n          entryCount = view.getUint32(4),\n          i;\n\n      for (i = 8; entryCount; i += 4, entryCount--) {\n        result.chunkOffsets.push(view.getUint32(i));\n      }\n\n      return result;\n    },\n    stsc: function stsc(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          entryCount = view.getUint32(4),\n          result = {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sampleToChunks: []\n      },\n          i;\n\n      for (i = 8; entryCount; i += 12, entryCount--) {\n        result.sampleToChunks.push({\n          firstChunk: view.getUint32(i),\n          samplesPerChunk: view.getUint32(i + 4),\n          sampleDescriptionIndex: view.getUint32(i + 8)\n        });\n      }\n\n      return result;\n    },\n    stsd: function stsd(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sampleDescriptions: inspectMp4(data.subarray(8))\n      };\n    },\n    stsz: function stsz(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sampleSize: view.getUint32(4),\n        entries: []\n      },\n          i;\n\n      for (i = 12; i < data.byteLength; i += 4) {\n        result.entries.push(view.getUint32(i));\n      }\n\n      return result;\n    },\n    stts: function stts(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          result = {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        timeToSamples: []\n      },\n          entryCount = view.getUint32(4),\n          i;\n\n      for (i = 8; entryCount; i += 8, entryCount--) {\n        result.timeToSamples.push({\n          sampleCount: view.getUint32(i),\n          sampleDelta: view.getUint32(i + 4)\n        });\n      }\n\n      return result;\n    },\n    styp: function styp(data) {\n      return parse.ftyp(data);\n    },\n    tfdt: parseTfdt,\n    tfhd: parseTfhd,\n    tkhd: function tkhd(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n          i = 4,\n          result = {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4))\n      };\n\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n\n      i += 4;\n      i += 2 * 4;\n      result.layer = view.getUint16(i);\n      i += 2;\n      result.alternateGroup = view.getUint16(i);\n      i += 2; // convert fixed-point, base 16 back to a number\n\n      result.volume = view.getUint8(i) + view.getUint8(i + 1) / 8;\n      i += 2;\n      i += 2;\n      result.matrix = new Uint32Array(data.subarray(i, i + 9 * 4));\n      i += 9 * 4;\n      result.width = view.getUint16(i) + view.getUint16(i + 2) / 65536;\n      i += 4;\n      result.height = view.getUint16(i) + view.getUint16(i + 2) / 65536;\n      return result;\n    },\n    traf: function traf(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trak: function trak(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trex: function trex(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        trackId: view.getUint32(4),\n        defaultSampleDescriptionIndex: view.getUint32(8),\n        defaultSampleDuration: view.getUint32(12),\n        defaultSampleSize: view.getUint32(16),\n        sampleDependsOn: data[20] & 0x03,\n        sampleIsDependedOn: (data[21] & 0xc0) >> 6,\n        sampleHasRedundancy: (data[21] & 0x30) >> 4,\n        samplePaddingValue: (data[21] & 0x0e) >> 1,\n        sampleIsDifferenceSample: !!(data[21] & 0x01),\n        sampleDegradationPriority: view.getUint16(22)\n      };\n    },\n    trun: parseTrun,\n    'url ': function url(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4))\n      };\n    },\n    vmhd: function vmhd(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        graphicsmode: view.getUint16(4),\n        opcolor: new Uint16Array([view.getUint16(6), view.getUint16(8), view.getUint16(10)])\n      };\n    }\n  };\n  /**\n   * Return a javascript array of box objects parsed from an ISO base\n   * media file.\n   * @param data {Uint8Array} the binary data of the media to be inspected\n   * @return {array} a javascript array of potentially nested box objects\n   */\n\n\n  inspectMp4 = function inspectMp4(data) {\n    var i = 0,\n        result = [],\n        view,\n        size,\n        type,\n        end,\n        box; // Convert data from Uint8Array to ArrayBuffer, to follow Dataview API\n\n    var ab = new ArrayBuffer(data.length);\n    var v = new Uint8Array(ab);\n\n    for (var z = 0; z < data.length; ++z) {\n      v[z] = data[z];\n    }\n\n    view = new DataView(ab);\n\n    while (i < data.byteLength) {\n      // parse box data\n      size = view.getUint32(i);\n      type = parseType_1(data.subarray(i + 4, i + 8));\n      end = size > 1 ? i + size : data.byteLength; // parse type-specific data\n\n      box = (parse[type] || function (data) {\n        return {\n          data: data\n        };\n      })(data.subarray(i + 8, end));\n\n      box.size = size;\n      box.type = type; // store this box and move to the next\n\n      result.push(box);\n      i = end;\n    }\n\n    return result;\n  };\n  /**\n   * Returns a textual representation of the javascript represtentation\n   * of an MP4 file. You can use it as an alternative to\n   * JSON.stringify() to compare inspected MP4s.\n   * @param inspectedMp4 {array} the parsed array of boxes in an MP4\n   * file\n   * @param depth {number} (optional) the number of ancestor boxes of\n   * the elements of inspectedMp4. Assumed to be zero if unspecified.\n   * @return {string} a text representation of the parsed MP4\n   */\n\n\n  _textifyMp = function textifyMp4(inspectedMp4, depth) {\n    var indent;\n    depth = depth || 0;\n    indent = new Array(depth * 2 + 1).join(' '); // iterate over all the boxes\n\n    return inspectedMp4.map(function (box, index) {\n      // list the box type first at the current indentation level\n      return indent + box.type + '\\n' + // the type is already included and handle child boxes separately\n      Object.keys(box).filter(function (key) {\n        return key !== 'type' && key !== 'boxes'; // output all the box properties\n      }).map(function (key) {\n        var prefix = indent + '  ' + key + ': ',\n            value = box[key]; // print out raw bytes as hexademical\n\n        if (value instanceof Uint8Array || value instanceof Uint32Array) {\n          var bytes = Array.prototype.slice.call(new Uint8Array(value.buffer, value.byteOffset, value.byteLength)).map(function (byte) {\n            return ' ' + ('00' + byte.toString(16)).slice(-2);\n          }).join('').match(/.{1,24}/g);\n\n          if (!bytes) {\n            return prefix + '<>';\n          }\n\n          if (bytes.length === 1) {\n            return prefix + '<' + bytes.join('').slice(1) + '>';\n          }\n\n          return prefix + '<\\n' + bytes.map(function (line) {\n            return indent + '  ' + line;\n          }).join('\\n') + '\\n' + indent + '  >';\n        } // stringify generic objects\n\n\n        return prefix + JSON.stringify(value, null, 2).split('\\n').map(function (line, index) {\n          if (index === 0) {\n            return line;\n          }\n\n          return indent + '  ' + line;\n        }).join('\\n');\n      }).join('\\n') + ( // recursively textify the child boxes\n      box.boxes ? '\\n' + _textifyMp(box.boxes, depth + 1) : '');\n    }).join('\\n');\n  };\n\n  var mp4Inspector = {\n    inspect: inspectMp4,\n    textify: _textifyMp,\n    parseType: parseType_1,\n    findBox: findBox_1,\n    parseTraf: parse.traf,\n    parseTfdt: parse.tfdt,\n    parseHdlr: parse.hdlr,\n    parseTfhd: parse.tfhd,\n    parseTrun: parse.trun,\n    parseSidx: parse.sidx\n  };\n\n  /**\n   * mux.js\n   *\n   * Copyright (c) Brightcove\n   * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n   */\n\n  var tagTypes = {\n    0x08: 'audio',\n    0x09: 'video',\n    0x12: 'metadata'\n  },\n      hex = function hex(val) {\n    return '0x' + ('00' + val.toString(16)).slice(-2).toUpperCase();\n  },\n      hexStringList = function hexStringList(data) {\n    var arr = [],\n        i;\n\n    while (data.byteLength > 0) {\n      i = 0;\n      arr.push(hex(data[i++]));\n      data = data.subarray(i);\n    }\n\n    return arr.join(' ');\n  },\n      parseAVCTag = function parseAVCTag(tag, obj) {\n    var avcPacketTypes = ['AVC Sequence Header', 'AVC NALU', 'AVC End-of-Sequence'],\n        compositionTime = tag[1] & parseInt('01111111', 2) << 16 | tag[2] << 8 | tag[3];\n    obj = obj || {};\n    obj.avcPacketType = avcPacketTypes[tag[0]];\n    obj.CompositionTime = tag[1] & parseInt('10000000', 2) ? -compositionTime : compositionTime;\n\n    if (tag[0] === 1) {\n      obj.nalUnitTypeRaw = hexStringList(tag.subarray(4, 100));\n    } else {\n      obj.data = hexStringList(tag.subarray(4));\n    }\n\n    return obj;\n  },\n      parseVideoTag = function parseVideoTag(tag, obj) {\n    var frameTypes = ['Unknown', 'Keyframe (for AVC, a seekable frame)', 'Inter frame (for AVC, a nonseekable frame)', 'Disposable inter frame (H.263 only)', 'Generated keyframe (reserved for server use only)', 'Video info/command frame'],\n        codecID = tag[0] & parseInt('00001111', 2);\n    obj = obj || {};\n    obj.frameType = frameTypes[(tag[0] & parseInt('11110000', 2)) >>> 4];\n    obj.codecID = codecID;\n\n    if (codecID === 7) {\n      return parseAVCTag(tag.subarray(1), obj);\n    }\n\n    return obj;\n  },\n      parseAACTag = function parseAACTag(tag, obj) {\n    var packetTypes = ['AAC Sequence Header', 'AAC Raw'];\n    obj = obj || {};\n    obj.aacPacketType = packetTypes[tag[0]];\n    obj.data = hexStringList(tag.subarray(1));\n    return obj;\n  },\n      parseAudioTag = function parseAudioTag(tag, obj) {\n    var formatTable = ['Linear PCM, platform endian', 'ADPCM', 'MP3', 'Linear PCM, little endian', 'Nellymoser 16-kHz mono', 'Nellymoser 8-kHz mono', 'Nellymoser', 'G.711 A-law logarithmic PCM', 'G.711 mu-law logarithmic PCM', 'reserved', 'AAC', 'Speex', 'MP3 8-Khz', 'Device-specific sound'],\n        samplingRateTable = ['5.5-kHz', '11-kHz', '22-kHz', '44-kHz'],\n        soundFormat = (tag[0] & parseInt('11110000', 2)) >>> 4;\n    obj = obj || {};\n    obj.soundFormat = formatTable[soundFormat];\n    obj.soundRate = samplingRateTable[(tag[0] & parseInt('00001100', 2)) >>> 2];\n    obj.soundSize = (tag[0] & parseInt('00000010', 2)) >>> 1 ? '16-bit' : '8-bit';\n    obj.soundType = tag[0] & parseInt('00000001', 2) ? 'Stereo' : 'Mono';\n\n    if (soundFormat === 10) {\n      return parseAACTag(tag.subarray(1), obj);\n    }\n\n    return obj;\n  },\n      parseGenericTag = function parseGenericTag(tag) {\n    return {\n      tagType: tagTypes[tag[0]],\n      dataSize: tag[1] << 16 | tag[2] << 8 | tag[3],\n      timestamp: tag[7] << 24 | tag[4] << 16 | tag[5] << 8 | tag[6],\n      streamID: tag[8] << 16 | tag[9] << 8 | tag[10]\n    };\n  },\n      inspectFlvTag = function inspectFlvTag(tag) {\n    var header = parseGenericTag(tag);\n\n    switch (tag[0]) {\n      case 0x08:\n        parseAudioTag(tag.subarray(11), header);\n        break;\n\n      case 0x09:\n        parseVideoTag(tag.subarray(11), header);\n        break;\n    }\n\n    return header;\n  },\n      inspectFlv = function inspectFlv(bytes) {\n    var i = 9,\n        // header\n    dataSize,\n        parsedResults = [],\n        tag; // traverse the tags\n\n    i += 4; // skip previous tag size\n\n    while (i < bytes.byteLength) {\n      dataSize = bytes[i + 1] << 16;\n      dataSize |= bytes[i + 2] << 8;\n      dataSize |= bytes[i + 3];\n      dataSize += 11;\n      tag = bytes.subarray(i, i + dataSize);\n      parsedResults.push(inspectFlvTag(tag));\n      i += dataSize + 4;\n    }\n\n    return parsedResults;\n  },\n      textifyFlv = function textifyFlv(flvTagArray) {\n    return JSON.stringify(flvTagArray, null, 2);\n  };\n\n  var flvInspector = {\n    inspectTag: inspectFlvTag,\n    inspect: inspectFlv,\n    textify: textifyFlv\n  };\n\n  var parsePid = function parsePid(packet) {\n    var pid = packet[1] & 0x1f;\n    pid <<= 8;\n    pid |= packet[2];\n    return pid;\n  };\n\n  var parsePayloadUnitStartIndicator = function parsePayloadUnitStartIndicator(packet) {\n    return !!(packet[1] & 0x40);\n  };\n\n  var parseAdaptionField = function parseAdaptionField(packet) {\n    var offset = 0; // if an adaption field is present, its length is specified by the\n    // fifth byte of the TS packet header. The adaptation field is\n    // used to add stuffing to PES packets that don't fill a complete\n    // TS packet, and to specify some forms of timing and control data\n    // that we do not currently use.\n\n    if ((packet[3] & 0x30) >>> 4 > 0x01) {\n      offset += packet[4] + 1;\n    }\n\n    return offset;\n  };\n\n  var parseType = function parseType(packet, pmtPid) {\n    var pid = parsePid(packet);\n\n    if (pid === 0) {\n      return 'pat';\n    } else if (pid === pmtPid) {\n      return 'pmt';\n    } else if (pmtPid) {\n      return 'pes';\n    }\n\n    return null;\n  };\n\n  var parsePat = function parsePat(packet) {\n    var pusi = parsePayloadUnitStartIndicator(packet);\n    var offset = 4 + parseAdaptionField(packet);\n\n    if (pusi) {\n      offset += packet[offset] + 1;\n    }\n\n    return (packet[offset + 10] & 0x1f) << 8 | packet[offset + 11];\n  };\n\n  var parsePmt = function parsePmt(packet) {\n    var programMapTable = {};\n    var pusi = parsePayloadUnitStartIndicator(packet);\n    var payloadOffset = 4 + parseAdaptionField(packet);\n\n    if (pusi) {\n      payloadOffset += packet[payloadOffset] + 1;\n    } // PMTs can be sent ahead of the time when they should actually\n    // take effect. We don't believe this should ever be the case\n    // for HLS but we'll ignore \"forward\" PMT declarations if we see\n    // them. Future PMT declarations have the current_next_indicator\n    // set to zero.\n\n\n    if (!(packet[payloadOffset + 5] & 0x01)) {\n      return;\n    }\n\n    var sectionLength, tableEnd, programInfoLength; // the mapping table ends at the end of the current section\n\n    sectionLength = (packet[payloadOffset + 1] & 0x0f) << 8 | packet[payloadOffset + 2];\n    tableEnd = 3 + sectionLength - 4; // to determine where the table is, we have to figure out how\n    // long the program info descriptors are\n\n    programInfoLength = (packet[payloadOffset + 10] & 0x0f) << 8 | packet[payloadOffset + 11]; // advance the offset to the first entry in the mapping table\n\n    var offset = 12 + programInfoLength;\n\n    while (offset < tableEnd) {\n      var i = payloadOffset + offset; // add an entry that maps the elementary_pid to the stream_type\n\n      programMapTable[(packet[i + 1] & 0x1F) << 8 | packet[i + 2]] = packet[i]; // move to the next table entry\n      // skip past the elementary stream descriptors, if present\n\n      offset += ((packet[i + 3] & 0x0F) << 8 | packet[i + 4]) + 5;\n    }\n\n    return programMapTable;\n  };\n\n  var parsePesType = function parsePesType(packet, programMapTable) {\n    var pid = parsePid(packet);\n    var type = programMapTable[pid];\n\n    switch (type) {\n      case streamTypes.H264_STREAM_TYPE:\n        return 'video';\n\n      case streamTypes.ADTS_STREAM_TYPE:\n        return 'audio';\n\n      case streamTypes.METADATA_STREAM_TYPE:\n        return 'timed-metadata';\n\n      default:\n        return null;\n    }\n  };\n\n  var parsePesTime = function parsePesTime(packet) {\n    var pusi = parsePayloadUnitStartIndicator(packet);\n\n    if (!pusi) {\n      return null;\n    }\n\n    var offset = 4 + parseAdaptionField(packet);\n\n    if (offset >= packet.byteLength) {\n      // From the H 222.0 MPEG-TS spec\n      // \"For transport stream packets carrying PES packets, stuffing is needed when there\n      //  is insufficient PES packet data to completely fill the transport stream packet\n      //  payload bytes. Stuffing is accomplished by defining an adaptation field longer than\n      //  the sum of the lengths of the data elements in it, so that the payload bytes\n      //  remaining after the adaptation field exactly accommodates the available PES packet\n      //  data.\"\n      //\n      // If the offset is >= the length of the packet, then the packet contains no data\n      // and instead is just adaption field stuffing bytes\n      return null;\n    }\n\n    var pes = null;\n    var ptsDtsFlags; // PES packets may be annotated with a PTS value, or a PTS value\n    // and a DTS value. Determine what combination of values is\n    // available to work with.\n\n    ptsDtsFlags = packet[offset + 7]; // PTS and DTS are normally stored as a 33-bit number.  Javascript\n    // performs all bitwise operations on 32-bit integers but javascript\n    // supports a much greater range (52-bits) of integer using standard\n    // mathematical operations.\n    // We construct a 31-bit value using bitwise operators over the 31\n    // most significant bits and then multiply by 4 (equal to a left-shift\n    // of 2) before we add the final 2 least significant bits of the\n    // timestamp (equal to an OR.)\n\n    if (ptsDtsFlags & 0xC0) {\n      pes = {}; // the PTS and DTS are not written out directly. For information\n      // on how they are encoded, see\n      // http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n\n      pes.pts = (packet[offset + 9] & 0x0E) << 27 | (packet[offset + 10] & 0xFF) << 20 | (packet[offset + 11] & 0xFE) << 12 | (packet[offset + 12] & 0xFF) << 5 | (packet[offset + 13] & 0xFE) >>> 3;\n      pes.pts *= 4; // Left shift by 2\n\n      pes.pts += (packet[offset + 13] & 0x06) >>> 1; // OR by the two LSBs\n\n      pes.dts = pes.pts;\n\n      if (ptsDtsFlags & 0x40) {\n        pes.dts = (packet[offset + 14] & 0x0E) << 27 | (packet[offset + 15] & 0xFF) << 20 | (packet[offset + 16] & 0xFE) << 12 | (packet[offset + 17] & 0xFF) << 5 | (packet[offset + 18] & 0xFE) >>> 3;\n        pes.dts *= 4; // Left shift by 2\n\n        pes.dts += (packet[offset + 18] & 0x06) >>> 1; // OR by the two LSBs\n      }\n    }\n\n    return pes;\n  };\n\n  var parseNalUnitType = function parseNalUnitType(type) {\n    switch (type) {\n      case 0x05:\n        return 'slice_layer_without_partitioning_rbsp_idr';\n\n      case 0x06:\n        return 'sei_rbsp';\n\n      case 0x07:\n        return 'seq_parameter_set_rbsp';\n\n      case 0x08:\n        return 'pic_parameter_set_rbsp';\n\n      case 0x09:\n        return 'access_unit_delimiter_rbsp';\n\n      default:\n        return null;\n    }\n  };\n\n  var videoPacketContainsKeyFrame = function videoPacketContainsKeyFrame(packet) {\n    var offset = 4 + parseAdaptionField(packet);\n    var frameBuffer = packet.subarray(offset);\n    var frameI = 0;\n    var frameSyncPoint = 0;\n    var foundKeyFrame = false;\n    var nalType; // advance the sync point to a NAL start, if necessary\n\n    for (; frameSyncPoint < frameBuffer.byteLength - 3; frameSyncPoint++) {\n      if (frameBuffer[frameSyncPoint + 2] === 1) {\n        // the sync point is properly aligned\n        frameI = frameSyncPoint + 5;\n        break;\n      }\n    }\n\n    while (frameI < frameBuffer.byteLength) {\n      // look at the current byte to determine if we've hit the end of\n      // a NAL unit boundary\n      switch (frameBuffer[frameI]) {\n        case 0:\n          // skip past non-sync sequences\n          if (frameBuffer[frameI - 1] !== 0) {\n            frameI += 2;\n            break;\n          } else if (frameBuffer[frameI - 2] !== 0) {\n            frameI++;\n            break;\n          }\n\n          if (frameSyncPoint + 3 !== frameI - 2) {\n            nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n\n            if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n              foundKeyFrame = true;\n            }\n          } // drop trailing zeroes\n\n\n          do {\n            frameI++;\n          } while (frameBuffer[frameI] !== 1 && frameI < frameBuffer.length);\n\n          frameSyncPoint = frameI - 2;\n          frameI += 3;\n          break;\n\n        case 1:\n          // skip past non-sync sequences\n          if (frameBuffer[frameI - 1] !== 0 || frameBuffer[frameI - 2] !== 0) {\n            frameI += 3;\n            break;\n          }\n\n          nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n\n          if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n            foundKeyFrame = true;\n          }\n\n          frameSyncPoint = frameI - 2;\n          frameI += 3;\n          break;\n\n        default:\n          // the current byte isn't a one or zero, so it cannot be part\n          // of a sync sequence\n          frameI += 3;\n          break;\n      }\n    }\n\n    frameBuffer = frameBuffer.subarray(frameSyncPoint);\n    frameI -= frameSyncPoint;\n    frameSyncPoint = 0; // parse the final nal\n\n    if (frameBuffer && frameBuffer.byteLength > 3) {\n      nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n\n      if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n        foundKeyFrame = true;\n      }\n    }\n\n    return foundKeyFrame;\n  };\n\n  var probe$1 = {\n    parseType: parseType,\n    parsePat: parsePat,\n    parsePmt: parsePmt,\n    parsePayloadUnitStartIndicator: parsePayloadUnitStartIndicator,\n    parsePesType: parsePesType,\n    parsePesTime: parsePesTime,\n    videoPacketContainsKeyFrame: videoPacketContainsKeyFrame\n  };\n\n  var handleRollover = timestampRolloverStream.handleRollover;\n  var probe = {};\n  probe.ts = probe$1;\n  probe.aac = utils;\n  var ONE_SECOND_IN_TS = clock.ONE_SECOND_IN_TS;\n  var MP2T_PACKET_LENGTH = 188,\n      // bytes\n  SYNC_BYTE = 0x47;\n  /**\n   * walks through segment data looking for pat and pmt packets to parse out\n   * program map table information\n   */\n\n  var parsePsi_ = function parsePsi_(bytes, pmt) {\n    var startIndex = 0,\n        endIndex = MP2T_PACKET_LENGTH,\n        packet,\n        type;\n\n    while (endIndex < bytes.byteLength) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n        // We found a packet\n        packet = bytes.subarray(startIndex, endIndex);\n        type = probe.ts.parseType(packet, pmt.pid);\n\n        switch (type) {\n          case 'pat':\n            pmt.pid = probe.ts.parsePat(packet);\n            break;\n\n          case 'pmt':\n            var table = probe.ts.parsePmt(packet);\n            pmt.table = pmt.table || {};\n            Object.keys(table).forEach(function (key) {\n              pmt.table[key] = table[key];\n            });\n            break;\n        }\n\n        startIndex += MP2T_PACKET_LENGTH;\n        endIndex += MP2T_PACKET_LENGTH;\n        continue;\n      } // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n\n\n      startIndex++;\n      endIndex++;\n    }\n  };\n  /**\n   * walks through the segment data from the start and end to get timing information\n   * for the first and last audio pes packets\n   */\n\n\n  var parseAudioPes_ = function parseAudioPes_(bytes, pmt, result) {\n    var startIndex = 0,\n        endIndex = MP2T_PACKET_LENGTH,\n        packet,\n        type,\n        pesType,\n        pusi,\n        parsed;\n    var endLoop = false; // Start walking from start of segment to get first audio packet\n\n    while (endIndex <= bytes.byteLength) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (bytes[startIndex] === SYNC_BYTE && (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n        // We found a packet\n        packet = bytes.subarray(startIndex, endIndex);\n        type = probe.ts.parseType(packet, pmt.pid);\n\n        switch (type) {\n          case 'pes':\n            pesType = probe.ts.parsePesType(packet, pmt.table);\n            pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n            if (pesType === 'audio' && pusi) {\n              parsed = probe.ts.parsePesTime(packet);\n\n              if (parsed) {\n                parsed.type = 'audio';\n                result.audio.push(parsed);\n                endLoop = true;\n              }\n            }\n\n            break;\n        }\n\n        if (endLoop) {\n          break;\n        }\n\n        startIndex += MP2T_PACKET_LENGTH;\n        endIndex += MP2T_PACKET_LENGTH;\n        continue;\n      } // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n\n\n      startIndex++;\n      endIndex++;\n    } // Start walking from end of segment to get last audio packet\n\n\n    endIndex = bytes.byteLength;\n    startIndex = endIndex - MP2T_PACKET_LENGTH;\n    endLoop = false;\n\n    while (startIndex >= 0) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (bytes[startIndex] === SYNC_BYTE && (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n        // We found a packet\n        packet = bytes.subarray(startIndex, endIndex);\n        type = probe.ts.parseType(packet, pmt.pid);\n\n        switch (type) {\n          case 'pes':\n            pesType = probe.ts.parsePesType(packet, pmt.table);\n            pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n            if (pesType === 'audio' && pusi) {\n              parsed = probe.ts.parsePesTime(packet);\n\n              if (parsed) {\n                parsed.type = 'audio';\n                result.audio.push(parsed);\n                endLoop = true;\n              }\n            }\n\n            break;\n        }\n\n        if (endLoop) {\n          break;\n        }\n\n        startIndex -= MP2T_PACKET_LENGTH;\n        endIndex -= MP2T_PACKET_LENGTH;\n        continue;\n      } // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n\n\n      startIndex--;\n      endIndex--;\n    }\n  };\n  /**\n   * walks through the segment data from the start and end to get timing information\n   * for the first and last video pes packets as well as timing information for the first\n   * key frame.\n   */\n\n\n  var parseVideoPes_ = function parseVideoPes_(bytes, pmt, result) {\n    var startIndex = 0,\n        endIndex = MP2T_PACKET_LENGTH,\n        packet,\n        type,\n        pesType,\n        pusi,\n        parsed,\n        frame,\n        i,\n        pes;\n    var endLoop = false;\n    var currentFrame = {\n      data: [],\n      size: 0\n    }; // Start walking from start of segment to get first video packet\n\n    while (endIndex < bytes.byteLength) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n        // We found a packet\n        packet = bytes.subarray(startIndex, endIndex);\n        type = probe.ts.parseType(packet, pmt.pid);\n\n        switch (type) {\n          case 'pes':\n            pesType = probe.ts.parsePesType(packet, pmt.table);\n            pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n            if (pesType === 'video') {\n              if (pusi && !endLoop) {\n                parsed = probe.ts.parsePesTime(packet);\n\n                if (parsed) {\n                  parsed.type = 'video';\n                  result.video.push(parsed);\n                  endLoop = true;\n                }\n              }\n\n              if (!result.firstKeyFrame) {\n                if (pusi) {\n                  if (currentFrame.size !== 0) {\n                    frame = new Uint8Array(currentFrame.size);\n                    i = 0;\n\n                    while (currentFrame.data.length) {\n                      pes = currentFrame.data.shift();\n                      frame.set(pes, i);\n                      i += pes.byteLength;\n                    }\n\n                    if (probe.ts.videoPacketContainsKeyFrame(frame)) {\n                      var firstKeyFrame = probe.ts.parsePesTime(frame); // PTS/DTS may not be available. Simply *not* setting\n                      // the keyframe seems to work fine with HLS playback\n                      // and definitely preferable to a crash with TypeError...\n\n                      if (firstKeyFrame) {\n                        result.firstKeyFrame = firstKeyFrame;\n                        result.firstKeyFrame.type = 'video';\n                      } else {\n                        // eslint-disable-next-line\n                        console.warn('Failed to extract PTS/DTS from PES at first keyframe. ' + 'This could be an unusual TS segment, or else mux.js did not ' + 'parse your TS segment correctly. If you know your TS ' + 'segments do contain PTS/DTS on keyframes please file a bug ' + 'report! You can try ffprobe to double check for yourself.');\n                      }\n                    }\n\n                    currentFrame.size = 0;\n                  }\n                }\n\n                currentFrame.data.push(packet);\n                currentFrame.size += packet.byteLength;\n              }\n            }\n\n            break;\n        }\n\n        if (endLoop && result.firstKeyFrame) {\n          break;\n        }\n\n        startIndex += MP2T_PACKET_LENGTH;\n        endIndex += MP2T_PACKET_LENGTH;\n        continue;\n      } // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n\n\n      startIndex++;\n      endIndex++;\n    } // Start walking from end of segment to get last video packet\n\n\n    endIndex = bytes.byteLength;\n    startIndex = endIndex - MP2T_PACKET_LENGTH;\n    endLoop = false;\n\n    while (startIndex >= 0) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n        // We found a packet\n        packet = bytes.subarray(startIndex, endIndex);\n        type = probe.ts.parseType(packet, pmt.pid);\n\n        switch (type) {\n          case 'pes':\n            pesType = probe.ts.parsePesType(packet, pmt.table);\n            pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n            if (pesType === 'video' && pusi) {\n              parsed = probe.ts.parsePesTime(packet);\n\n              if (parsed) {\n                parsed.type = 'video';\n                result.video.push(parsed);\n                endLoop = true;\n              }\n            }\n\n            break;\n        }\n\n        if (endLoop) {\n          break;\n        }\n\n        startIndex -= MP2T_PACKET_LENGTH;\n        endIndex -= MP2T_PACKET_LENGTH;\n        continue;\n      } // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n\n\n      startIndex--;\n      endIndex--;\n    }\n  };\n  /**\n   * Adjusts the timestamp information for the segment to account for\n   * rollover and convert to seconds based on pes packet timescale (90khz clock)\n   */\n\n\n  var adjustTimestamp_ = function adjustTimestamp_(segmentInfo, baseTimestamp) {\n    if (segmentInfo.audio && segmentInfo.audio.length) {\n      var audioBaseTimestamp = baseTimestamp;\n\n      if (typeof audioBaseTimestamp === 'undefined' || isNaN(audioBaseTimestamp)) {\n        audioBaseTimestamp = segmentInfo.audio[0].dts;\n      }\n\n      segmentInfo.audio.forEach(function (info) {\n        info.dts = handleRollover(info.dts, audioBaseTimestamp);\n        info.pts = handleRollover(info.pts, audioBaseTimestamp); // time in seconds\n\n        info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n        info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n      });\n    }\n\n    if (segmentInfo.video && segmentInfo.video.length) {\n      var videoBaseTimestamp = baseTimestamp;\n\n      if (typeof videoBaseTimestamp === 'undefined' || isNaN(videoBaseTimestamp)) {\n        videoBaseTimestamp = segmentInfo.video[0].dts;\n      }\n\n      segmentInfo.video.forEach(function (info) {\n        info.dts = handleRollover(info.dts, videoBaseTimestamp);\n        info.pts = handleRollover(info.pts, videoBaseTimestamp); // time in seconds\n\n        info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n        info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n      });\n\n      if (segmentInfo.firstKeyFrame) {\n        var frame = segmentInfo.firstKeyFrame;\n        frame.dts = handleRollover(frame.dts, videoBaseTimestamp);\n        frame.pts = handleRollover(frame.pts, videoBaseTimestamp); // time in seconds\n\n        frame.dtsTime = frame.dts / ONE_SECOND_IN_TS;\n        frame.ptsTime = frame.pts / ONE_SECOND_IN_TS;\n      }\n    }\n  };\n  /**\n   * inspects the aac data stream for start and end time information\n   */\n\n\n  var inspectAac_ = function inspectAac_(bytes) {\n    var endLoop = false,\n        audioCount = 0,\n        sampleRate = null,\n        timestamp = null,\n        frameSize = 0,\n        byteIndex = 0,\n        packet;\n\n    while (bytes.length - byteIndex >= 3) {\n      var type = probe.aac.parseType(bytes, byteIndex);\n\n      switch (type) {\n        case 'timed-metadata':\n          // Exit early because we don't have enough to parse\n          // the ID3 tag header\n          if (bytes.length - byteIndex < 10) {\n            endLoop = true;\n            break;\n          }\n\n          frameSize = probe.aac.parseId3TagSize(bytes, byteIndex); // Exit early if we don't have enough in the buffer\n          // to emit a full packet\n\n          if (frameSize > bytes.length) {\n            endLoop = true;\n            break;\n          }\n\n          if (timestamp === null) {\n            packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n            timestamp = probe.aac.parseAacTimestamp(packet);\n          }\n\n          byteIndex += frameSize;\n          break;\n\n        case 'audio':\n          // Exit early because we don't have enough to parse\n          // the ADTS frame header\n          if (bytes.length - byteIndex < 7) {\n            endLoop = true;\n            break;\n          }\n\n          frameSize = probe.aac.parseAdtsSize(bytes, byteIndex); // Exit early if we don't have enough in the buffer\n          // to emit a full packet\n\n          if (frameSize > bytes.length) {\n            endLoop = true;\n            break;\n          }\n\n          if (sampleRate === null) {\n            packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n            sampleRate = probe.aac.parseSampleRate(packet);\n          }\n\n          audioCount++;\n          byteIndex += frameSize;\n          break;\n\n        default:\n          byteIndex++;\n          break;\n      }\n\n      if (endLoop) {\n        return null;\n      }\n    }\n\n    if (sampleRate === null || timestamp === null) {\n      return null;\n    }\n\n    var audioTimescale = ONE_SECOND_IN_TS / sampleRate;\n    var result = {\n      audio: [{\n        type: 'audio',\n        dts: timestamp,\n        pts: timestamp\n      }, {\n        type: 'audio',\n        dts: timestamp + audioCount * 1024 * audioTimescale,\n        pts: timestamp + audioCount * 1024 * audioTimescale\n      }]\n    };\n    return result;\n  };\n  /**\n   * inspects the transport stream segment data for start and end time information\n   * of the audio and video tracks (when present) as well as the first key frame's\n   * start time.\n   */\n\n\n  var inspectTs_ = function inspectTs_(bytes) {\n    var pmt = {\n      pid: null,\n      table: null\n    };\n    var result = {};\n    parsePsi_(bytes, pmt);\n\n    for (var pid in pmt.table) {\n      if (pmt.table.hasOwnProperty(pid)) {\n        var type = pmt.table[pid];\n\n        switch (type) {\n          case streamTypes.H264_STREAM_TYPE:\n            result.video = [];\n            parseVideoPes_(bytes, pmt, result);\n\n            if (result.video.length === 0) {\n              delete result.video;\n            }\n\n            break;\n\n          case streamTypes.ADTS_STREAM_TYPE:\n            result.audio = [];\n            parseAudioPes_(bytes, pmt, result);\n\n            if (result.audio.length === 0) {\n              delete result.audio;\n            }\n\n            break;\n        }\n      }\n    }\n\n    return result;\n  };\n  /**\n   * Inspects segment byte data and returns an object with start and end timing information\n   *\n   * @param {Uint8Array} bytes The segment byte data\n   * @param {Number} baseTimestamp Relative reference timestamp used when adjusting frame\n   *  timestamps for rollover. This value must be in 90khz clock.\n   * @return {Object} Object containing start and end frame timing info of segment.\n   */\n\n\n  var inspect = function inspect(bytes, baseTimestamp) {\n    var isAacData = probe.aac.isLikelyAacData(bytes);\n    var result;\n\n    if (isAacData) {\n      result = inspectAac_(bytes);\n    } else {\n      result = inspectTs_(bytes);\n    }\n\n    if (!result || !result.audio && !result.video) {\n      return null;\n    }\n\n    adjustTimestamp_(result, baseTimestamp);\n    return result;\n  };\n\n  var tsInspector = {\n    inspect: inspect,\n    parseAudioPes_: parseAudioPes_\n  };\n\n  var muxjs = {\n    codecs: codecs,\n    mp4: mp4,\n    flv: flv,\n    mp2t: m2ts,\n    partial: partial\n  }; // include all the tools when the full library is required\n\n  muxjs.mp4.tools = mp4Inspector;\n  muxjs.flv.tools = flvInspector;\n  muxjs.mp2t.tools = tsInspector;\n  var lib = muxjs;\n\n  return lib;\n\n})));\n\n\n//# sourceURL=webpack://adserve/./node_modules/mux.js/dist/mux.js?");

/***/ }),

/***/ "./src/ads.js":
/*!********************!*\
  !*** ./src/ads.js ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _time_bus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./time-bus */ \"./src/time-bus.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"./src/utils.js\");\n/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./browser */ \"./src/browser.js\");\n/* harmony import */ var _gdpr__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./gdpr */ \"./src/gdpr.js\");\n/* harmony import */ var _usp__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./usp */ \"./src/usp.js\");\n/* harmony import */ var ads_manager__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ads-manager */ \"./node_modules/ads-manager/dist/ads-manager.es.js\");\n\n\n\n\n\n\n\nconst Ads = function(player, adContainer, options) {\n\n  this._player = player; // TODO:\n  this._adContainer = adContainer;\n  this._adsManager = null;\n  this._options = Object.assign({\n    desktop: {\n      inView: {\n        vastUrl: null,\n        interval: 5000, // Ad request interval after AdImpression\n        retryInterval: 10000 // Ad request retry interval after AdError\n      },\n      notInView: {\n        vastUrl: null,\n        interval: 15000,\n        retryInterval: 10000\n      }\n    },\n    mobile: {\n      inView: {\n        vastUrl: null,\n        interval: 5000, // Ad request interval after AdImpression\n        retryInterval: 10000 // Ad request retry interval after AdError\n      },\n      notInView: {\n        vastUrl: null,\n        interval: 15000,\n        retryInterval: 10000\n      }\n    },\n    gdpr: false, // if true check GDPR (EU)\n    usp: false, // if true check CCPA (US Privacy)\n    schain: null, // Supply Chain\n    customMacros: {} // Custom Macros\n  }, options);\n\n  this.lastAdHasError = false;\n  this.lastAdErrorRuntime = 0;\n  this.lastAdRequestRuntime = 0;\n  this.lastAdCompleteRuntime = 0;\n  this.isAdPlaying = false;\n\n  // GDPR\n  if(this._options.gdpr) {\n    _gdpr__WEBPACK_IMPORTED_MODULE_3__.lookupConsent();\n  }\n  // CCPA (US privacy)\n  if(this._options.usp) {\n    _usp__WEBPACK_IMPORTED_MODULE_4__.lookupConsent();\n  }\n\n  if(this._adContainer) {\n    // Initialize ads manager\n    this.initAdsManager();\n  }\n}\nAds.prototype.getInterval = function() {\n  if(this.lastAdHasError) {\n    // Retry ad interval\n    const retryAdInterval = this.getRetryInterval() * 1000;\n    const diff = this.lastAdErrorRuntime - this.lastAdRequestRuntime;\n    let newRetryAdInterval = 0;\n    if(diff < retryAdInterval) {\n      newRetryAdInterval = retryAdInterval - diff;\n    }\n    return (0,_utils__WEBPACK_IMPORTED_MODULE_1__.millisecondsToSeconds)(newRetryAdInterval);\n  }\n  // Ad interval\n  return this._player.visible()\n    ? (0,_utils__WEBPACK_IMPORTED_MODULE_1__.millisecondsToSeconds)(this.getInViewInterval())\n    : (0,_utils__WEBPACK_IMPORTED_MODULE_1__.millisecondsToSeconds)(this.getNotInViewInterval());\n}\nAds.prototype.getRetryInterval = function() {\n  return this._player.visible()\n    ? (0,_utils__WEBPACK_IMPORTED_MODULE_1__.millisecondsToSeconds)(this.getInViewRetryInterval())\n    : (0,_utils__WEBPACK_IMPORTED_MODULE_1__.millisecondsToSeconds)(this.getNotInViewRetryInterval());\n}\n// TODO:\nAds.prototype.getInViewInterval = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.inView.interval\n    : this._options.desktop.inView.interval;\n}\nAds.prototype.getNotInViewInterval = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.notInView.interval\n    : this._options.desktop.notInView.interval;\n}\nAds.prototype.getInViewRetryInterval = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.inView.retryInterval\n    : this._options.desktop.inView.retryInterval;\n}\nAds.prototype.getNotInViewRetryInterval = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.notInView.retryInterval\n    : this._options.desktop.notInView.retryInterval;\n}\nAds.prototype.getInViewVastUrl = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.inView.vastUrl\n    : this._options.desktop.inView.vastUrl;\n}\nAds.prototype.getNotInViewVastUrl = function() {\n  return _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET\n    ? this._options.mobile.notInView.vastUrl\n    : this._options.desktop.notInView.vastUrl;\n}\nAds.prototype.getVastUrl = function() {\n  return this._player.visible()\n    ? this.getInViewVastUrl()\n    : this.getNotInViewVastUrl();\n}\nAds.prototype.initAdsManager = function() {\n  this._adsManager = new ads_manager__WEBPACK_IMPORTED_MODULE_5__.AdsManager(this._adContainer);\n  console.log('AdsManager version is', this._adsManager.getVersion());\n\n  const handleAdError = (adError) => {\n    console.log('AdError', adError);\n\n    this.lastAdHasError = true;\n    this.isAdPlaying = false;\n    this.lastAdErrorRuntime = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getRunTime)();\n    this.lastAdCompleteRuntime = this.lastAdErrorRuntime;\n\n    if(this._adsManager) {\n      this._adsManager.destroy();\n    }\n\n    this._player._el.classList.remove('ads');\n    // If player paused, then play\n    if(this._player.paused()) {\n      this._player.play();\n    }\n  };\n\n  const handleAdStopped = () => {\n    // Resume player\n    this._player._el.classList.remove('ads');\n    if(!this._player.ended()) {\n      this._player.play();\n    }\n  };\n\n  // Subscribe for events\n  this._adsManager.addEventListener('AdError', handleAdError);\n  this._adsManager.addEventListener('AdsManagerLoaded', () => {\n    console.log('AdsManagerLoaded', this._player._videoSlot.clientWidth, this._player._videoSlot.clientHeight);\n    const width = this._player._videoSlot.clientWidth;\n    const height = this._player._videoSlot.clientHeight;\n    // TODO:\n    const viewMode = this.getViewMode(); // fullscreen\n    console.log('init > viewMode', viewMode);\n\n    try {\n      this._adsManager.init(width, height, viewMode);\n    } catch (adError) {\n      // Play the video without ads, if an error occurs\n      console.log('AdsManager could not initialize ad');\n      handleAdError(adError);\n    }\n\n  });\n  this._adsManager.addEventListener('AdLoaded', (adEvent) => {\n    console.log('AdLoaded');\n    if(adEvent.type === 'linear') {\n      try {\n        this._adsManager.start();\n      } catch (adError) {\n        // Play the video without ads, if an error occurs\n        console.log('AdsManager could not be started');\n        handleAdError(adError);\n      }\n    } else {\n      console.log('AdsManager > AdLoaded > ad is not linear');\n    }\n  });\n  this._adsManager.addEventListener('AdStarted', () => {\n    console.log('AdStarted');\n\n    // Pause player\n    this._player._el.classList.add('ads');\n    if(!this._player.paused()) {\n      this._player.pause();\n    }\n\n  });\n  this._adsManager.addEventListener('AdDurationChange', () => {\n    console.log('AdDurationChange', this._adsManager.getDuration());\n  });\n  this._adsManager.addEventListener('AdSizeChange', () => {\n    console.log('AdSizeChange');\n  });\n  this._adsManager.addEventListener('AdVideoStart', () => {\n    console.log('AdVideoStart');\n  });\n  this._adsManager.addEventListener('AdImpression', () => {\n    console.log('AdImpression');\n  });\n  this._adsManager.addEventListener('AdVideoFirstQuartile', () => {\n    console.log('AdVideoFirstQuartile');\n  });\n  this._adsManager.addEventListener('AdVideoMidpoint', () => {\n    console.log('AdVideoMidpoint');\n  });\n  this._adsManager.addEventListener('AdVideoThirdQuartile', () => {\n    console.log('AdVideoThirdQuartile');\n  });\n  this._adsManager.addEventListener('AdPaused', () => {\n    console.log('AdPaused');\n  });\n  this._adsManager.addEventListener('AdPlaying', () => {\n    console.log('AdPlaying');\n  });\n  this._adsManager.addEventListener('AdVideoComplete', () => {\n    console.log('AdVideoComplete');\n  });\n  this._adsManager.addEventListener('AdStopped', handleAdStopped);\n  this._adsManager.addEventListener('AdSkipped', handleAdStopped);\n  this._adsManager.addEventListener('AdClickThru', (url, id) => {\n    console.log('AdClickThru', url);\n  });\n  this._adsManager.addEventListener('AllAdsCompleted', () => {\n    console.log('AllAdsCompleted');\n    this.lastAdHasError = false;\n    this.isAdPlaying = false;\n    this.lastAdCompleteRuntime = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getRunTime)();\n\n    // TODO:\n\n  });\n\n  // Initialize time bus for intervals\n  _time_bus__WEBPACK_IMPORTED_MODULE_0__.addHandler(this.checkIfPlayAd.bind(this));\n}\nAds.prototype.checkIfPlayAd = function() {\n\n  /*\n  if(this.lastAdCompleteRuntime === 0 && !this._player.paused()) {\n    console.log('pre roll');\n    this.playAd();\n  }\n   */\n  if(_browser__WEBPACK_IMPORTED_MODULE_2__.IS_IOS && this._player.fullscreen()) {\n    return;\n  }\n\n  if((0,_utils__WEBPACK_IMPORTED_MODULE_1__.getRunTime)() - this.lastAdCompleteRuntime >= this.getInterval() * 1000\n    && !this.isAdPlaying\n    && !this._player.ended()\n    && !this._player.paused()) {\n    this.playAd();\n  }\n\n  return;\n}\nAds.prototype.getViewMode = function() {\n  return this._player.fullscreen() ? 'fullscreen' : 'normal'\n}\nAds.prototype.getSChain = function() {\n  return (0,_utils__WEBPACK_IMPORTED_MODULE_1__.serializeSupplyChain)(this._options.schain);\n}\nAds.prototype.populateCustomMacros = function(url) {\n  if(this._options.customMacros) {\n    Object.getOwnPropertyNames(this._options.customMacros).forEach((key) => {\n      // Find pattern [key] in the url\n      console.log('custom', key);\n      if(url.indexOf('[' + key + ']') != -1) {\n        try {\n          // Get the value from customMacros by key, replace the url pattern with the value\n          // and then put the value in customMacro[key] = value\n          const isFunc = typeof this._options.customMacros[key] == 'function';\n          const value = encodeURIComponent(isFunc ? this._options.customMacros[key]() : this._options.customMacros[key]);\n          url = url.replace(\n            new RegExp(`(?:\\\\[|%%)(${key})(?:\\\\]|%%)`, 'g'),\n            value\n          );\n          // Replace customMacros by key with value, if it was a function\n          if(isFunc) {\n            this._options.customMacros[key] = value;\n          }\n        } catch (e) {}\n      }\n    });\n  }\n  return url;\n}\nAds.prototype.getMacros = function() {\n  return {\n    'CACHEBUSTER': (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getCacheBuster)(), // random\n    'TIMESTAMP': (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getTimestamp)(), // UNIX timestamp\n    'HEIGHT': this._player._videoSlot.clientHeight,\n    'WIDTH': this._player._videoSlot.clientWidth,\n    'URL': encodeURIComponent((0,_utils__WEBPACK_IMPORTED_MODULE_1__.getUrl)()), // url\n    'DOMAIN': (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getHostname)((0,_utils__WEBPACK_IMPORTED_MODULE_1__.getUrl)()), // domain aka hostname\n    'USER_AGENT': encodeURIComponent(navigator.userAgent),\n    'DEVICE': _browser__WEBPACK_IMPORTED_MODULE_2__.IS_MOBILE_AND_TABLET ? 2 : 1, // device\n    'DNT': (navigator.doNotTrack == 'yes' || navigator.doNotTrack == '1' || navigator.msDoNotTrack == '1') ? 1 : 0, // do not track\n    'UTM': '', // TODO: utm params\n    'DURATION': this._player.getDuration(), // video duration length in seconds\n    'IS_VISIBLE': this._player.visible() ? 1 : 0, // is visible\n    'GDPR': this._options.gdpr ? (_gdpr__WEBPACK_IMPORTED_MODULE_3__.gdprApplies ? 1 : 0) : 0, // GDPR - A flag to indicate user is in the European Union and consent applies\n    'GDPR_CONSENT': this._options.gdpr ? _gdpr__WEBPACK_IMPORTED_MODULE_3__.getConsentString() : '', // GDPR_CONSENT - A consent string passed from various Consent Management Platforms (CMP's). Also accept numeric value for CTV consent.\n    'US_PRIVACY': this._options.usp ? _usp__WEBPACK_IMPORTED_MODULE_4__.getConsentString() : '', // CCPA - A mandatory string for all publishers in which they must pass the privacy consent for users from California\n    'SCHAIN': this.getSChain(), // supply chain object\n    'ABC': encodeURIComponent(this._player.getVariantName()) // ab test variant name\n  }\n}\nAds.prototype.playAd = function() {\n  if(this._adsManager) {\n    this.isAdPlaying = true;\n    this.lastAdRequestRuntime = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.getRunTime)();\n\n    // Request ad\n    this._adsManager.requestAds(this.populateCustomMacros((0,_utils__WEBPACK_IMPORTED_MODULE_1__.replaceMacrosValues)(this.getVastUrl(), this.getMacros())));\n  }\n}\nAds.prototype.resizeAd = function(width, height) {\n  console.log('resize > viewMode', this.getViewMode());\n  this._adsManager && this._adsManager.resize(width, height, this.getViewMode());\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Ads);\n\n\n//# sourceURL=webpack://adserve/./src/ads.js?");

/***/ }),

/***/ "./src/browser.js":
/*!************************!*\
  !*** ./src/browser.js ***!
  \************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IS_IPOD\": () => (/* binding */ IS_IPOD),\n/* harmony export */   \"IOS_VERSION\": () => (/* binding */ IOS_VERSION),\n/* harmony export */   \"IS_ANDROID\": () => (/* binding */ IS_ANDROID),\n/* harmony export */   \"ANDROID_VERSION\": () => (/* binding */ ANDROID_VERSION),\n/* harmony export */   \"IS_NATIVE_ANDROID\": () => (/* binding */ IS_NATIVE_ANDROID),\n/* harmony export */   \"IS_FIREFOX\": () => (/* binding */ IS_FIREFOX),\n/* harmony export */   \"IS_EDGE\": () => (/* binding */ IS_EDGE),\n/* harmony export */   \"IS_CHROME\": () => (/* binding */ IS_CHROME),\n/* harmony export */   \"CHROME_VERSION\": () => (/* binding */ CHROME_VERSION),\n/* harmony export */   \"IE_VERSION\": () => (/* binding */ IE_VERSION),\n/* harmony export */   \"IS_SAFARI\": () => (/* binding */ IS_SAFARI),\n/* harmony export */   \"IS_WINDOWS\": () => (/* binding */ IS_WINDOWS),\n/* harmony export */   \"TOUCH_ENABLED\": () => (/* binding */ TOUCH_ENABLED),\n/* harmony export */   \"IS_IPAD\": () => (/* binding */ IS_IPAD),\n/* harmony export */   \"IS_IPHONE\": () => (/* binding */ IS_IPHONE),\n/* harmony export */   \"IS_IOS\": () => (/* binding */ IS_IOS),\n/* harmony export */   \"IS_ANY_SAFARI\": () => (/* binding */ IS_ANY_SAFARI),\n/* harmony export */   \"IS_MOBILE_AND_TABLET\": () => (/* binding */ IS_MOBILE_AND_TABLET),\n/* harmony export */   \"IS_LIGHTHOUSE\": () => (/* binding */ IS_LIGHTHOUSE)\n/* harmony export */ });\nconst USER_AGENT = window.navigator && window.navigator.userAgent || '';\nconst webkitVersionMap = (/AppleWebKit\\/([\\d.]+)/i).exec(USER_AGENT);\nconst appleWebkitVersion = webkitVersionMap ? parseFloat(webkitVersionMap.pop()) : null;\n\nconst IS_IPOD = (/iPod/i).test(USER_AGENT);\n\nconst IOS_VERSION = (function() {\n  const match = USER_AGENT.match(/OS (\\d+)_/i);\n\n  if (match && match[1]) {\n    return match[1];\n  }\n  return null;\n}());\n\nconst IS_ANDROID = (/Android/i).test(USER_AGENT);\n\nconst ANDROID_VERSION = (function() {\n  // This matches Android Major.Minor.Patch versions\n  // ANDROID_VERSION is Major.Minor as a Number, if Minor isn't available, then only Major is returned\n  const match = USER_AGENT.match(/Android (\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))*/i);\n\n  if (!match) {\n    return null;\n  }\n\n  const major = match[1] && parseFloat(match[1]);\n  const minor = match[2] && parseFloat(match[2]);\n\n  if (major && minor) {\n    return parseFloat(match[1] + '.' + match[2]);\n  } else if (major) {\n    return major;\n  }\n  return null;\n}());\n\nconst IS_NATIVE_ANDROID = IS_ANDROID && ANDROID_VERSION < 5 && appleWebkitVersion < 537;\n\nconst IS_FIREFOX = (/Firefox/i).test(USER_AGENT);\n\nconst IS_EDGE = (/Edg/i).test(USER_AGENT);\n\nconst IS_CHROME = !IS_EDGE && ((/Chrome/i).test(USER_AGENT) || (/CriOS/i).test(USER_AGENT));\n\nconst CHROME_VERSION = (function() {\n  const match = USER_AGENT.match(/(Chrome|CriOS)\\/(\\d+)/);\n\n  if (match && match[2]) {\n    return parseFloat(match[2]);\n  }\n  return null;\n}());\n\nconst IE_VERSION = (function() {\n  const result = (/MSIE\\s(\\d+)\\.\\d/).exec(USER_AGENT);\n  let version = result && parseFloat(result[1]);\n\n  if (!version && (/Trident\\/7.0/i).test(USER_AGENT) && (/rv:11.0/).test(USER_AGENT)) {\n    // IE 11 has a different user agent string than other IE versions\n    version = 11.0;\n  }\n\n  return version;\n}());\n\nconst IS_SAFARI = (/Safari/i).test(USER_AGENT) && !IS_CHROME && !IS_ANDROID && !IS_EDGE;\n\nconst IS_WINDOWS = (/Windows/i).test(USER_AGENT);\n\nconst TOUCH_ENABLED = Boolean((\n  'ontouchstart' in window ||\n  window.navigator.maxTouchPoints ||\n  window.DocumentTouch && window.document instanceof window.DocumentTouch));\n\nconst IS_IPAD = (/iPad/i).test(USER_AGENT) ||\n  (IS_SAFARI && TOUCH_ENABLED && !(/iPhone/i).test(USER_AGENT));\n\nconst IS_IPHONE = (/iPhone/i).test(USER_AGENT) && !IS_IPAD;\n\nconst IS_IOS = IS_IPHONE || IS_IPAD || IS_IPOD;\n\nconst IS_ANY_SAFARI = (IS_SAFARI || IS_IOS) && !IS_CHROME;\n\nconst IS_MOBILE_AND_TABLET = (function() {\n  let check = false;\n  (function(userAgent) {\n    if(/(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(userAgent)\n      ||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(userAgent.substr(0,4))) check = true;\n  })(USER_AGENT);\n  return check;\n}());\n\nconst IS_LIGHTHOUSE = (function() {\n  return USER_AGENT.search(/lighthouse/i) >= 0;\n}());\n\n\n//# sourceURL=webpack://adserve/./src/browser.js?");

/***/ }),

/***/ "./src/controls.js":
/*!*************************!*\
  !*** ./src/controls.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Spinner\": () => (/* binding */ Spinner),\n/* harmony export */   \"Header\": () => (/* binding */ Header),\n/* harmony export */   \"Gradient\": () => (/* binding */ Gradient),\n/* harmony export */   \"Timeline\": () => (/* binding */ Timeline),\n/* harmony export */   \"PrevButton\": () => (/* binding */ PrevButton),\n/* harmony export */   \"PlayButton\": () => (/* binding */ PlayButton),\n/* harmony export */   \"NextButton\": () => (/* binding */ NextButton),\n/* harmony export */   \"VolumeButton\": () => (/* binding */ VolumeButton),\n/* harmony export */   \"Timer\": () => (/* binding */ Timer),\n/* harmony export */   \"BigPlayButton\": () => (/* binding */ BigPlayButton),\n/* harmony export */   \"FullscreenButton\": () => (/* binding */ FullscreenButton)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ \"./src/utils.js\");\n/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browser */ \"./src/browser.js\");\n\n\n\nfunction Spinner() {\n  const spinner = document.createElement('div');\n  spinner.classList.add('spinner');\n\n  this.render = () => spinner;\n}\n\nfunction Header() {\n  const header = document.createElement('div');\n  header.classList.add('header');\n\n  this.render = () => header;\n  this.setTitle = (text, url) => {\n    if(url) {\n      const link = document.createElement('a');\n      link.innerHTML = text;\n      link.href = url;\n      link.target = '_blank';\n      link.classList.add('title');\n      header.appendChild(link);\n    } else {\n      const title = document.createElement('span');\n      title.classList.add('title');\n      title.innerHTML = text;\n      header.appendChild(title);\n    }\n  }\n  this.hide = () => {\n    header.style.display = 'none';\n  }\n  this.show = () => {\n    header.style.display = 'block';\n  }\n}\n\nfunction Gradient() {\n  const gradient = document.createElement('div');\n  gradient.classList.add('gradient');\n\n  const gradientTop = document.createElement('div');\n  gradientTop.classList.add('gradient-top');\n  gradient.appendChild(gradientTop);\n\n  const gradientBottom = document.createElement('div');\n  gradientBottom.classList.add('gradient-bottom');\n  gradient.appendChild(gradientBottom);\n\n  this.render = () => gradient;\n  this.hide = () => {\n    gradient.style.display = 'none';\n  }\n  this.show = () => {\n    gradient.style.display = 'block';\n  }\n}\n\nfunction Timeline() {\n  const timeline = document.createElement('div');\n  timeline.classList.add('timeline');\n\n  // Timeline buffer\n  const timelineBuffer = document.createElement('div');\n  timelineBuffer.classList.add('timeline-buffer');\n  timeline.appendChild(timelineBuffer);\n\n  // Timeline progress\n  const timelineProgress = document.createElement('div');\n  timelineProgress.classList.add('timeline-progress');\n  const timeTooltip = document.createElement('div');\n  timeTooltip.innerHTML = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(0);\n  timeTooltip.classList.add('time-tooltip');\n  timelineProgress.appendChild(timeTooltip);\n\n  timeline.appendChild(timelineProgress);\n\n  // Events\n  this.onmousedown = null;\n  this.onmousemove = null;\n  this.onmouseup = null;\n\n  let totalDuration = 0;\n  // Seek\n  let newTime = 0;\n  let canMove = false;\n\n  const calculateDistance = (event) => {\n    const position = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.getPointerPosition)(timeline, event);\n    return position.x;\n  }\n\n  const handleMouseUp = (event) => {\n    const doc = timeline.ownerDocument;\n\n    // Slider inactive\n    timeline.classList.remove('sliding');\n    if(this.onmouseup\n      && typeof this.onmouseup === 'function') {\n      this.onmouseup();\n    }\n\n    canMove = false;\n\n    doc.removeEventListener('mousemove', handleMouseMove);\n    doc.removeEventListener('mouseup', handleMouseUp);\n    doc.removeEventListener('touchmove', handleMouseMove);\n    doc.removeEventListener('touchend', handleMouseUp);\n\n  }\n\n  const handleMouseMove = (event) => {\n    if(canMove) {\n      const distance = calculateDistance(event);\n      newTime = distance * totalDuration;\n      // Trigger onmousemove\n      if(this.onmousemove\n        && typeof this.onmousemove === 'function') {\n        // newTime > 0 ? (newTime > totalDuration ? totalDuration : newTime) : 0\n        this.onmousemove(newTime);\n      }\n    }\n  }\n\n  const handleMouseDown = (event) => {\n\n    const doc = timeline.ownerDocument;\n\n    if(event.type === 'mousedown') {\n      event.preventDefault();\n    }\n    // Stop event propagation to prevent double fire\n    //event.stopPropagation();\n    if(event.type === 'touchstart' && !_browser__WEBPACK_IMPORTED_MODULE_1__.IS_CHROME) {\n      if(event.cancelable) event.preventDefault();\n    }\n\n    // Slider active\n    timeline.classList.add('sliding');\n    if(this.onmousedown\n      && typeof this.onmousedown === 'function') {\n      this.onmousedown();\n    }\n\n    canMove = true;\n\n    doc.addEventListener('mousemove', handleMouseMove);\n    doc.addEventListener('mouseup', handleMouseUp);\n    doc.addEventListener('touchmove', handleMouseMove);\n    doc.addEventListener('touchend', handleMouseUp);\n\n    // Trigger mouseMove\n    handleMouseMove(event);\n  }\n\n  timeline.addEventListener('mousedown', handleMouseDown);\n  timeline.addEventListener('touchstart', handleMouseDown);\n  timeline.addEventListener('click', (event) => {\n    event.stopPropagation();\n    event.preventDefault();\n  });\n\n  this.render = () => timeline;\n  this.setDuration = (duration= 0) => {\n    totalDuration = duration;\n  }\n  this.updateProgress = (value) => {\n    value < 0 ? value = 0 : value > 1 && (value = 1), timelineProgress.style.width = 100 * value + '%'\n  }\n  this.updateTimeTooltip = (value) => {\n    timeTooltip.innerHTML = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(value);\n  }\n  this.updateBuffer = (value) => {\n    value < 0 ? value = 0 : value > 1 && (value = 1), timelineBuffer.style.width = 100 * value + '%'\n  }\n  this.hide = () => {\n    timeline.style.display = 'none';\n  }\n  this.show = () => {\n    timeline.style.display = 'block';\n  }\n}\n\nfunction PrevButton() {\n  const prevButton = document.createElement('button');\n  prevButton.classList.add('prev');\n\n  this.render = () => prevButton;\n  this.hide = () => {\n    prevButton.style.display = 'none';\n  }\n  this.show = () => {\n    prevButton.style.display = 'block';\n  }\n}\n\nfunction PlayButton() {\n  let isPlay = false;\n  const playButton = document.createElement('button');\n  playButton.classList.add('play');\n\n  // Events\n  this.onclick = null;\n\n  // Click\n  playButton.addEventListener('click', (event) => {\n    event.preventDefault();\n    event.stopPropagation();\n    // Trigger onclick\n    if(this.onclick\n      && typeof this.onclick === 'function') {\n      this.onclick(isPlay);\n    }\n  });\n\n  this.render = () => playButton;\n  this.setState = (hasPlay) => {\n    isPlay = hasPlay;\n    if(isPlay) {\n      playButton.classList.add('pause');\n    } else {\n      playButton.classList.remove('pause');\n    }\n  }\n  this.hide = () => {\n    playButton.style.display = 'none';\n  }\n  this.show = () => {\n    playButton.style.display = 'block';\n  }\n}\n\nfunction NextButton() {\n  const nextButton = document.createElement('button');\n  nextButton.classList.add('next');\n\n  this.render = () => nextButton;\n  this.hide = () => {\n    nextButton.style.display = 'none';\n  }\n  this.show = () => {\n    nextButton.style.display = 'block';\n  }\n}\n\nfunction VolumeButton() {\n  let isMuted = false;\n  const volumeButton = document.createElement('div');\n  volumeButton.classList.add('volume');\n\n  // Events\n  this.onclick = null;\n\n  // Click\n  volumeButton.addEventListener('click', (event) => {\n    event.preventDefault();\n    event.stopPropagation();\n    // Trigger onclick\n    if(this.onclick\n      && typeof this.onclick === 'function') {\n      this.onclick(isMuted);\n    }\n  });\n\n  this.render = () => volumeButton;\n  this.setState = (hasMuted) => {\n    isMuted = hasMuted;\n    if(isMuted) {\n      volumeButton.classList.add('muted');\n    } else {\n      volumeButton.classList.remove('muted');\n    }\n  }\n  this.hide = () => {\n    volumeButton.style.display = 'none';\n  }\n  this.show = () => {\n    volumeButton.style.display = 'block';\n  }\n}\n\nfunction Timer() {\n  const timer = document.createElement('div');\n  timer.classList.add('timer');\n  timer.innerHTML = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(0);\n\n  this.render = () => timer;\n  let totalDuration = 0;\n  let currentTimeElapsed = 0;\n  this.setDuration = (duration= 0) => {\n    totalDuration = duration;\n    timer.innerHTML = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(currentTimeElapsed) + ' / ' + (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(totalDuration);\n  }\n  this.updateTimeElapsed = (timeElapsed = 0) => {\n    currentTimeElapsed = timeElapsed;\n    timer.innerHTML = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(currentTimeElapsed) + ' / ' + (0,_utils__WEBPACK_IMPORTED_MODULE_0__.toHHMMSS)(totalDuration);\n  }\n  this.hide = () => {\n    timer.style.display = 'none';\n  }\n  this.show = () => {\n    timer.style.display = 'show';\n  }\n}\n\nfunction BigPlayButton() {\n  const bigPlayButton = document.createElement('div');\n  bigPlayButton.classList.add('big-play');\n\n  this.render = () => bigPlayButton;\n  this.hide = () => {\n    bigPlayButton.style.display = 'none';\n  }\n  this.show = () => {\n    bigPlayButton.style.display = 'block';\n  }\n}\n\nfunction FullscreenButton() {\n  let isFullscreen = false;\n  const fullscreenButton = document.createElement('button');\n  fullscreenButton.classList.add('fullscreen');\n\n  // Events\n  this.onclick = null;\n\n  // Click\n  fullscreenButton.addEventListener('click', (event) => {\n    event.preventDefault();\n    event.stopPropagation();\n    // Trigger onclick\n    if(this.onclick\n      && typeof this.onclick === 'function') {\n      this.onclick(isFullscreen);\n    }\n  });\n\n  this.render = () => fullscreenButton;\n  this.setState = (hasFullscreen) => {\n    isFullscreen = hasFullscreen;\n    if(isFullscreen) {\n      fullscreenButton.classList.add('off');\n    } else {\n      fullscreenButton.classList.remove('off');\n    }\n  }\n  this.hide = () => {\n    fullscreenButton.style.display = 'none';\n  }\n  this.show = () => {\n    fullscreenButton.style.display = 'block';\n  }\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/controls.js?");

/***/ }),

/***/ "./src/event-bus.js":
/*!**************************!*\
  !*** ./src/event-bus.js ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ EventBus)\n/* harmony export */ });\nclass EventBus {\n  constructor() {\n    this.listeners = {};\n  }\n  on(type, listener) {\n    if(!this.listeners[type]) {\n      this.listeners[type] = [];\n    }\n    this.listeners[type].push(listener);\n  }\n  off(type, listener) {\n    if(!this.listeners[type]) {\n      return false;\n    }\n\n    const index = this.listeners[type].indexOf(listener);\n\n    // TODO: which is better?\n    // we slice listener functions\n    // on trigger so that it does not mess up the order\n    // while we loop through.\n    //\n    // Here we slice on off so that the loop in trigger\n    // can continue using it's old reference to loop without\n    // messing up the order.\n    this.listeners[type] = this.listeners[type].slice(0);\n    this.listeners[type].splice(index, 1);\n    return index > -1;\n  }\n  trigger(type) {\n    const callbacks = this.listeners[type];\n\n    if(!callbacks) {\n      return;\n    }\n\n    // Slicing the arguments on every invocation of this method\n    // can add a significant amount of overhead. Avoid the\n    // intermediate object creation for the common case of a\n    // single callback argument\n    if(arguments.length === 2) {\n      const length = callbacks.length;\n\n      for(let i = 0; i < length; ++i) {\n        callbacks[i].call(this, arguments[1]);\n      }\n    } else {\n      const args = Array.prototype.slice.call(arguments, 1);\n      const length = callbacks.length;\n\n      for(let i = 0; i < length; ++i) {\n        callbacks[i].apply(this, args);\n      }\n    }\n  }\n  dispose() {\n    this.listeners = {};\n  }\n  pipe(destination) {\n    this.on('data', function(data) {\n      destination.push(data);\n    });\n  }\n}\n\n\n//# sourceURL=webpack://adserve/./src/event-bus.js?");

/***/ }),

/***/ "./src/gdpr.js":
/*!*********************!*\
  !*** ./src/gdpr.js ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"lookupConsent\": () => (/* binding */ lookupConsent),\n/* harmony export */   \"getConsentString\": () => (/* binding */ getConsentString),\n/* harmony export */   \"gdprApplies\": () => (/* binding */ gdprApplies)\n/* harmony export */ });\n// GDPR\nlet gdprApplies;\nlet consentString = '';\nlet triesLeft = 5;\nconst cmpCallbacks = {};\n// version 2.0\n\nfunction lookupConsent() {\n  consentString = '';\n  if(!window.__tcfapi && window !== window.top) {\n    let frame = window;\n    let cmpFrame;\n    while (!cmpFrame) {\n      try {\n        if(frame.frames['__tcfapiLocator']) cmpFrame = frame;\n      } catch (e) {}\n\n      if(frame === window.top) break;\n      frame = frame.parent;\n    }\n\n    window.__tcfapi = function(cmd, version, callback, arg) {\n      if(!cmpFrame) {\n        callback({ msg: 'CMP not found' }, false);\n      } else {\n        const callId = Math.random() + '';\n        const msg = {\n          __tcfapiCall: {\n            command: cmd,\n            parameter: arg,\n            version,\n            callId\n          }\n        };\n\n        cmpCallbacks[callId] = callback;\n        cmpFrame.postMessage(msg, '*');\n      }\n    }\n\n    window.addEventListener('message', function(event) {\n      let data;\n      if(typeof event.data === 'string') {\n        try {\n          data = JSON.parse(event.data);\n        } catch (e) {}\n      } else {\n        data = event.data;\n      }\n\n      if(data && data.__tcfapiReturn) {\n        const r = data.__tcfapiReturn;\n        if(r && cmpCallbacks.hasOwnProperty(r.callId)) {\n          try {\n            cmpCallbacks[r.callId](\n              r.returnValue,\n              r.success\n            );\n            delete cmpCallbacks[r.callId];\n          } catch (e) {}\n        }\n      }\n\n    });\n\n  }\n\n  if(typeof window.__tcfapi !== 'function') {\n    if(triesLeft-- > 0) {\n      window.setTimeout(lookupConsent, 1200);\n    } else {\n      // There's no CMP on the page\n      console.log('GDPR', 'There\\'s no CMP on the page');\n    }\n    return;\n  }\n\n  window.__tcfapi('ping', 2, (pingReturn, success) => {\n    if(success) {\n      console.log('GDPR', 'Ping', pingReturn);\n    }\n  });\n\n  window.__tcfapi('getTCData', 2, (tcData, success) => {\n    if(success) {\n      gdprApplies = tcData.gdprApplies;\n      consentString = tcData.tcString;\n      console.log('GDPR', tcData);\n    } else {\n      if(triesLeft-- == 0) {\n        // There's no CMP on the page\n        console.log('GDPR', 'There\\'s no CMP on the page');\n      } else {\n        window.setTimeout(lookupConsent, 1200);\n      }\n    }\n  });\n}\n\nfunction getConsentString() {\n  if(typeof consentString !== 'string') {\n    return '';\n  }\n  return consentString;\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/gdpr.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"tv\": () => (/* binding */ tv)\n/* harmony export */ });\n/* harmony import */ var _player__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./player */ \"./src/player.js\");\n\n\nconst tv = {\n  Player: _player__WEBPACK_IMPORTED_MODULE_0__.Player,\n  Players: _player__WEBPACK_IMPORTED_MODULE_0__.Players\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/index.js?");

/***/ }),

/***/ "./src/manifest.js":
/*!*************************!*\
  !*** ./src/manifest.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"parseManifest\": () => (/* binding */ parseManifest),\n/* harmony export */   \"setupMediaPlaylist\": () => (/* binding */ setupMediaPlaylist),\n/* harmony export */   \"setupMediaPlaylists\": () => (/* binding */ setupMediaPlaylists),\n/* harmony export */   \"forEachMediaGroup\": () => (/* binding */ forEachMediaGroup),\n/* harmony export */   \"addPropertiesToMaster\": () => (/* binding */ addPropertiesToMaster),\n/* harmony export */   \"masterForMedia\": () => (/* binding */ masterForMedia)\n/* harmony export */ });\n/* harmony import */ var m3u8_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! m3u8-parser */ \"./node_modules/m3u8-parser/dist/m3u8-parser.es.js\");\n/* harmony import */ var mux_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! mux.js */ \"./node_modules/mux.js/dist/mux.js\");\n/* harmony import */ var mux_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(mux_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils */ \"./src/utils.js\");\n/* harmony import */ var _playlist__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./playlist */ \"./src/playlist.js\");\n\n\n\n\n\nconst parseManifest = ({\n manifestString,\n customTagParsers = [],\n customTagMappers = [],\n experimentalLLHLS\n}) => {\n  const parser = new m3u8_parser__WEBPACK_IMPORTED_MODULE_0__.Parser();\n\n  customTagParsers.forEach(customParser => parser.addParser(customParser));\n  customTagMappers.forEach(mapper => parser.addTagMapper(mapper));\n\n  parser.push(manifestString);\n  parser.end();\n\n  const manifest = parser.manifest;\n\n  // remove llhls features from the parsed manifest\n  // if we don't want llhls support.\n  if (!experimentalLLHLS) {\n    [\n      'preloadSegment',\n      'skip',\n      'serverControl',\n      'renditionReports',\n      'partInf',\n      'partTargetDuration'\n    ].forEach(function(k) {\n      if (manifest.hasOwnProperty(k)) {\n        delete manifest[k];\n      }\n    });\n\n    if (manifest.segments) {\n      manifest.segments.forEach(function(segment) {\n        ['parts', 'preloadHints'].forEach(function(k) {\n          if (segment.hasOwnProperty(k)) {\n            delete segment[k];\n          }\n        });\n      });\n    }\n  }\n  if(!manifest.targetDuration) {\n    let targetDuration = 10;\n    if(manifest.segments && manifest.segments.length) {\n      targetDuration = manifest.segments.reduce((acc, s) => Math.max(acc, s.duration), 0);\n    }\n    console.log('manifest has no targetDuration defaulting to', targetDuration);\n    manifest.targetDuration = targetDuration;\n  }\n\n  const parts = (0,_playlist__WEBPACK_IMPORTED_MODULE_3__.getLastParts)(manifest);\n  console.log(parts);\n  if(parts.length && !manifest.partTargetDuration) {\n    const partTargetDuration = parts.reduce((acc, p) => Math.max(acc, p.duration), 0);\n    console.log('manifest has no partTargetDuration defaulting to', partTargetDuration);\n    manifest.partTargetDuration = partTargetDuration;\n  }\n\n  return manifest;\n}\n\nconst createPlaylistId = (index, uri) => {\n  return `${index}-${uri}`;\n};\n\nconst setupMediaPlaylist = ({ playlist, uri, id }) => {\n  playlist.id = id;\n  playlist.playlistErrors_ = 0;\n\n  if (uri) {\n    // For media playlists, m3u8-parser does not have access to a URI, as HLS media\n    // playlists do not contain their own source URI, but one is needed for consistency in\n    // VHS.\n    playlist.uri = uri;\n  }\n\n  // For HLS master playlists, even though certain attributes MUST be defined, the\n  // stream may still be played without them.\n  // For HLS media playlists, m3u8-parser does not attach an attributes object to the\n  // manifest.\n  //\n  // To avoid undefined reference errors through the project, and make the code easier\n  // to write/read, add an empty attributes object for these cases.\n  playlist.attributes = playlist.attributes || {};\n}\n\nconst setupMediaPlaylists = (master) => {\n  let i = master.playlists.length;\n\n  while (i--) {\n    const playlist = master.playlists[i];\n\n    setupMediaPlaylist({\n      playlist,\n      id: createPlaylistId(i, playlist.uri)\n    });\n    playlist.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_2__.resolveUrl)(master.uri, playlist.uri);\n    master.playlists[playlist.id] = playlist;\n    // URI reference added for backwards compatibility\n    master.playlists[playlist.uri] = playlist;\n\n    // Although the spec states an #EXT-X-STREAM-INF tag MUST have a BANDWIDTH attribute,\n    // the stream can be played without it. Although an attributes property may have been\n    // added to the playlist to prevent undefined references, issue a warning to fix the\n    // manifest.\n    if (!playlist.attributes.BANDWIDTH) {\n      console.log('Invalid playlist STREAM-INF detected. Missing BANDWIDTH attribute.');\n    }\n  }\n}\n\nconst forEachMediaGroup = (master, callback) => {\n  if (!master.mediaGroups) {\n    return;\n  }\n  ['AUDIO', 'SUBTITLES'].forEach((mediaType) => {\n    if (!master.mediaGroups[mediaType]) {\n      return;\n    }\n    for (const groupKey in master.mediaGroups[mediaType]) {\n      for (const labelKey in master.mediaGroups[mediaType][groupKey]) {\n        const mediaProperties = master.mediaGroups[mediaType][groupKey][labelKey];\n\n        callback(mediaProperties, mediaType, groupKey, labelKey);\n      }\n    }\n  });\n};\n\nconst addPropertiesToMaster = (master, uri) => {\n  master.uri = uri;\n\n  for (let i = 0; i < master.playlists.length; i++) {\n    if (!master.playlists[i].uri) {\n      // Set up phony URIs for the playlists since playlists are referenced by their URIs\n      // throughout VHS, but some formats (e.g., DASH) don't have external URIs\n      // TODO: consider adding dummy URIs in mpd-parser\n      const phonyUri = `placeholder-uri-${i}`;\n\n      master.playlists[i].uri = phonyUri;\n    }\n  }\n  const audioOnlyMaster = (0,_playlist__WEBPACK_IMPORTED_MODULE_3__.isAudioOnly)(master);\n\n  forEachMediaGroup(master, (properties, mediaType, groupKey, labelKey) => {\n    const groupId = `placeholder-uri-${mediaType}-${groupKey}-${labelKey}`;\n\n    // add a playlist array under properties\n    if (!properties.playlists || !properties.playlists.length) {\n      // If the manifest is audio only and this media group does not have a uri, check\n      // if the media group is located in the main list of playlists. If it is, don't add\n      // placeholder properties as it shouldn't be considered an alternate audio track.\n      if (audioOnlyMaster && mediaType === 'AUDIO' && !properties.uri) {\n        for (let i = 0; i < master.playlists.length; i++) {\n          const p = master.playlists[i];\n\n          if (p.attributes && p.attributes.AUDIO && p.attributes.AUDIO === groupKey) {\n            return;\n          }\n        }\n      }\n\n      properties.playlists = [Object.assign({}, properties)];\n    }\n\n    properties.playlists.forEach(function(p, i) {\n      const id = createPlaylistId(i, groupId);\n\n      if (p.uri) {\n        p.resolvedUri = p.resolvedUri || (0,_utils__WEBPACK_IMPORTED_MODULE_2__.resolveUrl)(master.uri, p.uri);\n      } else {\n        // DEPRECATED, this has been added to prevent a breaking change.\n        // previously we only ever had a single media group playlist, so\n        // we mark the first playlist uri without prepending the index as we used to\n        // ideally we would do all of the playlists the same way.\n        p.uri = i === 0 ? groupId : id;\n\n        // don't resolve a placeholder uri to an absolute url, just use\n        // the placeholder again\n        p.resolvedUri = p.uri;\n      }\n\n      p.id = p.id || id;\n\n      // add an empty attributes object, all playlists are\n      // expected to have this.\n      p.attributes = p.attributes || {};\n\n      // setup ID and URI references (URI for backwards compatibility)\n      master.playlists[p.id] = p;\n      master.playlists[p.uri] = p;\n    });\n\n  });\n\n  setupMediaPlaylists(master);\n  resolveMediaGroupUris(master);\n}\n\nconst resolveMediaGroupUris = (master) => {\n  forEachMediaGroup(master, (properties) => {\n    if (properties.uri) {\n      properties.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_2__.resolveUrl)(master.uri, properties.uri);\n    }\n  });\n}\n\nconst masterForMedia = (media, uri) => {\n  const id = createPlaylistId(0, uri);\n  const master = {\n    mediaGroups: {\n      'AUDIO': {},\n      'VIDEO': {},\n      'CLOSED-CAPTIONS': {},\n      'SUBTITLES': {}\n    },\n    uri: window.location.href,\n    resolvedUri: window.location.href,\n    playlists: [{\n      uri,\n      id,\n      resolvedUri: uri,\n      // m3u8-parser does not attach an attributes property to media playlists so make\n      // sure that the property is attached to avoid undefined reference errors\n      attributes: {}\n    }]\n  };\n\n  // set up ID reference\n  master.playlists[id] = master.playlists[0];\n  // URI reference added for backwards compatibility\n  master.playlists[uri] = master.playlists[0];\n\n  return master;\n};\n\n\n\n//# sourceURL=webpack://adserve/./src/manifest.js?");

/***/ }),

/***/ "./src/master-playlist-controller.js":
/*!*******************************************!*\
  !*** ./src/master-playlist-controller.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MasterPlaylistController\": () => (/* binding */ MasterPlaylistController)\n/* harmony export */ });\n/* harmony import */ var _event_bus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./event-bus */ \"./src/event-bus.js\");\n/* harmony import */ var _playlist_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./playlist-loader */ \"./src/playlist-loader.js\");\n\n\n\nclass MasterPlaylistController extends _event_bus__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor(options) {\n    super();\n\n    const {\n      src,\n      handleManifestRedirects,\n      withCredentials\n    } = options;\n\n    if (!src) {\n      throw new Error('A non-empty playlist URL or JSON manifest string is required');\n    }\n\n    this.withCredentials = withCredentials;\n    this._requestOptions = {\n      withCredentials,\n      handleManifestRedirects\n    };\n\n    this.mediaSource = new window.MediaSource();\n\n    this._handleDurationChange = this._handleDurationChange.bind(this);\n    this._handleSourceOpen = this._handleSourceOpen.bind(this);\n    this._handleSourceEnded = this._handleSourceEnded.bind(this);\n\n    this.mediaSource.addEventListener('durationchange', this._handleDurationChange);\n\n    // load the media source into the player\n    this.mediaSource.addEventListener('sourceopen', this._handleSourceOpen);\n    this.mediaSource.addEventListener('sourceended', this._handleSourceEnded);\n    // we don't have to handle sourceclose since dispose will handle termination of\n    // everything, and the MediaSource should not be detached without a proper disposal\n\n\n    // Playlist loader\n    this._masterPlaylistLoader = new _playlist_loader__WEBPACK_IMPORTED_MODULE_1__[\"default\"](src, this._requestOptions);\n    this._setupMasterPlaylistLoaderListeners();\n\n    // load\n    this._masterPlaylistLoader.load();\n  }\n  _handleDurationChange() {\n    console.log('durationchange');\n    this.trigger('durationchange');\n  }\n  _handleSourceOpen() {\n    console.log('sourceopen');\n    this.trigger('sourceopen');\n  }\n  _handleSourceEnded() {\n    console.log('sourceended');\n  }\n  _setupMasterPlaylistLoaderListeners() {\n    // subscribe for events\n    this._masterPlaylistLoader.on('loadedmetadata', () => {\n      console.log('player > loadedmetadata');\n      const media = this._masterPlaylistLoader.media();\n      const requestTimeout = (media.targetDuration * 1.5) * 1000;\n\n      // If we don't have any more available playlists, we don't want to\n      // timeout the request.\n      // TODO:\n\n      // if this isn't a live video and preload permits, start\n      // downloading segments\n      if(media.endList) {\n        console.log('not live');\n      }\n\n      console.log(media);\n      console.log(requestTimeout);\n\n      // segment loader\n\n\n    });\n\n    this._masterPlaylistLoader.on('loadedplaylist', () => {\n      console.log('player > loadedplaylist');\n    });\n  }\n}\n\n\n//# sourceURL=webpack://adserve/./src/master-playlist-controller.js?");

/***/ }),

/***/ "./src/player.js":
/*!***********************!*\
  !*** ./src/player.js ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Player\": () => (/* binding */ Player),\n/* harmony export */   \"Players\": () => (/* binding */ Players)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ \"./src/utils.js\");\n/* harmony import */ var _controls__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./controls */ \"./src/controls.js\");\n/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./browser */ \"./src/browser.js\");\n/* harmony import */ var _css_styles_css__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./css/styles.css */ \"./src/css/styles.css\");\n/* harmony import */ var _ads__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ads */ \"./src/ads.js\");\n/* harmony import */ var _master_playlist_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./master-playlist-controller */ \"./src/master-playlist-controller.js\");\n\n\n\n\n\n\n\n\nconst Player = function(el, options = {}, callback) {\n\n  if(!(el instanceof Element || el instanceof HTMLDocument)) {\n    throw new Error('player element is not defined');\n  }\n\n  // Player HTML element\n  this._el = el;\n  // Set paused\n  this._el.classList.add('paused');\n\n  this._slot = null;\n  this._videoSlot = null;\n\n  this._resizer = null;\n  this._ads = null;\n\n  // Play promise\n  this._playPromise = null;\n\n  // Gradient\n  this._gradient = null;\n  // Header\n  this._header = null;\n  // Spinner\n  this._spinner = null;\n  // Big Play\n  this._bigPlayButton = null;\n\n  // Control Bar\n  this._controlBar = null;\n  // Controls\n  this._timeline = null;\n  this._prevButton = null;\n  this._playButton = null;\n  this._nextButton = null;\n  this._timer = null;\n  this._fullscreenButton = null;\n\n  // Attributes\n  this._attributes = {\n    variantName: '',\n    sessionId: (0,_utils__WEBPACK_IMPORTED_MODULE_0__.generateSessionId)(),\n    isReady: false,\n    userActive: false,\n    userActivity: false,\n    aspectRatioPercentage: null,\n    poster: null,\n    src: null,\n    duration: 0,\n    remainingTime: 0,\n    currentTime: 0,\n    waitingTime: 0,\n    muted: true,\n    volume: 0,\n    get hidden() {\n      return document.hidden;\n    },\n    fullscreen : false,\n    visibilityThreshold: 50, // 50%\n    intersectionRatio: 1,\n    get visible() {\n      if(this.hidden) {\n        return false;\n      } else if(this.fullscreen) {\n        return true;\n      }\n      return (0,_utils__WEBPACK_IMPORTED_MODULE_0__.visible)(this.intersectionRatio, this.visibilityThreshold);\n    },\n    prevVisible: true,\n    inactivityTimeout: 2000,\n    version: '1.0.3'\n  };\n\n  // Options\n  this._options = Object.assign({\n    width: 'auto',\n    height: 'auto',\n    aspectRatio: '16:9', // '16:9', '9:16', '4:3', '1:1'\n    title: null,\n    url: null,\n    poster: null,\n    src: null,\n    sources: null,\n    autoplay: false, // false, true, 'muted', 'play', 'any'\n    preload: 'metadata', // 'none', 'auto', 'metadata'\n    loop: false,\n    playbackRates: null,\n    muted: true,\n    volume: 1,\n    controls: true,\n    inactivityTimeout: 2000,\n    stickyFloating: false,\n    textTracks: null, // closed captions, subtitles\n    ads: null, // ads\n    timeRanges: null,\n    abTest: null //  ab test\n  }, options);\n\n  // Check AB test\n  if(this._options.abTest\n    && this._options.abTest.enabled\n    && this._options.abTest.hasOwnProperty('variants')) {\n\n    let selectedVariant = null;\n\n    const createVariantRanges = function(abTestOptions) {\n      const ranges = [];\n      let lastRange = 0;\n      if(abTestOptions) {\n        abTestOptions.variants.forEach((variant) => {\n          lastRange += variant.percentage;\n          ranges.push(lastRange);\n        });\n      }\n      return { ranges, lastRange };\n    }\n\n    const randomSelectVariants = function(abTestOptions, ranges, lastRange) {\n      let variant = null;\n      const random = Math.round(Math.random() * lastRange);\n      for(let i = 0; i < ranges.length; i++) {\n        if(random <= ranges[i]) {\n          variant = abTestOptions.variants[i];\n          break;\n        }\n      }\n      return variant;\n    }\n\n    const selectVariantByName = function(abTestOptions, variantName) {\n      let variant = null;\n      const abTestVariants = abTestOptions.variants;\n      if(variantName) {\n        variant = abTestVariants.find((currentVariant) => currentVariant.name == variantName)\n      }\n      return variant;\n    }\n    // Check for external variant name\n    let externalVariantName = null;\n\n    // Query String\n    if((0,_utils__WEBPACK_IMPORTED_MODULE_0__.isQueryStringContains)('ab_test_variant_name')) {\n      externalVariantName = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.getQueryStringValue)('ab_test_variant_name');\n    }\n    if(externalVariantName) {\n      selectedVariant = selectVariantByName(this._options.abTest, externalVariantName);\n    } else {\n      const { ranges, lastRange } = createVariantRanges(this._options.abTest);\n      selectedVariant = randomSelectVariants(this._options.abTest, ranges, lastRange);\n    }\n\n    if(selectedVariant) {\n      this._attributes.variantName = selectedVariant.name;\n      // Merge select variant options into the options\n      this._options = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.mergeObjects)(this._options, selectedVariant.options);\n    }\n\n  }\n\n  // Set attributes\n  // Muted\n  this._attributes.muted = this._options.muted;\n  this._attributes.volume = this._attributes.muted ? 0 : this._options.volume;\n  if(!this._attributes.muted && this._attributes.volume == 0) {\n    this._attributes.muted = true;\n  }\n  // Autoplay 'muted'\n  if(this._options.autoplay === 'muted') {\n    this._attributes.muted = true;\n    this._attributes.volume = 0;\n  }\n  // Aspect ratio\n  this._attributes.aspectRatioPercentage = _utils__WEBPACK_IMPORTED_MODULE_0__.ASPECT_RATIOS[this._options.aspectRatio];\n  if(this._attributes.aspectRatioPercentage) {\n    (0,_utils__WEBPACK_IMPORTED_MODULE_0__.injectStyle)(`adserve-tv-player-${this._attributes.sessionId}`,\n      `.adserve-tv-player-${this._attributes.sessionId} .video-container {\n        padding-bottom: ${this._attributes.aspectRatioPercentage}\n      }`\n    )\n  }\n  // Inactivity Timeout\n  if(this._options.inactivityTimeout) {\n    this._attributes.inactivityTimeout = this._options.inactivityTimeout;\n  }\n\n  // Time Ranges\n  if(this._options.timeRanges\n    && this._options.timeRanges.length != 0) {\n    const ranges = this._options.timeRanges.filter(item => item.enabled);\n    if(!ranges.length) return;\n\n    const parseTime = (time) => {\n      if(!time) return NaN;\n      const tokens = time.split(':');\n      //console.log(tokens);\n      return (\n        parseInt(tokens[0] || '0') * 3600 +\n        parseInt(tokens[1] || '0') * 60 +\n        parseInt(tokens[2] || '0')\n      );\n    }\n\n    setInterval(() => {\n      const date = new Date();\n      const hours = date.getUTCHours();\n      const minutes = date.getUTCMinutes();\n      const seconds = date.getUTCSeconds();\n      //console.log(hours, minutes, seconds);\n      const time = hours * 3600 + minutes * 60 + seconds;\n      //console.log(time);\n\n      const range = ranges.find((item) => {\n        const from = parseTime(item.range[0]);\n        const to = parseTime(item.range[1]);\n        if(!isNaN(from) && !isNaN(to)) {\n          if(from <= to) {\n            return time >= from && time <= to;\n          }\n          return time <= to || time >= from;\n        }\n      });\n\n      if(range) {\n        console.log(range);\n      }\n\n    }, 1000);\n  }\n\n  this.EVENTS = {\n    PlayerReady: 'PlayerReady',\n    PlayerVisibilityChange: 'PlayerVisibilityChange',\n    PlayerFullscreenChange: 'PlayerFullscreenChange',\n    PlayerVolumeChange: 'PlayerVolumeChange',\n    PlayerVideoPlaying: 'PlayerVideoPlaying',\n    PlayerVideoPaused: 'PlayerVideoPaused',\n    PlayerVideoComplete: 'PlayerVideoComplete',\n    PlayerUserActive: 'PlayerUserActive',\n    PlayerUserInactive: 'PlayerUserInactive',\n    PlayerResize: 'PlayerResize',\n    PlayerError: 'PlayerError'\n  }\n\n  this._callback = callback;\n  this._eventCallbacks = {};\n\n  // Observe visibility\n  (0,_utils__WEBPACK_IMPORTED_MODULE_0__.observeVisibility)(this._el, (intersectionEntries) => {\n    const { intersectionRatio } = intersectionEntries[intersectionEntries.length - 1];\n    this._attributes.intersectionRatio = intersectionRatio;\n    this.onVisibilityChange();\n  });\n\n  // Tab change, document hidden\n  // TODO: 1 time\n  document.addEventListener('visibilitychange', () => {\n    this.onVisibilityChange();\n  });\n\n  // Create slot\n  this.createSlot();\n\n}\nPlayer.prototype.createSlot = function() {\n  this._slot = document.createElement('div');\n  this._slot.classList.add('video-container');\n  this._el.classList.add('adserve-tv-player');\n  // Add classname with session id\n  this._el.classList.add('adserve-tv-player-' + this._attributes.sessionId);\n  this._el.appendChild(this._slot);\n  // Width and Height\n  if(this._options.width !== 'auto'\n    || this._options.height !== 'auto') {\n    this._el.style.width = (typeof this._options.width === 'number') ? this._options.width + 'px' : this._options.width;\n    this._el.style.height = (typeof this._options.height === 'number') ? this._options.height + 'px' : this._options.height;\n  }\n\n  this.createVideoSlot();\n}\nPlayer.prototype.createVideoSlot = function() {\n  this._videoSlot = document.createElement('video');\n  this._videoSlot.setAttribute('webkit-playsinline', true);\n  this._videoSlot.setAttribute('playsinline', true);\n  // x-webkit-airplay=\"allow\"\n  this._videoSlot.setAttribute('preload', this._options.preload); // none, auto, metadata\n  this._videoSlot.setAttribute('tabindex', -1);\n  this._videoSlot.style.backgroundColor = 'rgb(0, 0, 0)'; // TODO: remove\n  this._videoSlot.classList.add('video');\n\n  if(this._attributes.muted) {\n    this._videoSlot.muted = true;\n  }\n  // Append video slot\n  this._slot.appendChild(this._videoSlot);\n\n  // Fullscreen change\n  // iOS\n  if(_browser__WEBPACK_IMPORTED_MODULE_2__.IS_IOS) {\n    this._videoSlot.addEventListener('webkitbeginfullscreen', () => {\n      this.onFullscreenChange();\n    });\n    this._videoSlot.addEventListener('webkitendfullscreen', () => {\n      this.onFullscreenChange();\n    });\n  } else {\n    document.addEventListener('fullscreenchange', () => {\n      this.onFullscreenChange();\n    });\n    document.addEventListener('webkitfullscreenchange', () => {\n      this.onFullscreenChange();\n    });\n    document.addEventListener('mozfullscreenchange', () => {\n      this.onFullscreenChange();\n    });\n  }\n\n  // Create resizer\n  this._resizer = document.createElement('iframe');\n  this._resizer.classList.add('resizer');\n  this._resizer.setAttribute('allowtransparency', true);\n\n  this._slot.appendChild(this._resizer);\n\n  this._resizer.contentWindow.onresize = this.onResize.bind(this);\n\n  // Create overlay\n  this.createOverlay();\n  // Set source\n  this.setSrc(this._options.src);\n  // Poster\n  this.setPoster(this._options.poster);\n\n  // User Active\n  this.userActive(true);\n  this.listenForUserActivity();\n\n  // Sticky Floating\n  if(this._options.stickyFloating) {\n    const position = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.findPosition)(this._el);\n    const handleScroll = () => {\n      if(window.scrollY > (position.top + position.height)) {\n        this._el.classList.add('sticky');\n      } else {\n        this._el.classList.remove('sticky');\n      }\n    }\n    window.addEventListener('scroll', handleScroll);\n  }\n\n  // TODO:\n  window.setTimeout(() => {\n    this._attributes.isReady = true;\n    Players.push(this);\n    // Player ready callback\n    if(this._callback\n      && typeof this._callback === 'function') {\n      this._callback();\n    }\n\n    // Ads\n    if(this._options.ads && this._options.ads.enabled && !_browser__WEBPACK_IMPORTED_MODULE_2__.IS_LIGHTHOUSE) {\n      this.createAdContainer();\n    } else {\n      console.log('no ads');\n    }\n\n    this.onPlayerReady();\n  }, 75);\n\n}\nPlayer.prototype.createAdContainer = function() {\n  const adContainer = document.createElement('div');\n  adContainer.classList.add('ad-container');\n  this._slot.appendChild(adContainer);\n\n  // Initialize ads\n  this._ads = new _ads__WEBPACK_IMPORTED_MODULE_4__[\"default\"](this, adContainer, this._options.ads);\n\n}\nPlayer.prototype.userActive = function(isActive) {\n  if(isActive === undefined) {\n    return this._attributes.userActive;\n  }\n\n  isActive = !!isActive;\n\n  if(isActive === this._attributes.userActive) {\n    return;\n  }\n\n  this._attributes.userActive = isActive;\n\n  if(this._attributes.userActive) {\n    this._attributes.userActivity = true;\n    this._el.classList.remove('user-inactive');\n    this._el.classList.add('user-active');\n    // Trigger onUserActive\n    this.onUserActive();\n    return;\n  }\n\n  // Chrome/Safari/IE have bugs where when you change the cursor it can\n  // trigger a mousemove event. This causes an issue when you're hiding\n  // the cursor when the user is inactive, and a mousemove signals user\n  // activity. Making it impossible to go into inactive mode. Specifically\n  // this happens in fullscreen when we really need to hide the cursor.\n  this._el.addEventListener('mousemove', (event) => {\n    event.stopPropagation();\n    event.preventDefault();\n  }, { once: true });\n\n  this._attributes.userActivity = false;\n  this._el.classList.remove('user-active');\n  this._el.classList.add('user-inactive');\n\n  // Trigger onUserInactive\n  this.onUserInactive();\n}\nPlayer.prototype.reportUserActivity = function() {\n  this._attributes.userActivity = true;\n}\nPlayer.prototype.listenForUserActivity = function() {\n  let mouseInProgress;\n  let lastMoveX;\n  let lastMoveY;\n\n  const handleActivity = this.reportUserActivity.bind(this);\n\n  const handleMouseMove = (event) => {\n    if(event.screenX !== lastMoveX || event.screenY !== lastMoveY) {\n      lastMoveX = event.screenX;\n      lastMoveY = event.screenY;\n      handleActivity();\n    }\n  };\n\n  const handleMouseDown = () => {\n    handleActivity();\n    // For as long as they are touching the device or have their mouse down,\n    // we consider them active even if they're not moving their finger or mouse.\n    // So we want to continue to update that they are active\n    window.clearInterval(mouseInProgress);\n    // Setting userActivity=true now and setting the interval to the same time\n    // as the activityCheck interval (250) should ensure we never miss the\n    // next activityCheck\n    mouseInProgress = window.setInterval(handleActivity, 250);\n  };\n\n  const handleMouseUpAndMouseLeave = () => {\n    handleActivity();\n    // Stop the interval that maintains activity if the mouse/touch is down\n    window.clearInterval(mouseInProgress);\n  };\n\n  // Any mouse movement will be considered user activity\n  this._el.addEventListener('mousedown', handleMouseDown);\n  this._el.addEventListener('mousemove', handleMouseMove);\n  this._el.addEventListener('mouseup', handleMouseUpAndMouseLeave);\n  this._el.addEventListener('mouseleave', handleMouseUpAndMouseLeave);\n\n  // control bar would no longer be hidden by default timeout.\n  if(this._controlBar && !_browser__WEBPACK_IMPORTED_MODULE_2__.IS_IOS && !_browser__WEBPACK_IMPORTED_MODULE_2__.IS_ANDROID) {\n    this._controlBar.addEventListener('mouseenter', () => {\n      this._options.inactivityTimeout = 0;\n    });\n    this._controlBar.addEventListener('mouseleave', () => {\n      this._options.inactivityTimeout = this._attributes.inactivityTimeout;\n    });\n  }\n\n  // Run an interval every 250 milliseconds instead of stuffing everything into\n  // the mousemove/touchmove function itself, to prevent performance degradation.\n  let inactivityTimeout;\n\n  window.setInterval(() => {\n    // Check to see if mouse/touch activity has happened\n    if(!this._attributes.userActivity) {\n      return;\n    }\n\n    // Reset the activity tracker\n    this._attributes.userActivity = false;\n    // If the user state was inactive, set the state to active\n    this.userActive(true);\n    // Clear any existing inactivity timeout to start the timer over\n    window.clearTimeout(inactivityTimeout);\n\n    const timeout = this._options.inactivityTimeout;\n\n    if(timeout <= 0) {\n      return;\n    }\n\n    // In <timeout> milliseconds, if no more activity has occurred the\n    // user will be considered inactive\n    inactivityTimeout = window.setTimeout(() => {\n      // Protect against the case where the inactivityTimeout can trigger just\n      // before the next user activity is picked up by the activity check loop\n      // causing a flicker\n      if(!this._attributes.userActivity) {\n        this.userActive(false);\n      }\n    }, timeout);\n\n  }, 250);\n\n}\nPlayer.prototype.createOverlay = function() {\n\n  // Overlay\n  const overlay = document.createElement('div');\n  overlay.classList.add('overlay');\n\n  // Gradient\n  this._gradient = new _controls__WEBPACK_IMPORTED_MODULE_1__.Gradient();\n  overlay.appendChild(this._gradient.render());\n\n  // Header\n  this._header = new _controls__WEBPACK_IMPORTED_MODULE_1__.Header();\n  overlay.appendChild(this._header.render());\n\n  // Spinner\n  this._spinner = new _controls__WEBPACK_IMPORTED_MODULE_1__.Spinner();\n  overlay.appendChild(this._spinner.render());\n\n  // Big Play\n  this._bigPlayButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.BigPlayButton();\n  overlay.appendChild(this._bigPlayButton.render());\n\n  if(this._options.controls) {\n\n    // Control Bar\n    this._controlBar = document.createElement('div');\n    this._controlBar.classList.add('control-bar');\n\n    // Timeline\n    this._timeline = new _controls__WEBPACK_IMPORTED_MODULE_1__.Timeline();\n    this._controlBar.appendChild(this._timeline.render());\n\n    // Controls\n    const controls = document.createElement('div');\n    controls.classList.add('controls');\n\n    // Prev Button\n    this._prevButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.PrevButton();\n    controls.appendChild(this._prevButton.render());\n    // TODO:\n    this._prevButton.hide();\n\n    // Play Button\n    this._playButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.PlayButton();\n    controls.appendChild(this._playButton.render());\n\n    // Next Button\n    this._nextButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.NextButton();\n    controls.appendChild(this._nextButton.render());\n    // TODO:\n    this._nextButton.hide();\n\n    // Volume Button\n    this._volumeButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.VolumeButton();\n    if (this._attributes.muted) {\n      this._volumeButton.setState(true);\n    } else {\n      console.log('is muted', this._attributes.muted, 'volume', this._attributes.volume)\n    }\n\n    controls.appendChild(this._volumeButton.render());\n\n    // Timer\n    this._timer = new _controls__WEBPACK_IMPORTED_MODULE_1__.Timer();\n    controls.appendChild(this._timer.render());\n\n    // Fullscreen Button\n    this._fullscreenButton = new _controls__WEBPACK_IMPORTED_MODULE_1__.FullscreenButton();\n    controls.appendChild(this._fullscreenButton.render());\n\n    // Append controls to control bar\n    this._controlBar.appendChild(controls);\n    // Append control bar to overlay\n    overlay.appendChild(this._controlBar);\n\n  }\n\n  this._el.appendChild(overlay);\n}\nPlayer.prototype.onResize = function() {\n  this._ads && this._ads.resizeAd(this._videoSlot.clientWidth, this._videoSlot.clientHeight);\n  this.onPlayerResize();\n}\nPlayer.prototype.onPlayerResize = function() {\n  if(this.EVENTS.PlayerResize in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerResize] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerResize]();\n    }\n  }\n}\nPlayer.prototype.onUserActive = function() {\n  this.onPlayerUserActive();\n}\nPlayer.prototype.onPlayerUserActive = function() {\n  if(this.EVENTS.PlayerUserActive in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerUserActive] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerUserActive]();\n    }\n  }\n}\nPlayer.prototype.onUserInactive = function() {\n  this.onPlayerUserInactive();\n}\nPlayer.prototype.onPlayerUserInactive = function() {\n  if(this.EVENTS.PlayerUserInactive in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerUserInactive] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerUserInactive]();\n    }\n  }\n}\nPlayer.prototype.onFullscreenChange = function() {\n  this._attributes.fullscreen = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.isFullscreen)(document, this._videoSlot);\n  this._fullscreenButton && this._fullscreenButton.setState(this._attributes.fullscreen);\n  this.onPlayerFullscreenChange(this._attributes.fullscreen);\n}\nPlayer.prototype.onPlayerFullscreenChange = function(fullscreen) {\n  if(this.EVENTS.PlayerFullscreenChange in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerFullscreenChange] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerFullscreenChange](fullscreen);\n    }\n  }\n}\nPlayer.prototype.onVisibilityChange = function() {\n  const value = this._attributes.visible;\n  const isVisibleChanged = this._attributes.prevVisible !== value;\n  if(isVisibleChanged) {\n    this._attributes.prevVisible = value;\n    this.onPlayerVisibilityChange(value);\n  }\n}\nPlayer.prototype.onPlayerReady = function() {\n  if(this.EVENTS.PlayerReady in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerReady] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerReady]();\n    }\n  }\n}\nPlayer.prototype.onPlayerVisibilityChange = function(visibility) {\n  if(this.EVENTS.PlayerVisibilityChange in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerVisibilityChange] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerVisibilityChange](visibility);\n    }\n  }\n}\nPlayer.prototype.onPlayerVolumeChange = function() {\n  if(this.EVENTS.PlayerVolumeChange in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerVolumeChange] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerVolumeChange]();\n    }\n  }\n}\nPlayer.prototype.onPlayerVideoPlaying = function() {\n  if(this.EVENTS.PlayerVideoPlaying in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerVideoPlaying] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerVideoPlaying]();\n    }\n  }\n}\nPlayer.prototype.onPlayerVideoPaused = function() {\n  if(this.EVENTS.PlayerVideoPaused in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerVideoPaused] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerVideoPaused]();\n    }\n  }\n}\nPlayer.prototype.onContentComplete = function() {\n  this._el.classList.add('ended');\n  if(this._options.loop) {\n    this.setCurrentTime(0);\n    this.play();\n  }\n  this.onPlayerVideoComplete();\n}\nPlayer.prototype.onPlayerVideoComplete = function() {\n  if(this.EVENTS.PlayerVideoComplete in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerVideoComplete] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerVideoComplete]();\n    }\n  }\n}\nPlayer.prototype.onPlayerError = function(message) {\n  if(this.EVENTS.PlayerError in this._eventCallbacks) {\n    if(typeof this._eventCallbacks[this.EVENTS.PlayerError] === 'function') {\n      this._eventCallbacks[this.EVENTS.PlayerError](message);\n    }\n  }\n}\nPlayer.prototype.addEventListener = function(eventName, callback, context) {\n  const giveCallback = callback.bind(context);\n  this._eventCallbacks[eventName] = giveCallback;\n}\nPlayer.prototype.removeEventListener = function(eventName) {\n  if(eventName in this._eventCallbacks) {\n    this._eventCallbacks[eventName] = null;\n  }\n}\nPlayer.prototype.setSrc = function(source) {\n\n  if(!source) {\n    return;\n  }\n\n  // Try to play source from options\n  if(source && typeof source === 'string') {\n    console.log('source exists', source);\n    // Set source, detect mime type by file extension\n    this._attributes.src = source;\n  }\n\n  if(this._attributes.src) {\n    this._attributes.mimeType = (0,_utils__WEBPACK_IMPORTED_MODULE_0__.getMimeType)(this._attributes.src);\n\n    console.log('play > source mime type is', this._attributes.mimeType);\n\n    // Check if HLS\n    if(this._attributes.mimeType === 'application/x-mpegurl'\n      && !(0,_utils__WEBPACK_IMPORTED_MODULE_0__.supportsNativeHls)()) {\n      console.log('source is HLS, this browser does not support it, requires HLS plugin');\n\n      //return;\n    }\n    // Check for MPEG-DASH\n    if(this._attributes.mimeType === 'application/dash+xml'\n      && !(0,_utils__WEBPACK_IMPORTED_MODULE_0__.supportsNativeDash)()) {\n      console.log('source is MPEG-DASH, this browser does not support it, requires MPEG-DASH plugin');\n\n      return;\n    }\n\n    // Attach events\n    this._videoSlot.addEventListener('loadstart', () => {\n      // Autoplay 'muted'\n      if(this._options.autoplay === 'muted') {\n        this.play();\n      }\n      // Autoplay 'play' or 'any'\n      if(this._options.autoplay === 'play'\n        || this._options.autoplay === 'any') {\n        this.play();\n      }\n    });\n\n    this._videoSlot.addEventListener('waiting', () => {\n      this._el.classList.add('waiting');\n      this._attributes.waitingTime = this.getCurrentTime();\n      const timeUpdateListener = () => {\n        if(this._attributes.waitingTime !== this.getCurrentTime()) {\n          this._el.classList.remove('waiting');\n          this._videoSlot.removeEventListener('timeupdate', timeUpdateListener);\n        }\n      }\n      this._videoSlot.addEventListener('timeupdate', timeUpdateListener);\n    });\n\n    this._videoSlot.addEventListener('canplay', () => {\n      this._el.classList.remove('waiting');\n    });\n\n    this._videoSlot.addEventListener('canplaythrough', () => {\n      this._el.classList.remove('waiting');\n    });\n\n    this._videoSlot.addEventListener('play', () => {\n      this._el.classList.remove('ended');\n      this._el.classList.remove('paused');\n      // Update play button\n      this._playButton && this._playButton.setState(true);\n      this.onPlayerVideoPlaying();\n    });\n\n    this._videoSlot.addEventListener('pause', () => {\n      this._el.classList.remove('ended');\n      this._el.classList.add('paused');\n      // Update play button\n      this._playButton && this._playButton.setState(false);\n      this.onPlayerVideoPaused();\n    });\n\n    this._videoSlot.addEventListener('volumechange', () => {\n      this._volumeButton && this._volumeButton.setState(!this.getVolume());\n      this.onPlayerVolumeChange();\n    });\n\n    this._videoSlot.addEventListener('progress', (event) => {\n      let range = 0;\n      const bf = event.target.buffered;\n      const time = event.target.currentTime;\n      try {\n        while (!(bf.start(range) <= time && time <= bf.end(range))) {\n          range += 1;\n        }\n        const loadStartPercentage = bf.start(range) / event.target.duration;\n        const loadEndPercentage = bf.end(range) / event.target.duration;\n        const loadPercentage = loadEndPercentage - loadStartPercentage;\n        // Update timeline buffer\n        this._timeline && this._timeline.updateBuffer(loadPercentage);\n      } catch (e) {}\n    });\n\n    this._videoSlot.addEventListener('timeupdate', (event) => {\n      const percentPlayed = event.target.currentTime * 100.0 / event.target.duration;\n      this._attributes.currentTime = event.target.currentTime;\n      this._attributes.remainingTime = event.target.duration - event.target.currentTime;\n\n      // Update timeline\n      if(this._timeline) {\n        this._timeline.updateProgress(event.target.currentTime > 0 && event.target.duration > 0 ? event.target.currentTime / event.target.duration : 0);\n        this._timeline.updateTimeTooltip(event.target.currentTime);\n      }\n      // Update timer\n      this._timer && this._timer.updateTimeElapsed(event.target.currentTime);\n\n    });\n\n    this._videoSlot.addEventListener('loadeddata', (event) => {\n      // TODO:\n    });\n\n    this._videoSlot.addEventListener('loadedmetadata', (event) => {\n      if(event.target.duration === Infinity) {\n        return;\n      }\n      this._attributes.duration = event.target.duration;\n      // Update timeline\n      this._timeline && this._timeline.setDuration(event.target.duration);\n      // Update timer\n      this._timer && this._timer.setDuration(event.target.duration);\n    });\n\n    this._videoSlot.addEventListener('durationchange', (event) => {\n      if(event.target.duration === Infinity) {\n        return;\n      }\n      this._attributes.duration = event.target.duration;\n      // Update timeline\n      this._timeline && this._timeline.setDuration(event.target.duration);\n      // Update timer\n      this._timer && this._timer.setDuration(event.target.duration);\n    });\n\n    this._videoSlot.addEventListener('ended', () => {\n      this._playButton && this._playButton.setState(false);\n      this.onContentComplete();\n    });\n\n    this._videoSlot.addEventListener('error', (event) => {\n      console.log('error - remove waiting');\n      console.log('error', event.target);\n      this._el.classList.remove('waiting');\n      this.pause();\n      this.onPlayerError('The media could not be loaded, either because the server or network failed or because the format is not supported.');\n    });\n\n\n\n\n    const masterPlaylistController = new _master_playlist_controller__WEBPACK_IMPORTED_MODULE_5__.MasterPlaylistController({\n      src: this._attributes.src\n    });\n    this._videoSlot.setAttribute('src', window.URL.createObjectURL(masterPlaylistController.mediaSource));\n\n    /*\n    // Set source\n    this._videoSlot.setAttribute('src', this._attributes.src);\n     */\n\n\n\n    // Autoplay\n    if(this._options.autoplay === true) {\n      this._videoSlot.setAttribute('autoplay', true);\n    }\n\n    // Set title\n    if(this._options.title) {\n      this._header && this._header.setTitle(this._options.title, this._options.url);\n    }\n\n    // Play button\n    if(this._playButton) {\n      this._playButton.onclick = () => {\n        if(!this.paused()) {\n          this.pause();\n        } else {\n          this.play();\n        }\n      }\n    }\n\n    // Timeline\n    if(this._timeline) {\n      // Seek\n      let videoWasPlaying = false;\n      this._timeline.onmousedown = () => {\n        // Slider active\n        this._el.classList.add('slider-active');\n        videoWasPlaying = !this.paused();\n        this.pause();\n      }\n      this._timeline.onmousemove = (newTime) => {\n        this.setCurrentTime(newTime);\n      }\n      this._timeline.onmouseup = () => {\n        // Slider inactive\n        this._el.classList.remove('slider-active');\n        if(videoWasPlaying && !this._videoSlot.ended) {\n          this.play();\n        }\n      }\n    }\n\n    // Volume button\n    if(this._volumeButton) {\n      this._volumeButton.onclick = () => {\n        if(!this.getVolume()) {\n          this.setVolume(1)\n        } else {\n          this.setVolume(0)\n        }\n      }\n    }\n\n    // Fullscreen button\n    if(this._fullscreenButton) {\n      this._fullscreenButton.onclick = () => {\n        if(this.fullscreen()) {\n          this.exitFullscreen()\n        } else {\n          this.requestFullscreen()\n        }\n      }\n    }\n\n  }\n\n  // TODO:\n  // String, source Object, Array of Source Objects\n  console.log('set > source', source);\n}\nPlayer.prototype.getCurrentSrc = function() {\n  return this._attributes.src;\n}\nPlayer.prototype.setPoster = function(poster) {\n  if(!poster) {\n    return\n  }\n  this._attributes.poster = poster\n  this._videoSlot.poster = this._attributes.poster;\n}\nPlayer.prototype.getPoster = function() {\n  return this._attributes.poster;\n}\nPlayer.prototype.play = function(source) {\n\n  if(source) {\n    // Try to play source from given source\n    this.setSrc(source);\n  }\n\n  if(this._videoSlot && this._attributes.src) {\n    if(this._videoSlot.paused) {\n      if(this._attributes.muted) {\n        this._videoSlot.muted = true;\n        this._videoSlot.volume = 0;\n        // Set attributes\n        this._attributes.muted = true;\n        this._attributes.volume = 0;\n      }\n      // Play\n      const maxPlayRetries = 3;\n      let playRetries = 0;\n      this._playPromise = this._videoSlot.play();\n      if(this._playPromise instanceof Promise) {\n        this._playPromise.then(() => {\n\n        }).catch((error) => {\n          // Play failed\n          console.log('play failed', error);\n          if(playRetries <= maxPlayRetries) {\n            if (this._options.autoplay === 'any') {\n              this._attributes.muted = true;\n              this._attributes.volume = 0;\n              this.play();\n            }\n            playRetries++;\n          }\n        });\n      }\n    }\n\n  } else {\n    // Error\n    console.log('source not exists');\n  }\n\n}\nPlayer.prototype.paused = function() {\n  return this._videoSlot ? this._videoSlot.paused : false;\n}\nPlayer.prototype.pause = function() {\n  if(this._videoSlot && !this._videoSlot.paused) {\n    this._videoSlot.pause();\n  }\n}\nPlayer.prototype.ended = function() {\n  return this._videoSlot ? this._videoSlot.ended : false;\n}\nPlayer.prototype.getVolume = function() {\n  return this._videoSlot ? (this._videoSlot.muted ? 0 : this._videoSlot.volume) : this._attributes.volume;\n}\nPlayer.prototype.setVolume = function(value) {\n  if(this._videoSlot) {\n    if (value) {\n      this._videoSlot.muted = false;\n      // Set attributes\n      this._attributes.muted = false;\n    } else {\n      this._videoSlot.muted = true;\n      // Set attributes\n      this._attributes.muted = true;\n    }\n    const isVolumeChanged = value !== this._videoSlot.volume;\n    if (isVolumeChanged) {\n      this._videoSlot.volume = value;\n      this._attributes.volume = value;\n    }\n  }\n}\nPlayer.prototype.readyState = function() {\n  return null;\n}\nPlayer.prototype.getDuration = function() {\n  return this._videoSlot && this._attributes.src ? this._attributes.duration : -1;\n}\nPlayer.prototype.getCurrentTime = function() {\n  return this._videoSlot && this._attributes.src ? this._attributes.currentTime : -1;\n}\nPlayer.prototype.setCurrentTime = function(seconds) {\n  if (typeof seconds !== 'undefined') {\n    if (seconds < 0) {\n      seconds = 0;\n    }\n    if (this._videoSlot && this._attributes.src) {\n      if(seconds != this._attributes.duration) {\n        this._el.classList.remove('ended');\n      }\n      this._videoSlot.currentTime = seconds;\n    }\n  }\n}\nPlayer.prototype.getRemainingTime = function() {\n  return this._videoSlot && this._attributes.src ? this._attributes.remainingTime : -1;\n}\nPlayer.prototype.visible = function() {\n  return this._attributes.visible;\n}\nPlayer.prototype.hidden = function() {\n  return this._attributes.hidden;\n}\nPlayer.prototype.fullscreen = function() {\n  return this._videoSlot && (0,_utils__WEBPACK_IMPORTED_MODULE_0__.isFullscreen)(document, this._videoSlot);\n}\nPlayer.prototype.requestFullscreen = function() {\n  if(this._videoSlot && this._attributes.src && !(0,_utils__WEBPACK_IMPORTED_MODULE_0__.isFullscreen)(document, this._videoSlot)) {\n    (0,_utils__WEBPACK_IMPORTED_MODULE_0__.requestFullscreen)(this._el, this._videoSlot);\n  }\n}\nPlayer.prototype.exitFullscreen = function() {\n  if(this._videoSlot && this._attributes.src && (0,_utils__WEBPACK_IMPORTED_MODULE_0__.isFullscreen)(document, this._videoSlot)) {\n    (0,_utils__WEBPACK_IMPORTED_MODULE_0__.existFullscreen)(document, this._videoSlot);\n  }\n}\nPlayer.prototype.getWidth = function() {\n  return this._el.clientWidth;\n}\nPlayer.prototype.getHeight = function() {\n  return this._el.clientHeight;\n}\nPlayer.prototype.getVariantName = function() {\n  return this._attributes.variantName;\n}\nPlayer.prototype.destroy = function() {\n  // TODO: destroy\n}\nPlayer.prototype.getSessionId = function() {\n  return this._attributes.sessionId;\n}\nPlayer.prototype.getVersion = function() {\n  return this._attributes.version;\n}\n\nlet Players = [{}];\n(function() {\n  Players = window.adserve && window.adserve.tv ? window.adserve.tv.Players : []\n})();\n\n\n\n\n//# sourceURL=webpack://adserve/./src/player.js?");

/***/ }),

/***/ "./src/playlist-loader.js":
/*!********************************!*\
  !*** ./src/playlist-loader.js ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ PlaylistLoader),\n/* harmony export */   \"refreshDelay\": () => (/* binding */ refreshDelay),\n/* harmony export */   \"updateSegment\": () => (/* binding */ updateSegment),\n/* harmony export */   \"updateSegments\": () => (/* binding */ updateSegments),\n/* harmony export */   \"resolveSegmentUris\": () => (/* binding */ resolveSegmentUris),\n/* harmony export */   \"getAllSegments\": () => (/* binding */ getAllSegments),\n/* harmony export */   \"isPlaylistUnchanged\": () => (/* binding */ isPlaylistUnchanged),\n/* harmony export */   \"updateMaster\": () => (/* binding */ updateMaster)\n/* harmony export */ });\n/* harmony import */ var _manifest__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./manifest */ \"./src/manifest.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"./src/utils.js\");\n/* harmony import */ var _playlist__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./playlist */ \"./src/playlist.js\");\n/* harmony import */ var _event_bus__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./event-bus */ \"./src/event-bus.js\");\n\n\n\n\n\nclass PlaylistLoader extends _event_bus__WEBPACK_IMPORTED_MODULE_3__[\"default\"] {\n  constructor(src, options = {}) {\n    super();\n\n    if(!src) {\n      throw new Error('A non-empty playlist URL or object is required');\n    }\n\n    console.log('> PlaylistLoader');\n    const { withCredentials = false, handleManifestRedirects = false } = options;\n\n    this.src = src;\n    this.withCredentials = withCredentials;\n    this.handleManifestRedirects = handleManifestRedirects;\n\n    this.experimentalLLHLS = false;\n\n    // initialize the loader state\n    this.state = 'HAVE_NOTHING';\n    this.master = {\n      uri: src,\n      playlists: []\n    }\n\n    // live playlist staleness timeout\n    this._handleMediaupdatetimeout = this._handleMediaupdatetimeout.bind(this);\n    this.on('mediaupdatetimeout', this._handleMediaupdatetimeout);\n  }\n  _handleMediaupdatetimeout() {\n    if (this.state !== 'HAVE_METADATA') {\n      // only refresh the media playlist if no other activity is going on\n      return;\n    }\n    const media = this.media();\n\n    let uri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(this.master.uri, media.uri);\n\n    if (this.experimentalLLHLS) {\n      uri = addLLHLSQueryDirectives(uri, media);\n    }\n    this.state = 'HAVE_CURRENT_METADATA';\n\n    this.request = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.xhr)({\n      uri,\n      withCredentials: this.withCredentials\n    }, (error, req) => {\n      // disposed\n      if (!this.request) {\n        return;\n      }\n\n      if (error) {\n        return this.playlistRequestError(this.request, this.media(), 'HAVE_METADATA');\n      }\n\n      this.haveMetadata({\n        playlistString: this.request.responseText,\n        url: this.media().uri,\n        id: this.media().id\n      });\n    });\n\n  }\n  playlistRequestError(xhr, playlist, startingState) {\n    const {\n      uri,\n      id\n    } = playlist;\n\n    // any in-flight request is now finished\n    this.request = null;\n\n    if (startingState) {\n      this.state = startingState;\n    }\n\n    this.error = {\n      playlist: this.master.playlists[id],\n      status: xhr.status,\n      message: `HLS playlist request error at URL: ${uri}.`,\n      responseText: xhr.responseText,\n      code: (xhr.status >= 500) ? 4 : 2\n    };\n\n    this.trigger('error');\n  }\n  _updateMediaUpdateTimeout(delay) {\n    if (this.mediaUpdateTimeout) {\n      window.clearTimeout(this.mediaUpdateTimeout);\n      this.mediaUpdateTimeout = null;\n    }\n\n    // we only have use mediaupdatetimeout for live playlists.\n    if (!this.media() || this.media().endList) {\n      return;\n    }\n\n    this.mediaUpdateTimeout = window.setTimeout(() => {\n      this.mediaUpdateTimeout = null;\n      this.trigger('mediaupdatetimeout');\n      this._updateMediaUpdateTimeout(delay);\n    }, delay);\n  }\n  dispose() {\n    this.trigger('dispose');\n    this.stopRequest();\n    window.clearTimeout(this.mediaUpdateTimeout);\n    window.clearTimeout(this.finalRenditionTimeout);\n\n    this.off();\n  }\n  stopRequest() {\n    if (this.request) {\n      const oldRequest = this.request;\n\n      this.request = null;\n      oldRequest.onreadystatechange = null;\n      oldRequest.abort();\n    }\n  }\n  start() {\n    this.started = true;\n\n    console.log('start');\n\n    // request the specified URL\n    this.request = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.xhr)({\n      uri: this.src,\n      withCredentials: this.withCredentials\n    }, (error, req) => {\n      // disposed\n      if (!this.request) {\n        return;\n      }\n\n      // clear the loader's request reference\n      this.request = null;\n\n      if (error) {\n        this.error = {\n          status: req.status,\n          message: `HLS playlist request error at URL: ${this.src}.`,\n          responseText: req.responseText,\n          // MEDIA_ERR_NETWORK\n          code: 2\n        };\n        if (this.state === 'HAVE_NOTHING') {\n          this.started = false;\n        }\n        return this.trigger('error');\n      }\n\n      this.src = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveManifestRedirect)(this.handleManifestRedirects, this.src, req);\n\n      const manifest = this._parseManifest({\n        manifestString: req.responseText,\n        url: this.src\n      });\n\n      this.setupInitialPlaylist(manifest);\n    });\n  }\n  pause() {\n    if (this.mediaUpdateTimeout) {\n      window.clearTimeout(this.mediaUpdateTimeout);\n      this.mediaUpdateTimeout = null;\n    }\n\n    this.stopRequest();\n    if (this.state === 'HAVE_NOTHING') {\n      // If we pause the loader before any data has been retrieved, its as if we never\n      // started, so reset to an unstarted state.\n      this.started = false;\n    }\n    // Need to restore state now that no activity is happening\n    if (this.state === 'SWITCHING_MEDIA') {\n      // if the loader was in the process of switching media, it should either return to\n      // HAVE_MASTER or HAVE_METADATA depending on if the loader has loaded a media\n      // playlist yet. This is determined by the existence of loader.media_\n      if (this._media) {\n        this.state = 'HAVE_METADATA';\n      } else {\n        this.state = 'HAVE_MASTER';\n      }\n    } else if (this.state === 'HAVE_CURRENT_METADATA') {\n      this.state = 'HAVE_METADATA';\n    }\n  }\n  load(shouldDelay) {\n    if (this.mediaUpdateTimeout) {\n      window.clearTimeout(this.mediaUpdateTimeout);\n      this.mediaUpdateTimeout = null;\n    }\n    const media = this.media();\n\n    if (shouldDelay) {\n      const delay = media ? ((media.partTargetDuration || media.targetDuration) / 2) * 1000 : 5 * 1000;\n\n      this.mediaUpdateTimeout = window.setTimeout(() => {\n        this.mediaUpdateTimeout = null;\n        this.load();\n      }, delay);\n\n      return;\n    }\n\n    if (!this.started) {\n      this.start();\n      return;\n    }\n\n    if (media && !media.endList) {\n      this.trigger('mediaupdatetimeout');\n    } else {\n      this.trigger('loadedplaylist');\n    }\n  }\n  _parseManifest({url, manifestString}) {\n    console.log('parse manifest', url);\n    return (0,_manifest__WEBPACK_IMPORTED_MODULE_0__.parseManifest)({\n      manifestString,\n      customTagParsers: [],\n      customTagMappers: [],\n      experimentalLLHLS: false\n    });\n  }\n  setupInitialPlaylist(manifest) {\n    this.state = 'HAVE_MASTER';\n\n    if(manifest.playlists) {\n      console.log('has playlists');\n      this.master = manifest;\n      console.log('master', this.master);\n      console.log('manifest', manifest);\n\n      (0,_manifest__WEBPACK_IMPORTED_MODULE_0__.addPropertiesToMaster)(this.master, this.src);\n\n      // If the initial master playlist has playlists wtih segments already resolved,\n      // then resolve URIs in advance, as they are usually done after a playlist request,\n      // which may not happen if the playlist is resolved.\n      manifest.playlists.forEach((playlist) => {\n        console.log('playlist', playlist);\n        playlist.segments = getAllSegments(playlist);\n\n        playlist.segments.forEach((segment) => {\n          resolveSegmentUris(segment, playlist.resolvedUri);\n        });\n      });\n      this.trigger('loadedplaylist');\n      console.log('master', this.master);\n\n      if (!this.request) {\n        // no media playlist was specifically selected so start\n        // from the first listed one\n        this.media(this.master.playlists[0]);\n      }\n\n      return;\n    }\n\n    console.log('CONTINUE');\n\n    // In order to support media playlists passed in as vhs-json, the case where the uri\n    // is not provided as part of the manifest should be considered, and an appropriate\n    // default used.\n    const uri = this.src || window.location.href;\n    console.log(uri);\n\n    this.master = (0,_manifest__WEBPACK_IMPORTED_MODULE_0__.masterForMedia)(manifest, uri);\n    console.log(this.master);\n\n    this.haveMetadata({\n      playlistObject: manifest,\n      url: uri,\n      id: this.master.playlists[0].id\n    });\n    this.trigger('loadedmetadata');\n\n\n\n    /*\n    manifest.segments.forEach((segment) => {\n      resolveSegmentUris(segment, uri);\n    });\n     */\n\n    //console.log(manifest);\n\n\n\n    /*\n\n\n\n\n    // Replace this value with your files codec info\n    const mime = 'video/mp4; codecs=\"mp4a.40.2,avc1.64001f\"';\n\n\n  // segments\n    let segments = [\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_526/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_527/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_528/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_529/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_530/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_531/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_532/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_533/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_534/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_535/193039199_mp4_h264_aac_ld_7.ts',\n      'https://test-streams.mux.dev/x36xhzz/url_2/url_536/193039199_mp4_h264_aac_ld_7.ts'\n    ];\n\n    if(manifest.segments) {\n      segments = [];\n      manifest.segments.forEach((segment) => {\n        segments.push(segment.resolvedUri);\n      });\n    }\n\n    const mediaSource = new window.MediaSource();\n    const transmuxer = new muxjs.mp4.Transmuxer();\n    let sourceBuffer = null;\n\n    const handleFirstSegment = () => {\n      if(segments.length == 0) {\n        return;\n      }\n\n      sourceBuffer = mediaSource.addSourceBuffer(mime);\n      sourceBuffer.addEventListener('updateend', handleNextSegment);\n\n      transmuxer.on('data', (segment) => {\n        const data = new Uint8Array(segment.initSegment.byteLength + segment.data.byteLength);\n        data.set(segment.initSegment, 0);\n        data.set(segment.data, segment.initSegment.byteLength);\n        console.log(muxjs.mp4.tools.inspect(data));\n        sourceBuffer.appendBuffer(data);\n      });\n\n      fetch(segments.shift())\n        .then(res => res.arrayBuffer())\n        .then(response => {\n          transmuxer.push(new Uint8Array(response));\n          transmuxer.flush();\n        });\n\n    }\n\n    const handleNextSegment = () => {\n      // reset the data event listener to just append (moof/mdat) boxes to the Source Buffer\n      transmuxer.off('data');\n      transmuxer.on('data', (segment) => {\n        sourceBuffer.appendBuffer(new Uint8Array(segment.data));\n      });\n\n      if(segments.length == 0) {\n        // notify MSE that no more segments to append\n        mediaSource.endOfStream();\n      } else {\n\n        // fetch the next segment from the segments array and pass it into the transmuxer.push method\n        fetch(segments.shift())\n          .then(res => res.arrayBuffer())\n          .then(response => {\n            transmuxer.push(new Uint8Array(response));\n            transmuxer.flush();\n          });\n      }\n    }\n\n    mediaSource.addEventListener('sourceopen', handleFirstSegment);\n\n    return mediaSource;\n     */\n  }\n  haveMetadata({ playlistString, playlistObject, url, id }) {\n    // any in-flight request is now finished\n    this.request = null;\n    this.state = 'HAVE_METADATA';\n\n    const playlist = playlistObject || this._parseManifest({\n      url,\n      manifestString: playlistString\n    });\n\n    playlist.lastRequest = Date.now();\n\n    (0,_manifest__WEBPACK_IMPORTED_MODULE_0__.setupMediaPlaylist)({\n      playlist,\n      uri: url,\n      id\n    });\n\n    // merge this playlist into the master\n    const update = updateMaster(this.master, playlist);\n\n    this.targetDuration = playlist.partTargetDuration || playlist.targetDuration;\n\n    this._pendingMedia = null;\n\n    if (update) {\n      this.master = update;\n      this._media = this.master.playlists[id];\n    } else {\n      this.trigger('playlistunchanged');\n    }\n\n    this._updateMediaUpdateTimeout(refreshDelay(this.media(), !!update));\n\n    this.trigger('loadedplaylist');\n  }\n  media(playlist, shouldDelay) {\n    // getter\n    if (!playlist) {\n      return this._media;\n    }\n\n    // setter\n    if (this.state === 'HAVE_NOTHING') {\n      throw new Error('Cannot switch media playlist from ' + this.state);\n    }\n\n    // find the playlist object if the target playlist has been\n    // specified by URI\n    if (typeof playlist === 'string') {\n      if (!this.master.playlists[playlist]) {\n        throw new Error('Unknown playlist URI: ' + playlist);\n      }\n      playlist = this.master.playlists[playlist];\n    }\n\n    window.clearTimeout(this.finalRenditionTimeout);\n\n    if (shouldDelay) {\n      const delay = ((playlist.partTargetDuration || playlist.targetDuration) / 2) * 1000 || 5 * 1000;\n\n      this.finalRenditionTimeout =\n        window.setTimeout(this.media.bind(this, playlist, false), delay);\n      return;\n    }\n\n    const startingState = this.state;\n    const mediaChange = !this._media || playlist.id !== this._media.id;\n    const masterPlaylistRef = this.master.playlists[playlist.id];\n\n    // switch to fully loaded playlists immediately\n    if (masterPlaylistRef && masterPlaylistRef.endList ||\n      // handle the case of a playlist object (e.g., if using vhs-json with a resolved\n      // media playlist or, for the case of demuxed audio, a resolved audio media group)\n      (playlist.endList && playlist.segments.length)) {\n\n      // abort outstanding playlist requests\n      if (this.request) {\n        this.request.onreadystatechange = null;\n        this.request.abort();\n        this.request = null;\n      }\n      this.state = 'HAVE_METADATA';\n      this._media = playlist;\n\n      // trigger media change if the active media has been updated\n      if (mediaChange) {\n        this.trigger('mediachanging');\n\n        if (startingState === 'HAVE_MASTER') {\n          // The initial playlist was a master manifest, and the first media selected was\n          // also provided (in the form of a resolved playlist object) as part of the\n          // source object (rather than just a URL). Therefore, since the media playlist\n          // doesn't need to be requested, loadedmetadata won't trigger as part of the\n          // normal flow, and needs an explicit trigger here.\n          this.trigger('loadedmetadata');\n        } else {\n          this.trigger('mediachange');\n        }\n      }\n      return;\n    }\n\n    // We update/set the timeout here so that live playlists\n    // that are not a media change will \"start\" the loader as expected.\n    // We expect that this function will start the media update timeout\n    // cycle again. This also prevents a playlist switch failure from\n    // causing us to stall during live.\n    this._updateMediaUpdateTimeout(refreshDelay(playlist, true));\n\n    // switching to the active playlist is a no-op\n    if (!mediaChange) {\n      return;\n    }\n\n    this.state = 'SWITCHING_MEDIA';\n\n    // there is already an outstanding playlist request\n    if (this.request) {\n      if (playlist.resolvedUri === this.request.url) {\n        // requesting to switch to the same playlist multiple times\n        // has no effect after the first\n        return;\n      }\n      this.request.onreadystatechange = null;\n      this.request.abort();\n      this.request = null;\n    }\n\n    // request the new playlist\n    if (this._media) {\n      this.trigger('mediachanging');\n    }\n\n    this._pendingMedia = playlist;\n\n    // TODO:\n    this.request = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.xhr)({\n      uri: playlist.resolvedUri,\n      withCredentials: this.withCredentials\n    }, (error, req) => {\n      // disposed\n      if (!this.request) {\n        return;\n      }\n\n      playlist.lastRequest = Date.now();\n\n      playlist.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveManifestRedirect)(this.handleManifestRedirects, playlist.resolvedUri, req);\n\n      if (error) {\n        return this.playlistRequestError(this.request, playlist, startingState);\n      }\n\n      console.log(req.responseText);\n\n      this.haveMetadata({\n        playlistString: req.responseText,\n        url: playlist.uri,\n        id: playlist.id\n      });\n\n      // fire loadedmetadata the first time a media playlist is loaded\n      if (startingState === 'HAVE_MASTER') {\n        this.trigger('loadedmetadata');\n      } else {\n        this.trigger('mediachange');\n      }\n    });\n  }\n}\n\nconst addLLHLSQueryDirectives = (uri, media) => {\n  if (media.endList || !media.serverControl) {\n    return uri;\n  }\n\n  const parameters = {};\n\n  if (media.serverControl.canBlockReload) {\n    const {preloadSegment} = media;\n    // next msn is a zero based value, length is not.\n    let nextMSN = media.mediaSequence + media.segments.length;\n\n    // If preload segment has parts then it is likely\n    // that we are going to request a part of that preload segment.\n    // the logic below is used to determine that.\n    if (preloadSegment) {\n      const parts = preloadSegment.parts || [];\n      // _HLS_part is a zero based index\n      const nextPart = (0,_playlist__WEBPACK_IMPORTED_MODULE_2__.getKnownPartCount)(media) - 1;\n\n      // if nextPart is > -1 and not equal to just the\n      // length of parts, then we know we had part preload hints\n      // and we need to add the _HLS_part= query\n      if (nextPart > -1 && nextPart !== (parts.length - 1)) {\n        // add existing parts to our preload hints\n        // eslint-disable-next-line\n        parameters._HLS_part = nextPart;\n      }\n\n      // this if statement makes sure that we request the msn\n      // of the preload segment if:\n      // 1. the preload segment had parts (and was not yet a full segment)\n      //    but was added to our segments array\n      // 2. the preload segment had preload hints for parts that are not in\n      //    the manifest yet.\n      // in all other cases we want the segment after the preload segment\n      // which will be given by using media.segments.length because it is 1 based\n      // rather than 0 based.\n      if (nextPart > -1 || parts.length) {\n        nextMSN--;\n      }\n    }\n\n    // add _HLS_msn= in front of any _HLS_part query\n    // eslint-disable-next-line\n    parameters._HLS_msn = nextMSN;\n  }\n\n  if (media.serverControl && media.serverControl.canSkipUntil) {\n    // add _HLS_skip= infront of all other queries.\n    // eslint-disable-next-line\n    parameters._HLS_skip = (media.serverControl.canSkipDateranges ? 'v2' : 'YES');\n  }\n\n  if (Object.keys(parameters).length) {\n    const parsedUri = new window.URL(uri);\n\n    ['_HLS_skip', '_HLS_msn', '_HLS_part'].forEach(function(name) {\n      if (!parameters.hasOwnProperty(name)) {\n        return;\n      }\n\n      parsedUri.searchParams.set(name, parameters[name]);\n    });\n\n    uri = parsedUri.toString();\n  }\n\n  return uri;\n};\n\nconst refreshDelay = (media, update) => {\n  const segments = media.segments || [];\n  const lastSegment = segments[segments.length - 1];\n  const lastPart = lastSegment && lastSegment.parts && lastSegment.parts[lastSegment.parts.length - 1];\n  const lastDuration = lastPart && lastPart.duration || lastSegment && lastSegment.duration;\n\n  if (update && lastDuration) {\n    return lastDuration * 1000;\n  }\n\n  // if the playlist is unchanged since the last reload or last segment duration\n  // cannot be determined, try again after half the target duration\n  return (media.partTargetDuration || media.targetDuration || 10) * 500;\n};\n\nconst updateSegment = (a, b) => {\n  if (!a) {\n    return b;\n  }\n\n  const result = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.mergeObjects)(a, b);\n\n  // if only the old segment has preload hints\n  // and the new one does not, remove preload hints.\n  if (a.preloadHints && !b.preloadHints) {\n    delete result.preloadHints;\n  }\n\n  // if only the old segment has parts\n  // then the parts are no longer valid\n  if (a.parts && !b.parts) {\n    delete result.parts;\n    // if both segments have parts\n    // copy part propeties from the old segment\n    // to the new one.\n  } else if (a.parts && b.parts) {\n    for (let i = 0; i < b.parts.length; i++) {\n      if (a.parts && a.parts[i]) {\n        result.parts[i] = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.mergeObjects)(a.parts[i], b.parts[i]);\n      }\n    }\n  }\n\n  // set skipped to false for segments that have\n  // have had information merged from the old segment.\n  if (!a.skipped && b.skipped) {\n    result.skipped = false;\n  }\n\n  // set preload to false for segments that have\n  // had information added in the new segment.\n  if (a.preload && !b.preload) {\n    result.preload = false;\n  }\n\n  return result;\n};\n\nconst updateSegments = (original, update, offset) => {\n  const oldSegments = original.slice();\n  const newSegments = update.slice();\n\n  offset = offset || 0;\n  const result = [];\n\n  let currentMap;\n\n  for (let newIndex = 0; newIndex < newSegments.length; newIndex++) {\n    const oldSegment = oldSegments[newIndex + offset];\n    const newSegment = newSegments[newIndex];\n\n    if (oldSegment) {\n      currentMap = oldSegment.map || currentMap;\n\n      result.push(updateSegment(oldSegment, newSegment));\n    } else {\n      // carry over map to new segment if it is missing\n      if (currentMap && !newSegment.map) {\n        newSegment.map = currentMap;\n      }\n\n      result.push(newSegment);\n\n    }\n  }\n  return result;\n};\n\nconst resolveSegmentUris = (segment, baseUri) => {\n  // preloadSegment will not have a uri at all\n  // as the segment isn't actually in the manifest yet, only parts\n  if (!segment.resolvedUri && segment.uri) {\n    segment.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, segment.uri);\n  }\n  if (segment.key && !segment.key.resolvedUri) {\n    segment.key.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, segment.key.uri);\n  }\n  if (segment.map && !segment.map.resolvedUri) {\n    segment.map.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, segment.map.uri);\n  }\n\n  if (segment.map && segment.map.key && !segment.map.key.resolvedUri) {\n    segment.map.key.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, segment.map.key.uri);\n  }\n  if (segment.parts && segment.parts.length) {\n    segment.parts.forEach((p) => {\n      if (p.resolvedUri) {\n        return;\n      }\n      p.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, p.uri);\n    });\n  }\n\n  if (segment.preloadHints && segment.preloadHints.length) {\n    segment.preloadHints.forEach((p) => {\n      if (p.resolvedUri) {\n        return;\n      }\n      p.resolvedUri = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.resolveUrl)(baseUri, p.uri);\n    });\n  }\n}\n\nconst getAllSegments = function(media) {\n  const segments = media.segments || [];\n  const preloadSegment = media.preloadSegment;\n\n  // a preloadSegment with only preloadHints is not currently\n  // a usable segment, only include a preloadSegment that has\n  // parts.\n  if (preloadSegment && preloadSegment.parts && preloadSegment.parts.length) {\n    // if preloadHints has a MAP that means that the\n    // init segment is going to change. We cannot use any of the parts\n    // from this preload segment.\n    if (preloadSegment.preloadHints) {\n      for (let i = 0; i < preloadSegment.preloadHints.length; i++) {\n        if (preloadSegment.preloadHints[i].type === 'MAP') {\n          return segments;\n        }\n      }\n    }\n    // set the duration for our preload segment to target duration.\n    preloadSegment.duration = media.targetDuration;\n    preloadSegment.preload = true;\n\n    segments.push(preloadSegment);\n  }\n\n  return segments;\n}\n\nconst isPlaylistUnchanged = (a, b) => a === b ||\n  (a.segments && b.segments && a.segments.length === b.segments.length &&\n    a.endList === b.endList &&\n    a.mediaSequence === b.mediaSequence &&\n    a.preloadSegment === b.preloadSegment);\n\nconst updateMaster = (master, newMedia, unchangedCheck = isPlaylistUnchanged) => {\n  const result = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.mergeObjects)(master, {});\n  const oldMedia = result.playlists[newMedia.id];\n\n  if (!oldMedia) {\n    return null;\n  }\n\n  if (unchangedCheck(oldMedia, newMedia)) {\n    return null;\n  }\n\n  newMedia.segments = getAllSegments(newMedia);\n\n  const mergedPlaylist = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.mergeObjects)(oldMedia, newMedia);\n\n  // always use the new media's preload segment\n  if (mergedPlaylist.preloadSegment && !newMedia.preloadSegment) {\n    delete mergedPlaylist.preloadSegment;\n  }\n\n  // if the update could overlap existing segment information, merge the two segment lists\n  if (oldMedia.segments) {\n    if (newMedia.skip) {\n      newMedia.segments = newMedia.segments || [];\n      // add back in objects for skipped segments, so that we merge\n      // old properties into the new segments\n      for (let i = 0; i < newMedia.skip.skippedSegments; i++) {\n        newMedia.segments.unshift({skipped: true});\n      }\n    }\n    mergedPlaylist.segments = updateSegments(\n      oldMedia.segments,\n      newMedia.segments,\n      newMedia.mediaSequence - oldMedia.mediaSequence\n    );\n  }\n\n  // resolve any segment URIs to prevent us from having to do it later\n  mergedPlaylist.segments.forEach((segment) => {\n    resolveSegmentUris(segment, mergedPlaylist.resolvedUri);\n  });\n\n  // TODO Right now in the playlists array there are two references to each playlist, one\n  // that is referenced by index, and one by URI. The index reference may no longer be\n  // necessary.\n  for (let i = 0; i < result.playlists.length; i++) {\n    if (result.playlists[i].id === newMedia.id) {\n      result.playlists[i] = mergedPlaylist;\n    }\n  }\n  result.playlists[newMedia.id] = mergedPlaylist;\n  // URI reference added for backwards compatibility\n  result.playlists[newMedia.uri] = mergedPlaylist;\n\n  // update media group playlist references.\n  (0,_manifest__WEBPACK_IMPORTED_MODULE_0__.forEachMediaGroup)(master, (properties, mediaType, groupKey, labelKey) => {\n    if (!properties.playlists) {\n      return;\n    }\n    for (let i = 0; i < properties.playlists.length; i++) {\n      if (newMedia.id === properties.playlists[i].id) {\n        properties.playlists[i] = mergedPlaylist;\n      }\n    }\n  });\n\n  return result;\n}\n\n\n//# sourceURL=webpack://adserve/./src/playlist-loader.js?");

/***/ }),

/***/ "./src/playlist.js":
/*!*************************!*\
  !*** ./src/playlist.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getLastParts\": () => (/* binding */ getLastParts),\n/* harmony export */   \"getKnownPartCount\": () => (/* binding */ getKnownPartCount),\n/* harmony export */   \"playlistMatch\": () => (/* binding */ playlistMatch),\n/* harmony export */   \"isAudioOnly\": () => (/* binding */ isAudioOnly)\n/* harmony export */ });\nconst getLastParts = (media) => {\n  const lastSegment = media.segments && media.segments.length && media.segments[media.segments.length - 1];\n  return lastSegment && lastSegment.parts || [];\n}\n\nconst getKnownPartCount = ({preloadSegment}) => {\n  if (!preloadSegment) {\n    return;\n  }\n  const {parts, preloadHints} = preloadSegment;\n  let partCount = (preloadHints || [])\n    .reduce((count, hint) => count + (hint.type === 'PART' ? 1 : 0), 0);\n\n  partCount += (parts && parts.length) ? parts.length : 0;\n\n  return partCount;\n};\n\nconst playlistMatch = (a, b) => {\n  // both playlits are null\n  // or only one playlist is non-null\n  // no match\n  if (!a && !b || (!a && b) || (a && !b)) {\n    return false;\n  }\n\n  // playlist objects are the same, match\n  if (a === b) {\n    return true;\n  }\n\n  // first try to use id as it should be the most\n  // accurate\n  if (a.id && b.id && a.id === b.id) {\n    return true;\n  }\n\n  // next try to use reslovedUri as it should be the\n  // second most accurate.\n  if (a.resolvedUri && b.resolvedUri && a.resolvedUri === b.resolvedUri) {\n    return true;\n  }\n\n  // finally try to use uri as it should be accurate\n  // but might miss a few cases for relative uris\n  if (a.uri && b.uri && a.uri === b.uri) {\n    return true;\n  }\n\n  return false;\n}\n\nconst someAudioVariant = function(master, callback) {\n  const AUDIO = master && master.mediaGroups && master.mediaGroups.AUDIO || {};\n  let found = false;\n\n  for (const groupName in AUDIO) {\n    for (const label in AUDIO[groupName]) {\n      found = callback(AUDIO[groupName][label]);\n\n      if (found) {\n        break;\n      }\n    }\n\n    if (found) {\n      break;\n    }\n  }\n\n  return !!found;\n}\n\nconst regexs = {\n  // to determine mime types\n  mp4: /^(av0?1|avc0?[1234]|vp0?9|flac|opus|mp3|mp4a|mp4v|stpp.ttml.im1t)/,\n  webm: /^(vp0?[89]|av0?1|opus|vorbis)/,\n  ogg: /^(vp0?[89]|theora|flac|opus|vorbis)/,\n  // to determine if a codec is audio or video\n  video: /^(av0?1|avc0?[1234]|vp0?[89]|hvc1|hev1|theora|mp4v)/,\n  audio: /^(mp4a|flac|vorbis|opus|ac-[34]|ec-3|alac|mp3|speex|aac)/,\n  text: /^(stpp.ttml.im1t)/,\n  // mux.js support regex\n  muxerVideo: /^(avc0?1)/,\n  muxerAudio: /^(mp4a)/,\n  // match nothing as muxer does not support text right now.\n  // there cannot never be a character before the start of a string\n  // so this matches nothing.\n  muxerText: /a^/\n};\nconst mediaTypes = ['video', 'audio', 'text'];\nconst upperMediaTypes = ['Video', 'Audio', 'Text'];\n\nfunction isAudioCodec(codec) {\n  if (codec === void 0) {\n    codec = '';\n  }\n\n  return regexs.audio.test(codec.trim().toLowerCase());\n}\n\nconst isAudioOnly = (master) => {\n  // we are audio only if we have no main playlists but do\n  // have media group playlists.\n  if (!master || !master.playlists || !master.playlists.length) {\n    // without audio variants or playlists this\n    // is not an audio only master.\n    const found = someAudioVariant(master, (variant) =>\n      (variant.playlists && variant.playlists.length) || variant.uri);\n\n    return found;\n  }\n\n  // if every playlist has only an audio codec it is audio only\n  for (let i = 0; i < master.playlists.length; i++) {\n    const playlist = master.playlists[i];\n    const CODECS = playlist.attributes && playlist.attributes.CODECS;\n\n    // all codecs are audio, this is an audio playlist.\n    if (CODECS && CODECS.split(',').every((c) => isAudioCodec(c))) {\n      continue;\n    }\n\n    // playlist is in an audio group it is audio only\n    const found = someAudioVariant(master, (variant) => playlistMatch(playlist, variant));\n\n    if (found) {\n      continue;\n    }\n\n    // if we make it here this playlist isn't audio and we\n    // are not audio only\n    return false;\n  }\n\n  // if we make it past every playlist without returning, then\n  // this is an audio only playlist.\n  return true;\n}\n\n\n//# sourceURL=webpack://adserve/./src/playlist.js?");

/***/ }),

/***/ "./src/time-bus.js":
/*!*************************!*\
  !*** ./src/time-bus.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addHandler\": () => (/* binding */ addHandler),\n/* harmony export */   \"removeHandler\": () => (/* binding */ removeHandler),\n/* harmony export */   \"getTime\": () => (/* binding */ getTime),\n/* harmony export */   \"pause\": () => (/* binding */ pause),\n/* harmony export */   \"resume\": () => (/* binding */ resume),\n/* harmony export */   \"reset\": () => (/* binding */ reset)\n/* harmony export */ });\n\nlet time = 0;\n/*\nlet triggers = {};\nlet interval = null;\nlet updateTrigger = false;\n*/\nlet timerWorkerHandlers = [];\n\nconst run = (callback) => {\n  try {\n    return new Worker(URL.createObjectURL(new Blob(['(' + callback + ')()'])));\n  } catch (e) {\n    console.log('time bus error', e);\n  }\n}\n\nconst timerWorker = run(function() {\n  const stepInterval = 20;\n  const messagingInterval = 200;\n  let start = 0;\n  let stepTimeout;\n\n  function handleMessages(event) {\n    if(!event || !event.data) return;\n\n    switch(event.data.type) {\n      case 'pause':\n        pause();\n        break;\n      case 'resume':\n        resume();\n        break;\n      default:\n    }\n  }\n\n  self.onmessage = handleMessages;\n\n  function pause() {\n    if(stepTimeout) {\n      clearTimeout(stepTimeout);\n      stepTimeout = null;\n      postMessage('timeBus paused');\n    }\n  }\n\n  function resume() {\n    if(stepTimeout === null) {\n      stepTimeout = setTimeout(step, 0);\n      postMessage('timeBus resumed');\n    }\n  }\n\n  function step() {\n    const timestamp = performance.now();\n    if(!start) start = timestamp;\n    const progress = timestamp - start;\n    if(progress >= messagingInterval) {\n      postMessage({ type: 'timeUpdate', time: timestamp });\n      start = start + messagingInterval;\n    }\n    stepTimeout = setTimeout(step, stepInterval);\n  }\n\n  stepTimeout = setTimeout(step, 0);\n  postMessage('timeBus initialized');\n\n});\n\nconst getTime = () => time;\nconst pause = () => timerWorker.postMessage({ type: 'pause' });\nconst resume = () => timerWorker.postMessage({ type: 'resume' });\nconst reset = () => {\n  time = 0;\n}\n\nconst execHandlers = (time) => {\n  timerWorkerHandlers.forEach((handler) => {\n    if(time % handler.interval < 200) {\n      handler.callback.call(null, time);\n    }\n  });\n}\n\nconst handleTimeWorkerMessages = (event) => {\n  switch (event.data.type) {\n    case 'timeUpdate':\n      time = event.data.time;\n      execHandlers(time);\n      break;\n    default:\n  }\n}\n\ntimerWorker.onmessage = handleTimeWorkerMessages;\n\nconst addHandler = (callback, interval = 200) => {\n  interval = parseInt(interval);\n  timerWorkerHandlers.push({\n    callback: callback,\n    interval: interval\n  })\n}\n\nconst removeHandler = (excutable) => {\n  timerWorkerHandlers = timerWorkerHandlers.filter(({ callback }) => callback !== excutable);\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/time-bus.js?");

/***/ }),

/***/ "./src/usp.js":
/*!********************!*\
  !*** ./src/usp.js ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"lookupConsent\": () => (/* binding */ lookupConsent),\n/* harmony export */   \"getConsentString\": () => (/* binding */ getConsentString)\n/* harmony export */ });\n// USP\nlet consentString = '';\nlet triesLeft = 5;\nconst cmpCallbacks = {};\nconst uspVersion = 1;\n\nfunction lookupConsent() {\n  consentString = '';\n  if(!window.__uspapi && window !== window.top) {\n    // Find the CMP frame\n    let frame = window;\n    let cmpFrame;\n    while (!cmpFrame) {\n      try {\n        if(frame.frames['__uspapiLocator']) cmpFrame = frame;\n      } catch (e) {}\n\n      if(frame === window.top) break;\n      frame = frame.parent;\n    }\n\n    // Setup a __uspapi function to do the postMessage and stash the callback.\n    // This function behaves (from the caller's perspective)\n    // identically to the same frame __uspapi call\n    window.__uspapi = function(cmd, version, callback) {\n      if(!cmpFrame) {\n        callback({ msg: 'CMP not found' }, false);\n        return;\n      }\n      const callId = Math.random() + '';\n      const msg = {\n        __uspapiCall: {\n          command: cmd,\n          version,\n          callId\n        }\n      };\n      cmpCallbacks[callId] = callback;\n      cmpFrame.postMessage(msg, '*');\n    }\n\n    // When receive message, call the stashed callback\n    window.addEventListener('message', function(event) {\n      let data;\n      if(typeof event.data === 'string') {\n        try {\n          data = JSON.parse(event.data);\n        } catch (e) {}\n      } else {\n        data = event.data;\n      }\n\n      if(data && data.__uspapiReturn) {\n        const r = data.__uspapiReturn;\n        if(r && cmpCallbacks.hasOwnProperty(r.callId)) {\n          try {\n            cmpCallbacks[r.callId](\n              r.returnValue,\n              r.success\n            );\n            delete cmpCallbacks[r.callId];\n          } catch (e) {}\n        }\n      }\n\n    });\n\n  }\n\n  if(typeof window.__uspapi !== 'function') {\n    if(triesLeft-- > 0) {\n      window.setTimeout(lookupConsent, 1200);\n    } else {\n      // There's no CMP on the page\n      console.log('CCPA', 'There\\'s no CMP on the page');\n    }\n    return;\n  }\n\n  window.__uspapi('getUSPData', uspVersion, (uspData, success) => {\n    if(success) {\n      consentString = uspData.uspString;\n      console.log('CCPA', uspData);\n    } else {\n      if(triesLeft-- == 0) {\n        // There's no CMP on the page\n        console.log('CCPA', 'There\\'s no CMP on the page');\n      } else {\n        window.setTimeout(lookupConsent, 1200);\n      }\n    }\n  });\n}\n\nfunction getConsentString() {\n  if(typeof consentString !== 'string') {\n    return '';\n  }\n  return consentString;\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/usp.js?");

/***/ }),

/***/ "./src/utils.js":
/*!**********************!*\
  !*** ./src/utils.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"observeVisibility\": () => (/* binding */ observeVisibility),\n/* harmony export */   \"visible\": () => (/* binding */ visible),\n/* harmony export */   \"MIME_TYPES\": () => (/* binding */ MIME_TYPES),\n/* harmony export */   \"getMimeType\": () => (/* binding */ getMimeType),\n/* harmony export */   \"getFileExtension\": () => (/* binding */ getFileExtension),\n/* harmony export */   \"supportsNativeHls\": () => (/* binding */ supportsNativeHls),\n/* harmony export */   \"supportsNativeDash\": () => (/* binding */ supportsNativeDash),\n/* harmony export */   \"toHHMMSS\": () => (/* binding */ toHHMMSS),\n/* harmony export */   \"getBuffer\": () => (/* binding */ getBuffer),\n/* harmony export */   \"getRunTime\": () => (/* binding */ getRunTime),\n/* harmony export */   \"getCacheBuster\": () => (/* binding */ getCacheBuster),\n/* harmony export */   \"getTimestamp\": () => (/* binding */ getTimestamp),\n/* harmony export */   \"millisecondsToSeconds\": () => (/* binding */ millisecondsToSeconds),\n/* harmony export */   \"isFullscreen\": () => (/* binding */ isFullscreen),\n/* harmony export */   \"requestFullscreen\": () => (/* binding */ requestFullscreen),\n/* harmony export */   \"existFullscreen\": () => (/* binding */ existFullscreen),\n/* harmony export */   \"ASPECT_RATIOS\": () => (/* binding */ ASPECT_RATIOS),\n/* harmony export */   \"injectStyle\": () => (/* binding */ injectStyle),\n/* harmony export */   \"generateSessionId\": () => (/* binding */ generateSessionId),\n/* harmony export */   \"getBoundingClientRect\": () => (/* binding */ getBoundingClientRect),\n/* harmony export */   \"findPosition\": () => (/* binding */ findPosition),\n/* harmony export */   \"getPointerPosition\": () => (/* binding */ getPointerPosition),\n/* harmony export */   \"replaceMacrosValues\": () => (/* binding */ replaceMacrosValues),\n/* harmony export */   \"serializeSupplyChain\": () => (/* binding */ serializeSupplyChain),\n/* harmony export */   \"getUrl\": () => (/* binding */ getUrl),\n/* harmony export */   \"resolveUrl\": () => (/* binding */ resolveUrl),\n/* harmony export */   \"resolveManifestRedirect\": () => (/* binding */ resolveManifestRedirect),\n/* harmony export */   \"getHostname\": () => (/* binding */ getHostname),\n/* harmony export */   \"xhr\": () => (/* binding */ xhr),\n/* harmony export */   \"fetchWithTimeout\": () => (/* binding */ fetchWithTimeout),\n/* harmony export */   \"isQueryStringContains\": () => (/* binding */ isQueryStringContains),\n/* harmony export */   \"getQueryStringValue\": () => (/* binding */ getQueryStringValue),\n/* harmony export */   \"mergeObjects\": () => (/* binding */ mergeObjects)\n/* harmony export */ });\n/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./browser */ \"./src/browser.js\");\n\n// IntersectionObserver\n// Detect element visibility\n\n\n\nfunction observeVisibility(el, callback) {\n  const observer = new IntersectionObserver(callback, {\n    root: null, // viewport\n    threshold: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] // every 10%\n  });\n  try {\n    observer.observe(el);\n  } catch (e) {\n    console.log('IntersectionObserver setup failed', e);\n  }\n  return observer\n}\n\nfunction visible(intersectionRatio, threshold) {\n  return intersectionRatio * 100 >= threshold\n}\n\nconst MIME_TYPES = {\n  webm: 'video/webm',\n  opus: 'video/ogg',\n  ogv: 'video/ogg',\n  mp4: 'video/mp4',\n  mov: 'video/mp4',\n  m4v: 'video/mp4',\n  mkv: 'video/x-matroska',\n  treegpv: 'video/3gpp',\n  m4a: 'audio/mp4',\n  mp3: 'audio/mpeg',\n  aac: 'audio/aac',\n  caf: 'audio/x-caf',\n  flac: 'audio/flac',\n  oga: 'audio/ogg',\n  wav: 'audio/wav',\n  m3u8: 'application/x-mpegurl',\n  mpd: 'application/dash+xml',\n  jpg: 'image/jpeg',\n  jpeg: 'image/jpeg',\n  gif: 'image/gif',\n  png: 'image/png',\n  svg: 'image/svg+xml',\n  webp: 'image/webp'\n}\n\nfunction getMimeType(src = '') {\n  const ext = getFileExtension(src);\n  const mimeType = MIME_TYPES[ext.toLowerCase()];\n  return mimeType || '';\n}\n\nfunction getFileExtension(path) {\n  if(typeof path === 'string') {\n    const splitPathRe = /^(\\/?)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?)(\\.([^\\.\\/\\?]+)))(?:[\\/]*|[\\?].*)$/;\n    const pathParts = splitPathRe.exec(path);\n    if (pathParts) {\n      return pathParts.pop().toLowerCase();\n    }\n  }\n  return '';\n}\n\nfunction supportsNativeHls() {\n  const video = document.createElement('video');\n  // HLS manifests can go by many mime-types\n  const canPlay = [\n    // Apple santioned\n    'application/vnd.apple.mpegurl',\n    // Apple sanctioned for backwards compatibility\n    'audio/mpegurl',\n    // Very common\n    'audio/x-mpegurl',\n    // Very common\n    'application/x-mpegurl',\n    // Included for completeness\n    'video/x-mpegurl',\n    'video/mpegurl',\n    'application/mpegurl'\n  ];\n\n  return canPlay.some(function(canItPlay) {\n    return (/maybe|probably/i).test(video.canPlayType(canItPlay));\n  });\n}\n\nfunction supportsNativeDash() {\n  return (/maybe|probably/i).test(document.createElement('video').canPlayType('application/dash+xml'));\n}\n\nfunction toHHMMSS(seconds) {\n  let from = 11;\n  let length = 8;\n  if(seconds < 3600) {\n    from = 14;\n    length = 5;\n  }\n  return new Date(seconds * 1000).toISOString().substr(from, length)\n}\n\nfunction getBuffer(value) {\n  return value + .1\n}\n\nconst startTime = new Date().getTime();\nfunction getRunTime() {\n  return new Date().getTime() - startTime;\n}\n\nfunction getCacheBuster() {\n  return Math.floor(Math.random() * 1000000);\n}\n\nfunction getTimestamp() {\n  return Date.now();\n}\n\nfunction millisecondsToSeconds(milliseconds) {\n  return Math.floor(milliseconds / 1000);\n}\n\nfunction isFullscreen(el, video) {\n  return hasFullscreen(el, video) ? true : false\n}\n\nfunction hasFullscreen(el, video) {\n  if(_browser__WEBPACK_IMPORTED_MODULE_0__.IS_IOS) return video.webkitDisplayingFullscreen;\n  if(el.fullscreenElement\n    || el.webkitFullscreenElement\n    || el.mozFullScreenElement) {\n    return true;\n  }\n  return false;\n}\n\nfunction requestFullscreen(el, video) {\n  if(_browser__WEBPACK_IMPORTED_MODULE_0__.IS_IOS) {\n    video.webkitEnterFullscreen();\n  } else {\n    if ('requestFullscreen' in el) {\n      el.requestFullscreen();\n    } else if ('webkitRequestFullscreen' in el) {\n      el.webkitRequestFullscreen();\n    } else if ('mozRequestFullScreen' in el) {\n      el.mozRequestFullScreen()\n    }\n  }\n}\n\nfunction existFullscreen(el, video) {\n  if(_browser__WEBPACK_IMPORTED_MODULE_0__.IS_IOS) {\n    video.webkitExitFullscreen();\n  } else {\n    if ('exitFullscreen' in el) {\n      el.exitFullscreen();\n    } else if ('webkitExitFullscreen' in el) {\n      el.webkitExitFullscreen();\n    } else if ('mozCancelFullScreen' in el) {\n      el.mozCancelFullScreen();\n    }\n  }\n}\n\nconst ASPECT_RATIOS = {\n  '1:1': '100%',\n  '16:9': '56.25%', // 9 / 16 * 100 = 56.25\n  '4:3': '75%',\n  '3:2': '66.66%',\n  '8:5': '62.5%',\n  '9:16': '177.77%' // 16 / 9 * 100 = 177.77777777777777\n}\n\nfunction injectStyle(id, cssContent) {\n  if(!cssContent || typeof cssContent !== 'string' || cssContent.length < 1) {\n    return;\n  }\n  let style = null;\n  if(id) {\n    // Update\n    style = document.getElementById(id);\n    if(!style) {\n      style = document.createElement('style');\n      style.id = id;\n      style.textContent = cssContent;\n      document.head.appendChild(style);\n    } else {\n      style.textContent = cssContent\n    }\n  } else {\n    // Set\n    style = document.createElement('style');\n    style.textContent = cssContent;\n    document.head.appendChild(style);\n  }\n}\n\nfunction generateSessionId() {\n  let sessionId = '';\n  const possible = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n  for(let i = 0; i < 32; i++)\n    sessionId += possible.charAt(Math.floor(Math.random() * possible.length));\n\n  return sessionId;\n}\n\nfunction computedStyle(el, prop) {\n  if(!el || !prop) {\n    return '';\n  }\n\n  if(typeof window.getComputedStyle === 'function') {\n    let computedStyleValue;\n\n    try {\n      computedStyleValue = window.getComputedStyle(el);\n    } catch (e) {\n      return '';\n    }\n\n    return computedStyleValue ? computedStyleValue.getPropertyValue(prop) || computedStyleValue[prop] : '';\n  }\n\n  return '';\n}\n\nfunction getBoundingClientRect(el) {\n  if(el && el.getBoundingClientRect && el.parentNode) {\n    const rect = el.getBoundingClientRect();\n    const result = {};\n\n    ['bottom', 'height', 'left', 'right', 'top', 'width'].forEach(k => {\n      if (rect[k] !== undefined) {\n        result[k] = rect[k];\n      }\n    });\n\n    if(!result.height) {\n      result.height = parseFloat(computedStyle(el, 'height'));\n    }\n\n    if(!result.width) {\n      result.width = parseFloat(computedStyle(el, 'width'));\n    }\n\n    return result;\n  }\n}\n\nfunction findPosition(el) {\n  if(!el || (el && !el.offsetParent)) {\n    return {\n      left: 0,\n      top: 0,\n      width: 0,\n      height: 0\n    };\n  }\n  const width = el.offsetWidth;\n  const height = el.offsetHeight;\n  let left = 0;\n  let top = 0;\n\n  while (el.offsetParent /*&& el !== document[fs.fullscreenElement]*/) {\n    left += el.offsetLeft;\n    top += el.offsetTop;\n\n    el = el.offsetParent;\n  }\n\n  return {\n    left,\n    top,\n    width,\n    height\n  };\n}\n\nfunction getPointerPosition(el, event) {\n  const translated = {\n    x: 0,\n    y: 0\n  };\n\n  if(_browser__WEBPACK_IMPORTED_MODULE_0__.IS_IOS) {\n    let item = el;\n\n    while(item && item.nodeName.toLowerCase() !== 'html') {\n      const transform = computedStyle(item, 'transform');\n\n      if(/^matrix/.test(transform)) {\n        const values = transform.slice(7, -1).split(/,\\s/).map(Number);\n\n        translated.x += values[4];\n        translated.y += values[5];\n      } else if (/^matrix3d/.test(transform)) {\n        const values = transform.slice(9, -1).split(/,\\s/).map(Number);\n\n        translated.x += values[12];\n        translated.y += values[13];\n      }\n\n      item = item.parentNode;\n    }\n  }\n\n  const position = {};\n  const boxTarget = findPosition(event.target);\n  const box = findPosition(el);\n  const boxW = box.width;\n  const boxH = box.height;\n  let offsetY = event.offsetY - (box.top - boxTarget.top);\n  let offsetX = event.offsetX - (box.left - boxTarget.left);\n\n  if(event.changedTouches) {\n    // TODO:\n    const _box = getBoundingClientRect(el);\n    offsetX = event.changedTouches[0].pageX - _box.left; //box.left;\n    offsetY = event.changedTouches[0].pageY + _box.top; //box.top;\n    if (_browser__WEBPACK_IMPORTED_MODULE_0__.IS_IOS) {\n      offsetX -= translated.x;\n      offsetY -= translated.y;\n    }\n  }\n\n  position.y = (1 - Math.max(0, Math.min(1, offsetY / boxH)));\n  position.x = Math.max(0, Math.min(1, offsetX / boxW));\n  return position;\n}\n\nfunction replaceMacrosValues(url, macros) {\n  let replacedMacrosUrl = url;\n  for(const key in macros) {\n    const value = macros[key];\n    // this will match [${key}] and %%${key}%% and replace it\n    replacedMacrosUrl = replacedMacrosUrl.replace(\n      new RegExp(`(?:\\\\[|%%)(${key})(?:\\\\]|%%)`, 'g'),\n      value\n    );\n  }\n  return replacedMacrosUrl;\n}\n\nfunction serializeSupplyChain(schain) {\n  if(!schain || typeof schain !== 'object'\n    || !schain.hasOwnProperty('ver')\n    || !schain.hasOwnProperty('complete')\n    || !schain.hasOwnProperty('nodes')) {\n    return '';\n  }\n  const keys = 'asi sid hp rid name domain'.split(' ');\n  return schain.ver + ',' + schain.complete + '!' + schain.nodes.map((function(item) {\n    return keys.map((function (key) {\n      return item[key] ? encodeURIComponent(item[key]) : ''\n    })).join(',');\n  })).join('!');\n}\n\nfunction getUrl() {\n  const href = window.location.href;\n  const referrer = document.referrer;\n\n  // Detect if you inside iframe\n  if (window.parent != window) {\n    const win = window, doc = document;\n    let\n      ampUrl = null,\n      topAncestorOriginHostname = null,\n      topAncestorOrigin = null,\n      windowLocationAncestorOriginsHostnames = null,\n      windowLocationAncestorOrigins = null,\n      documentReferrerHostname = null,\n      documentReferrer = null,\n      windowTopLocationOrigin = null,\n      windowLocationOrigin = null,\n      windowTopLocationHostname = null,\n      windowLocationHostname = null,\n      windowTopLocationHref = null,\n      windowLocationHref = null;\n    const parents = [], parentLocationHref = [], parentHostnames = [];\n    let\n      topParentLocationHref = null,\n      domainMatchSource = null,\n      domainMatch = null,\n      //url = null,\n      topParentHostname = null,\n      iframeHeight = 0,\n      topIdxDomain = (iframeHeight = -1);\n\n    const getHostname = function(url) {\n      try {\n        return new URL(url).hostname;\n      } catch (e) {\n        const link = document.createElement('a');\n        link.href = url;\n        return link.hostname;\n      }\n    }\n\n    const getAmpUrl = function(url) {\n      const n = (url = url.replace('.cdn.ampproject.org', '')).lastIndexOf('-');\n      return 0 <= n ? ((url = url.substring(0, n) + '.' + url.substring(n + 1)), getHostname(url)) : null;\n    }\n\n    try {\n      windowLocationHref = win.location.href;\n    } catch (e) {}\n    try {\n      windowTopLocationHref = win.top.location.href;\n    } catch (e) {}\n    try {\n      windowLocationHostname = win.location.hostname;\n    } catch (e) {}\n    try {\n      windowTopLocationHostname = win.top.location.hostname;\n    } catch (e) {}\n    try {\n      windowLocationOrigin = win.location.origin;\n    } catch (e) {}\n    try {\n      windowTopLocationOrigin = win.top.location.origin;\n    } catch (e) {}\n    try {\n      documentReferrer = doc.referrer;\n      documentReferrerHostname = getHostname(documentReferrer);\n    } catch (e) {}\n\n    // Try to collect window.location.ancestorOrigins\n    // ancestorOrigins not support in FF\n    try {\n      windowLocationAncestorOrigins = [];\n      windowLocationAncestorOriginsHostnames = [];\n      for(let i = 0; i < win.location.ancestorOrigins.length; i++) {\n        const ancestorOrigin = win.location.ancestorOrigins[i];\n        windowLocationAncestorOrigins.push(ancestorOrigin);\n        const ancestorOriginHostname = getHostname(ancestorOrigin);\n        windowLocationAncestorOriginsHostnames.push(\n          ancestorOriginHostname\n        );\n        ancestorOrigin.endsWith('.cdn.ampproject.org') && (ampUrl = getAmpUrl(ancestorOrigin));\n      }\n    } catch (e) {}\n    // If window.location.ancestorOrigins was collected get the last ancestorOrigin from array and set topAncestorOrigin\n    windowLocationAncestorOrigins !== null && windowLocationAncestorOrigins.length > 0 && (topAncestorOrigin = windowLocationAncestorOrigins[windowLocationAncestorOrigins.length - 1]);\n    windowLocationAncestorOriginsHostnames !== null && windowLocationAncestorOriginsHostnames.length > 0 && (topAncestorOriginHostname = windowLocationAncestorOriginsHostnames[windowLocationAncestorOriginsHostnames.length - 1]);\n\n    try {\n      let currentWindow = win;\n      iframeHeight = 0;\n      do {\n        try {\n          parents.push(currentWindow);\n        } catch (e) {}\n        try {\n          parentLocationHref.push({\n            url: currentWindow.location.href,\n          });\n          topParentLocationHref = currentWindow.location.href;\n        } catch (e) {}\n        try {\n          parentHostnames.push({\n            url: currentWindow.location.hostname,\n          });\n          topParentHostname = currentWindow.location.hostname;\n          topIdxDomain = iframeHeight + 1;\n        } catch (e) {}\n        currentWindow = currentWindow.parent;\n        iframeHeight++;\n      } while (currentWindow !== win.top && currentWindow !== currentWindow.parent && 50 > iframeHeight);\n    } catch (e) {}\n\n    const getDomainMatchSource = function() {\n      if(topAncestorOriginHostname !== null && topAncestorOriginHostname !== '')\n        return {\n          origin: topAncestorOrigin,\n          hostname: topAncestorOriginHostname,\n        };\n      if(windowTopLocationHostname !== null && windowTopLocationHostname !== '')\n        return {\n          origin: windowTopLocationOrigin,\n          hostname: windowTopLocationHostname,\n        };\n      if(!(1 >= iframeHeight)) {\n        if(!(2 === iframeHeight || 2 >= topIdxDomain) && topParentHostname !== null && topParentHostname !== '')\n          return {\n            origin: topParentLocationHref,\n            hostname: topParentHostname,\n          };\n        if(documentReferrerHostname !== null && documentReferrerHostname !== '')\n          return {\n            origin: documentReferrer,\n            hostname: documentReferrerHostname,\n          };\n      }\n      return windowLocationHostname !== null && windowLocationHostname !== ''\n        ? {\n          origin: windowLocationHref,\n          hostname: windowLocationHostname\n        }\n        : {\n          origin: null,\n          hostname: null\n        };\n    }\n\n    domainMatch = getDomainMatchSource();\n    return domainMatch.origin != null ? domainMatch.origin : referrer;\n  } else {\n    return href;\n  }\n}\n\nconst DEFAULT_LOCATION = 'http://example.com';\nfunction resolveUrl(baseUrl, relativeUrl) {\n  // return early if we don't need to resolve\n  if(/^[a-z]+:/i.test(relativeUrl)) {\n    return relativeUrl;\n  } // if baseUrl is a data URI, ignore it and resolve everything relative to window.location\n\n  if (/^data:/.test(baseUrl)) {\n    baseUrl = window.location && window.location.href || '';\n  } // IE11 supports URL but not the URL constructor\n  // feature detect the behavior we want\n\n  const protocolLess = /^\\/\\//.test(baseUrl); // remove location if window.location isn't available (i.e. we're in node)\n  // and if baseUrl isn't an absolute url\n  const removeLocation = !window.location && !/\\/\\//i.test(baseUrl); // if the base URL is relative then combine with the current location\n\n  baseUrl = new window.URL(baseUrl, window.location || DEFAULT_LOCATION);\n\n  const newUrl = new URL(relativeUrl, baseUrl); // if we're a protocol-less url, remove the protocol\n  // and if we're location-less, remove the location\n  // otherwise, return the url unmodified\n\n  if(removeLocation) {\n    return newUrl.href.slice(DEFAULT_LOCATION.length);\n  } else if (protocolLess) {\n    return newUrl.href.slice(newUrl.protocol.length);\n  }\n\n  return newUrl.href;\n}\n\nconst resolveManifestRedirect = (handleManifestRedirect, url, req) => {\n  // To understand how the responseURL below is set and generated:\n  // - https://fetch.spec.whatwg.org/#concept-response-url\n  // - https://fetch.spec.whatwg.org/#atomic-http-redirect-handling\n  if(\n    handleManifestRedirect &&\n    req &&\n    req.responseURL &&\n    url !== req.responseURL\n  ) {\n    return req.responseURL;\n  }\n\n  return url;\n};\n\nfunction getHostname(url) {\n  try {\n    return new URL(url).hostname;\n  } catch(e) {\n    return null\n  }\n}\n\nfunction fetchWithTimeout(url, options, timeout = 20000) {\n  return Promise.race([\n    fetch(url, options),\n    new Promise((res, rej) => {\n      setTimeout(() => rej(new Error('request rejected by timeout of ' + timeout)), timeout);\n    })\n  ]);\n}\n\nfunction xhr(options, callback) {\n  const method = options.method || 'GET';\n  const uri = options.uri;\n\n  let aborted = false;\n  const request = new XMLHttpRequest();\n\n  request.onabort = function () {\n    aborted = true;\n  };\n  request.open(method, uri);\n  request.withCredentials = !!options.withCredentials;\n\n  function handleLoad() {\n    if (aborted) return;\n    return callback(null, request);\n  }\n\n  function handleError(e) {\n    return callback(e);\n  }\n\n  request.onload = handleLoad\n  request.onerror = handleError;\n\n  request.send();\n  return request;\n}\n\nfunction isQueryStringContains(param, url = window.location.href) {\n  return url.includes(param);\n}\n\nfunction getQueryStringValue(param, url = window.location.href, def = undefined) {\n  let value = null;\n  try {\n    const params = (new URL(url)).searchParams;\n    value = params.get(param);\n  } catch (e) {}\n  return value || def;\n}\n\nfunction mergeObjects(target, source) {\n  for(const key of Object.keys(source)) {\n    if(source[key] instanceof Object) {\n      Object.assign(source[key], mergeObjects((target && Object.keys(target).length ? target : {})[key], source[key]));\n    }\n  }\n  Object.assign(target || {}, source);\n  return target;\n}\n\n\n\n\n//# sourceURL=webpack://adserve/./src/utils.js?");

/***/ }),

/***/ "./src/css/styles.css":
/*!****************************!*\
  !*** ./src/css/styles.css ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js */ \"./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleDomAPI.js */ \"./node_modules/style-loader/dist/runtime/styleDomAPI.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertBySelector.js */ \"./node_modules/style-loader/dist/runtime/insertBySelector.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js */ \"./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertStyleElement.js */ \"./node_modules/style-loader/dist/runtime/insertStyleElement.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleTagTransform.js */ \"./node_modules/style-loader/dist/runtime/styleTagTransform.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var _node_modules_css_loader_dist_cjs_js_styles_css__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! !!../../node_modules/css-loader/dist/cjs.js!./styles.css */ \"./node_modules/css-loader/dist/cjs.js!./src/css/styles.css\");\n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n\nvar options = {};\n\noptions.styleTagTransform = (_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default());\noptions.setAttributes = (_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default());\n\n      options.insert = _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default().bind(null, \"head\");\n    \noptions.domAPI = (_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default());\noptions.insertStyleElement = (_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default());\n\nvar update = _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default()(_node_modules_css_loader_dist_cjs_js_styles_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"], options);\n\n\n\n\n       /* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_node_modules_css_loader_dist_cjs_js_styles_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"] && _node_modules_css_loader_dist_cjs_js_styles_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals ? _node_modules_css_loader_dist_cjs_js_styles_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals : undefined);\n\n\n//# sourceURL=webpack://adserve/./src/css/styles.css?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js":
/*!****************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar stylesInDOM = [];\n\nfunction getIndexByIdentifier(identifier) {\n  var result = -1;\n\n  for (var i = 0; i < stylesInDOM.length; i++) {\n    if (stylesInDOM[i].identifier === identifier) {\n      result = i;\n      break;\n    }\n  }\n\n  return result;\n}\n\nfunction modulesToDom(list, options) {\n  var idCountMap = {};\n  var identifiers = [];\n\n  for (var i = 0; i < list.length; i++) {\n    var item = list[i];\n    var id = options.base ? item[0] + options.base : item[0];\n    var count = idCountMap[id] || 0;\n    var identifier = \"\".concat(id, \" \").concat(count);\n    idCountMap[id] = count + 1;\n    var indexByIdentifier = getIndexByIdentifier(identifier);\n    var obj = {\n      css: item[1],\n      media: item[2],\n      sourceMap: item[3],\n      supports: item[4],\n      layer: item[5]\n    };\n\n    if (indexByIdentifier !== -1) {\n      stylesInDOM[indexByIdentifier].references++;\n      stylesInDOM[indexByIdentifier].updater(obj);\n    } else {\n      var updater = addElementStyle(obj, options);\n      options.byIndex = i;\n      stylesInDOM.splice(i, 0, {\n        identifier: identifier,\n        updater: updater,\n        references: 1\n      });\n    }\n\n    identifiers.push(identifier);\n  }\n\n  return identifiers;\n}\n\nfunction addElementStyle(obj, options) {\n  var api = options.domAPI(options);\n  api.update(obj);\n\n  var updater = function updater(newObj) {\n    if (newObj) {\n      if (newObj.css === obj.css && newObj.media === obj.media && newObj.sourceMap === obj.sourceMap && newObj.supports === obj.supports && newObj.layer === obj.layer) {\n        return;\n      }\n\n      api.update(obj = newObj);\n    } else {\n      api.remove();\n    }\n  };\n\n  return updater;\n}\n\nmodule.exports = function (list, options) {\n  options = options || {};\n  list = list || [];\n  var lastIdentifiers = modulesToDom(list, options);\n  return function update(newList) {\n    newList = newList || [];\n\n    for (var i = 0; i < lastIdentifiers.length; i++) {\n      var identifier = lastIdentifiers[i];\n      var index = getIndexByIdentifier(identifier);\n      stylesInDOM[index].references--;\n    }\n\n    var newLastIdentifiers = modulesToDom(newList, options);\n\n    for (var _i = 0; _i < lastIdentifiers.length; _i++) {\n      var _identifier = lastIdentifiers[_i];\n\n      var _index = getIndexByIdentifier(_identifier);\n\n      if (stylesInDOM[_index].references === 0) {\n        stylesInDOM[_index].updater();\n\n        stylesInDOM.splice(_index, 1);\n      }\n    }\n\n    lastIdentifiers = newLastIdentifiers;\n  };\n};\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertBySelector.js":
/*!********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertBySelector.js ***!
  \********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar memo = {};\n/* istanbul ignore next  */\n\nfunction getTarget(target) {\n  if (typeof memo[target] === \"undefined\") {\n    var styleTarget = document.querySelector(target); // Special case to return head of iframe instead of iframe itself\n\n    if (window.HTMLIFrameElement && styleTarget instanceof window.HTMLIFrameElement) {\n      try {\n        // This will throw an exception if access to iframe is blocked\n        // due to cross-origin restrictions\n        styleTarget = styleTarget.contentDocument.head;\n      } catch (e) {\n        // istanbul ignore next\n        styleTarget = null;\n      }\n    }\n\n    memo[target] = styleTarget;\n  }\n\n  return memo[target];\n}\n/* istanbul ignore next  */\n\n\nfunction insertBySelector(insert, style) {\n  var target = getTarget(insert);\n\n  if (!target) {\n    throw new Error(\"Couldn't find a style target. This probably means that the value for the 'insert' parameter is invalid.\");\n  }\n\n  target.appendChild(style);\n}\n\nmodule.exports = insertBySelector;\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/insertBySelector.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertStyleElement.js":
/*!**********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertStyleElement.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction insertStyleElement(options) {\n  var element = document.createElement(\"style\");\n  options.setAttributes(element, options.attributes);\n  options.insert(element, options.options);\n  return element;\n}\n\nmodule.exports = insertStyleElement;\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/insertStyleElement.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction setAttributesWithoutAttributes(styleElement) {\n  var nonce =  true ? __webpack_require__.nc : 0;\n\n  if (nonce) {\n    styleElement.setAttribute(\"nonce\", nonce);\n  }\n}\n\nmodule.exports = setAttributesWithoutAttributes;\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleDomAPI.js":
/*!***************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleDomAPI.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction apply(styleElement, options, obj) {\n  var css = \"\";\n\n  if (obj.supports) {\n    css += \"@supports (\".concat(obj.supports, \") {\");\n  }\n\n  if (obj.media) {\n    css += \"@media \".concat(obj.media, \" {\");\n  }\n\n  var needLayer = typeof obj.layer !== \"undefined\";\n\n  if (needLayer) {\n    css += \"@layer\".concat(obj.layer.length > 0 ? \" \".concat(obj.layer) : \"\", \" {\");\n  }\n\n  css += obj.css;\n\n  if (needLayer) {\n    css += \"}\";\n  }\n\n  if (obj.media) {\n    css += \"}\";\n  }\n\n  if (obj.supports) {\n    css += \"}\";\n  }\n\n  var sourceMap = obj.sourceMap;\n\n  if (sourceMap && typeof btoa !== \"undefined\") {\n    css += \"\\n/*# sourceMappingURL=data:application/json;base64,\".concat(btoa(unescape(encodeURIComponent(JSON.stringify(sourceMap)))), \" */\");\n  } // For old IE\n\n  /* istanbul ignore if  */\n\n\n  options.styleTagTransform(css, styleElement, options.options);\n}\n\nfunction removeStyleElement(styleElement) {\n  // istanbul ignore if\n  if (styleElement.parentNode === null) {\n    return false;\n  }\n\n  styleElement.parentNode.removeChild(styleElement);\n}\n/* istanbul ignore next  */\n\n\nfunction domAPI(options) {\n  var styleElement = options.insertStyleElement(options);\n  return {\n    update: function update(obj) {\n      apply(styleElement, options, obj);\n    },\n    remove: function remove() {\n      removeStyleElement(styleElement);\n    }\n  };\n}\n\nmodule.exports = domAPI;\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/styleDomAPI.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleTagTransform.js":
/*!*********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleTagTransform.js ***!
  \*********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction styleTagTransform(css, styleElement) {\n  if (styleElement.styleSheet) {\n    styleElement.styleSheet.cssText = css;\n  } else {\n    while (styleElement.firstChild) {\n      styleElement.removeChild(styleElement.firstChild);\n    }\n\n    styleElement.appendChild(document.createTextNode(css));\n  }\n}\n\nmodule.exports = styleTagTransform;\n\n//# sourceURL=webpack://adserve/./node_modules/style-loader/dist/runtime/styleTagTransform.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/assertThisInitialized.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/assertThisInitialized.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _assertThisInitialized)\n/* harmony export */ });\nfunction _assertThisInitialized(self) {\n  if (self === void 0) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n\n  return self;\n}\n\n//# sourceURL=webpack://adserve/./node_modules/@babel/runtime/helpers/esm/assertThisInitialized.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/extends.js":
/*!************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/extends.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _extends)\n/* harmony export */ });\nfunction _extends() {\n  _extends = Object.assign || function (target) {\n    for (var i = 1; i < arguments.length; i++) {\n      var source = arguments[i];\n\n      for (var key in source) {\n        if (Object.prototype.hasOwnProperty.call(source, key)) {\n          target[key] = source[key];\n        }\n      }\n    }\n\n    return target;\n  };\n\n  return _extends.apply(this, arguments);\n}\n\n//# sourceURL=webpack://adserve/./node_modules/@babel/runtime/helpers/esm/extends.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/inheritsLoose.js":
/*!******************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/inheritsLoose.js ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _inheritsLoose)\n/* harmony export */ });\n/* harmony import */ var _setPrototypeOf_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./setPrototypeOf.js */ \"./node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js\");\n\nfunction _inheritsLoose(subClass, superClass) {\n  subClass.prototype = Object.create(superClass.prototype);\n  subClass.prototype.constructor = subClass;\n  (0,_setPrototypeOf_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(subClass, superClass);\n}\n\n//# sourceURL=webpack://adserve/./node_modules/@babel/runtime/helpers/esm/inheritsLoose.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _setPrototypeOf)\n/* harmony export */ });\nfunction _setPrototypeOf(o, p) {\n  _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) {\n    o.__proto__ = p;\n    return o;\n  };\n\n  return _setPrototypeOf(o, p);\n}\n\n//# sourceURL=webpack://adserve/./node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	adserve = __webpack_exports__;
/******/ 	
/******/ })()
;